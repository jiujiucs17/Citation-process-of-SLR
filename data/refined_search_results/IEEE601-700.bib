@INPROCEEDINGS{6225161,
author={Jing, Gangyuan and Finucane, Cameron and Raman, Vasumathi and Kress-Gazit, Hadas},
booktitle={2012 IEEE International Conference on Robotics and Automation},
title={Correct high-level robot control from structured English},
year={2012},
volume={},
number={},
pages={3543-3544},
abstract={The Linear Temporal Logic MissiOn Planning (LTLMoP) toolkit is a software package designed to generate a controller that guarantees a robot satisfies a task specification written by the user in structured English. The controller can be implemented on either a simulated or physical robot. This video illustrates the use of LTLMoP to generate a correct-by-construction robot controller. Here, an Aldebaran Nao humanoid robot carries out tasks as a worker in a simplified grocery store scenario.},
keywords={Robot sensing systems;Planning;Legged locomotion;Robot control;Manuals},
doi={10.1109/ICRA.2012.6225161},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{7028307,
author={Yen, Freedman and Hung, Leo and Kao, Nicholas and Jiang, Don Son},
booktitle={2014 IEEE 16th Electronics Packaging Technology Conference (EPTC)},
title={MoldFlow simulation study on void risk prediction for FCCSP with molded underfill technology},
year={2014},
volume={},
number={},
pages={817-821},
abstract={The microelectronics products of Flip Chip-Chip Scale Package (FCCSP) with more increasing challenges are faced to assure molding capability with rapid advances in flip chip technology such as decreasing stand-off height and bump pitch, especially when Molded Underfill (MUF) is used during transfer molding process. There is one important challenge that faced severe air void entrapment under the die (air void concentrate among bumps region). Generally, the experiments involving a lot of DOE matrixes which spend a lot of time and materials (dummy die, substrate, mold compound...etc.) to solve this air void issue. As above reasons, the moldflow simulation can be used to apply molding parameters to find out optimum solutions for air void risk free of MUF FCCSP with different bump structure or substrate structure design, which can reduce development cycle time before mass production. In this paper, 3D moldflow simulation software which can apply transfer molding process parameters is used. There are two molding flow factors will be presented in this paper. One is MUF FCCSP with different stand-off height construction (control different bump height dimension) which performs significant difference molding melt-front position. And another is substrate solder mask with different pattern design (solder mask w/ all open or finger like pattern design) which molding compound through over on solder mask pattern (solder mask with open region as 10um depth structure) and performs different melt-front pattern. From this study, we can conclude some results for improvement molding performance of MUF FCCSP during transfer molding process. The MUF FCCSP with the 50um stand-off height structure performs low air void risk due to mold compound could easily flow under die region with more flow space. In addition, mold compound also performs well melt-front flow that the substrate solder mask with all open structure design can get more 10um flow space under die region. Finally, the simulation results are aligned with experiments and it can be used to predict void risk.},
keywords={Viscosity;Substrates;Fingers;Transfer molding;Compounds;Curing;Kinetic theory},
doi={10.1109/EPTC.2014.7028307},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9849206,
author={Suwan, Anukoon and Uthayopas, Putchong},
booktitle={2022 International Conference on Digital Government Technology and Innovation (DGTi-CON)},
title={The Development of a Research Information Data Analysis Software for TSRI},
year={2022},
volume={},
number={},
pages={1-4},
abstract={Thailand Science Research and Innovation (TSRI) is one of the leading funding agencies in Thailand. TSRI kept more than 10,000 research reports in the e-library system. The analysis of these reports can give substantially important insight into the relationship among the funded research projects. This paper presents the development of a prototype research and information data analysis system in TSRI called the RIDA system. The design concept and implementation issues are described. A few basic natural language processing techniques are used to extract the information from the abstract of the research documents. Then, the relationship is analyzed utilizing the word co-occurrence technique. The result is then visualized as a graph that portrays the relationship among the group of related documents. The results of this work can lead to potentially more effective funding strategies that help drive national science and technology development in the future.},
keywords={Technological innovation;Data analysis;Government;Data visualization;Prototypes;Computer architecture;Software;information retrieval;natural language processing;document analysis},
doi={10.1109/DGTi-CON53875.2022.9849206},
ISSN={},
month={March},}
@INPROCEEDINGS{8720583,
author={Takeuchi, Kan and Shimada, Masaki and Konishi, Shinya and Oshida, Daisuke and Ota, Naoya and Yasumasu, Takashi and Shibutani, Koji and Iwashita, Tomohiro and Kokubun, Tetsuya and Tsuchiya, Fumio},
booktitle={2019 IEEE International Reliability Physics Symposium (IRPS)},
title={Experimental Implementation of 8.9Kgate Stress Monitor in 28nm MCU Along with Safety Software Library for IoT Device Maintenance},
year={2019},
volume={},
number={},
pages={1-7},
abstract={The on-chip stress monitor was experimentally implemented in a 28 nm automotive micro-controller-unit (MCU) to demonstrate the contribution to long-term fatigue monitoring of the MCU as well as short-term anomaly finding of the system. The monitor comprises of 8.1 Kgate digital soft-macro including four stress counters driven by 0.8 Kgate two dedicated ring oscillators, which automatically convert environmental temperature and voltage stress into oscillation frequency according to Arrhenius and Eyring models. The monitor operates independently in the background of main operations. The safety software library was developed to extract beneficial information from the counters after every power-on reset, including stress age and temporal variations of thermal stress. The functions were confirmed by the MCU measurements. The library also proved to contribute to functional safety of main temperature sensor. Future usage picture of the monitor was discussed including IoT maintenance, system design feedback and used electronics recycling.},
keywords={Stress;Monitoring;Temperature sensors;Temperature measurement;Safety;Thermal stresses;Stress measurement;aging;maintenance;ring oscillator;stress monitor;wear-out},
doi={10.1109/IRPS.2019.8720583},
ISSN={1938-1891},
month={March},}
@INPROCEEDINGS{4784,
author={Morris, D.S.},
booktitle={[Proceedings 1988] The Third International IEEE Conference on Ada Applications and Environments},
title={Packaging fault-tolerant software with Ada},
year={1988},
volume={},
number={},
pages={45-52},
abstract={The ability of the Ada programming language to support a software-engineering approach to building fault-tolerant applications systems by distributed redundant abstract data types (ADTs) is discussed. It is shown that the package, the separation of the specification from the implementation parts, the typing and exception handling mechanisms, and the nondeterministic rendezvous of the Ada language contribute to the fault-tolerance of systems constructed in this fashion.<>},
keywords={Software packages;Packaging;Fault tolerance;Fault tolerant systems;Software design;Circuit faults;Application software;Distributed computing;Computer languages;Software engineering},
doi={10.1109/ADA.1988.4784},
ISSN={},
month={May},}
@INPROCEEDINGS{8384648,
author={Toroslu, Irem and Doğan, Mustafa},
booktitle={2018 4th International Conference on Control, Automation and Robotics (ICCAR)},
title={Effective sensor fusion of a mobile robot for SLAM implementation},
year={2018},
volume={},
number={},
pages={76-81},
abstract={The Simultaneous Localization and Mapping (SLAM) is the process of building a map of an environment with an unknown topography by a mobile robot. The purpose of this paper is to build a mapping of an unknown environment by the mobile robot which we designed through the help of sensor fusion algorithms we have established. The mobile robot performs its mapping process by using the combination of ultrasonic, optical encoder and IMU sensors. Determining the position of the obstacles and its own location, for the mobile robot, is the core of this study. Inertial and rotational sensors are utilized to calculate the distance and position of the mobile robot. Due to low cost, the ultrasonic sensor is used instead of a Lidar laser, and the real-like results were provided. In this study, the robot's direction and movement is performed by an algorithm developed on the Raspberry Pi processor. This algorithm controls the movement of the wheels with the information received from the optical encoder and protractor. The data received from the gyroscope and the accelerometer is very affected from many external factors such as vibrational motion and the noise, eventhough, we used moving average filter and complementary filter to reduce the effect of the noise and measurement error problems. However, they still produce faulty results when calculating distance values. Therefore, the distance computation is carried out by using optical encoder instead of the accelerometer. The algorithm of the distance computation is written in Python programming language. In this study, it is established that the comparative usage of several detectors provide more accurate results. At the same time, the system is quite efficiently developed by using open structure software (Raspberry Pi, Linux etc.) and writing authentic libraries. The robot's coordinate information are combined under simulation medium by using Pygame library and by computing the coordinates of its location and the coordinates of the objects' locations it detects during its navigation. The mobile robot executes its mapping process according to these data derived. Also, the effects of margin of error in the information obtained during the comparable usage of detectors are studied within the scope of this study.},
keywords={Optical filters;Mobile robots;Low pass filters;Simultaneous localization and mapping;IIR filters;Gyroscopes;component;open software;raspberry pi;IMU;optic encoder;complementary filter;moving average filter},
doi={10.1109/ICCAR.2018.8384648},
ISSN={},
month={April},}
@INPROCEEDINGS{8916328,
author={Zhou, Hongkuan and Srivastava, Ajitesh and Kannan, Rajgopal and Prasanna, Viktor},
booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)},
title={Design and Implementation of Knowledge Base for Runtime Management of Software Deﬁned Hardware},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Runtime-reconfigurable software coupled with reconfigurable hardware is highly desirable as a means towards maximizing runtime efficiency without compromising programmability. Compilers for such software systems are extremely difficult to design as they must leverage different types of hardware at runtime. To address the need for static and dynamic compiler optimization of workflows matched to dynamically reconfigurable hardware, we propose a novel design of the central component of a dynamic software compiler for software defined hardware. Our comprehensive design focuses not just on static knowledge but also on semi-supervised extraction of knowledge from program executions and developing their performance models. Specifically, our novel dynamic and extensible knowledge base 1) continuously gathers knowledge during execution of workflows 2) identifies optimal implementations of workflows on optimal (available) hardware configurations. It plays a hub role in storing information from, and providing information to other components of the compiler, as well as the human analyst. Through a rich tripartite graph representation, the knowledge base captures and learns extensive information on decomposition and mapping of code steps to kernels and mapping of kernels to available hardware configurations. The knowledge base is implemented using the C++ Boost Library and is capable of quickly processing offline and online queries and updates. We show that our knowledge base can answer queries in 1ms regardless of the number of workflows it stores. To the best of our knowledge, this is the first design of a dynamic and extensible knowledge base to support compilation of high-level languages to leverage arbitrary reconfigurable platforms.},
keywords={Knowledge based systems;Hardware;Kernel;Runtime;Task analysis;Synchronous digital hierarchy;Dynamic compiler;Reconfigurable architectures;Knowledge management},
doi={10.1109/HPEC.2019.8916328},
ISSN={2643-1971},
month={Sep.},}
@ARTICLE{6134619,
author={},
journal={IEEE Std 1666-2011 (Revision of IEEE Std 1666-2005)},
title={IEEE Standard for Standard SystemC Language Reference Manual},
year={2012},
volume={},
number={},
pages={1-638},
abstract={SystemC® is defined in this standard. SystemC is an ANSI standard C++ class library for system and hardware design for use by designers and architects who need to address complex systems that are a hybrid between hardware and software. This standard provides a precise and complete definition of the SystemC class library so that a SystemC implementation can be developed with reference to this standard alone. The primary audiences for this standard are the implementors of the SystemC class library, the implementors of tools supporting the class library, and the users of the class library.},
keywords={IEEE standards;Computer languages;Programming;Electronic design automation and methodology;Discrete event simulation;Hardware design languages;System-on-a-chip;Embedded software;C++;computer languages;digital systems;discrete event simulation;electronic design automation;electronic system level;electronic systems;embedded software;fixed-point;hardware description language;hardware design;hardware verification;IEEE 1666;SystemC;system modeling;system-on-chip;transaction level},
doi={10.1109/IEEESTD.2012.6134619},
ISSN={},
month={Jan},}
@INPROCEEDINGS{6472468,
author={Kawashima, Ryota},
booktitle={2012 Second Symposium on Network Cloud Computing and Applications},
title={vNFC: A Virtual Networking Function Container for SDN-Enabled Virtual Networks},
year={2012},
volume={},
number={},
pages={124-129},
abstract={Software-defined networks (SDN) has gradually been deployed on commercial networks such as datacenter networks. Current SDN is based on OpenFlow technology that is a set ofnetwork flow control API for switch devices. For instance, network reachability between end-hosts (or virtual machines), packet filtering mechanisms, and status management of switches are enabled by the API. In practice, however, current OpenFlow-based SDN has following problems: no application-layer protocol support and switch-oriented flow control. Since OpenFlow targets L2-L4 flow handling, users have to arrange additional mechanism for upper-layer flow control. Furthermore, executing a lot of flow matching on a single switch (or virtual switch) can cause difficulty in network trace and overall performance degradation.This paper proposes a virtual networking function container (vNFC) that is a set of software implemented networking functions for VM-to-VM communications, and it is located between a virtual machine and a virtual network device of the host machine. vNFC enables not only lower-layer functions OpenFlow providing, but also upper-layer functions like application firewall in the same manner. That is, vNFC is a virtual machine dedicated flow handling function set. In addition, OpenFlow-compatible vNFC configuration protocol named OpenNF and vNFC controller are also presented. OpenNF provides communication path between each networking function and the controller for configuration and decision making.In this paper, architectural design and implementation of vNFC are presented, and also performance evaluation of using vNFC. The evaluation result shows that a lightweight networking function does not impact on the performance, but a function that frequently communicates with the controller incurs millisecond order cost per frame transmission.},
keywords={Switches;Libraries;Virtual machining;Protocols;Noise measurement;Performance evaluation;software-defined networks;datacenter network;virtual network;OpenFlow;systemcall interposition},
doi={10.1109/NCCA.2012.18},
ISSN={},
month={Dec},}
@INPROCEEDINGS{1327958,
author={Manjikian, N. and Huang Jin and Reed, J. and Cordeiro, N.},
booktitle={International Conference on Parallel Processing, 2004. ICPP 2004.},
title={Architecture and implementation of chip multiprocessors: custom logic components and software for rapid prototyping},
year={2004},
volume={},
number={},
pages={483-492 vol.1},
abstract={This work describes components and software tools in support of rapid prototyping in programmable logic for research on chip multiprocessors. Contemporary programmable logic chips offer considerable on-chip logic and memory resources. Prototyping of systems in programmable logic chips is faster and less costly than full-custom chip design. The first contribution that is described in this paper is a collection of original research-oriented logic components that provides processor, memory, and interconnect functionality for rapid prototyping. Because these are original components, and not proprietary vendor-supplied components, they may be arbitrarily extended and modified to suit research needs. The second contribution is a set of enhanced software tools for generating executable code. The third contribution is user-configurable software for testing and evaluating prototype chip multiprocessor implementations in hardware. In addition to describing these contributions, this paper provides results from implementing and testing prototype components and complete chip multiprocessors, including simulation waveforms, logic chip resource utilization, and observations of hardware operation.},
keywords={Computer architecture;Software prototyping;Programmable logic arrays;Programmable logic devices;Software tools;Prototypes;Hardware;Logic testing;Logic design;Chip scale packaging},
doi={10.1109/ICPP.2004.1327958},
ISSN={0190-3918},
month={Aug},}
@INPROCEEDINGS{7485733,
author={Tang, Jiuting and Wang, Haifeng and Chen, Libo and Liu, Yuxin and Wang, Ji},
booktitle={OCEANS 2016 - Shanghai},
title={The frequency domain analysis of a novel extended tension leg platform},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Tension leg platform (TLP) is a kind of offshore structures for oil or gas exploration in deep-water which has its special feature as partly compliant and partly rigid. Extended tension leg platform (ETLP) is the third generation of TLP which made an improvement on the basis of typical TLP structure. Extended structure is the most notable feature of ETLP which could increase the distance of groups of tethers and magnify the restoring moment. A novel ETLP which consists of four columns and a ring pontoon is proposed in this paper. Four box beams are welded onto each other and formed a ring pontoon. It makes the extended structures to be parts of the pontoons. This design decreases the number of blocks and welds needed for construction, which means the construction cost and period can be reduced, and the structure intensity and fatigue reliability can be enhanced. In this paper, a frequency domain numerical analysis is carried out using HydroD module of SESAM software. The natural periods, the hydrodynamic parameters and motion amplitude response function or response amplitude operator (RAO) of novel ETLP are obtained. The results indicate the natural periods of novel ETLP can satisfy the requirement of API. The novel ETLP has a reasonable hydrodynamic performance, and the asymmetry structure has a negligible impact on yaw performance. The novel ETLP provides an alternative for the structure design of deepwater floating platform, and is significant for launching and optimizing the devising of TLP in future.},
keywords={Hydrodynamics;Mathematical model;Load modeling;Welding;Damping;Tendons;Frequency-domain analysis;extended tension leg platform (ETLP);natural period;hydrodynamic performance;response amplitude operator (RAO);yaw performance},
doi={10.1109/OCEANSAP.2016.7485733},
ISSN={},
month={April},}
@INPROCEEDINGS{5341583,
author={Wang, Yuying and Zhou, Xingshe and Dong, Yunwei and Li, Changde},
booktitle={2009 International Conference on Scalable Computing and Communications; Eighth International Conference on Embedded Computing},
title={A MDA-Based Approach for General Embedded Software Simulation Platform},
year={2009},
volume={},
number={},
pages={20-25},
abstract={The needs for reusing software components and integrating them into a system arise from complexity of embedded system. As one of the most important embedded system development tools, simulation platform is in favor of the reuse and integration of simulation software components and models. This paper presents a simulation platform for general embedded software followed the idea of component reuse and integration through Model Driven Architecture (MDA). There are four components in the simulation platform architecture: data exchange interface, data process engine, actuator module and signal exchange interface. Simulation system could be developed using models provided by an extendable component/model library based on the MathWorks Matlab/Simulink in the platform, which helps improved the reusability and decrease time-to market of embedded system. As a case study, the implementation of the proposed platform and a smarthome control system development example are demonstrated in an experiment. The results show that this platform is feasible and effective.},
keywords={Embedded software;Mathematical model;Embedded system;Computer architecture;Software tools;Engines;Actuators;Signal processing;Software libraries;Control systems;Model-Driven Architecture;simulation platform;embedded system;reusability},
doi={10.1109/EmbeddedCom-ScalCom.2009.14},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9842690,
author={Bo, Sun and Mao, Xinjun and Yang, Shuo and Chen, Long},
booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)},
title={Towards An Efficient Searching Approach of ROS Message by Knowledge Graph},
year={2022},
volume={},
number={},
pages={934-943},
abstract={The Robot Operating System (ROS) has become the most popular robot development framework in the last few years, which has loosely coupled structure and provides remote communications between different component nodes. The ROS messages are critical to bridge the communication channels and clearly define the data structures. The developers can use the standardized or user-customized ROS message types to construct a communication channel between two component nodes uniquely. However, it becomes increasingly difficult for developers to find the required ROS message type from thousands of diverse ROS message types in ROS-based robotic software development. Finding the proper ROS message type is a non-trivial task because developers may hardly know the exact names of required ROS messages but only has a rough knowledge of the task domain features. To tackle this challenge, we construct a novel ROS Message Knowledge Graph (RMKG) with 4543 entities and 14320 relationships, including all ROS message types and message packages. We take the shortest path algorithm to search ROS message in RMKG by searching with ROS message feature or ROS message package and visualize the subgraph structure of the search results. Moreover, we develop a ROS message package library that supports fuzzy queries to find the required message package. A comprehensive evaluation of RMKG shows the high accuracy of our knowledge construction approach. A user study indicates that RMKG is promising in helping developers find suitable ROS message types for robotics software development tasks. An effect evaluation of message package fuzzy query shows the good effects of our fuzzy query method under different situations.},
keywords={Bridges;Operating systems;Conferences;Communication channels;Data structures;Software;Libraries;search;Knowledge Graph;message;feature;fuzzy query;ROS},
doi={10.1109/COMPSAC54236.2022.00145},
ISSN={0730-3157},
month={June},}
@INPROCEEDINGS{874067,
author={Fujimoto, R. and McLean, T. and Perumalla, K. and Tacic, I.},
booktitle={Proceedings Fourth IEEE International Workshop on Distributed Simulation and Real-Time Applications (DS-RT 2000)},
title={Design of high performance RTI software},
year={2000},
volume={},
number={},
pages={89-96},
abstract={This paper describes the implementation of RTI-Kit, a modular software package to realize runtime infrastructure (RTI) software for distributed simulations such as those for the High Level Architecture. RTI-Kit software spans a wide variety of computing platforms, ranging from tightly coupled machines such as shared memory multiprocessors and cluster computers to distributed workstations connected via a local area or wide area network. The time management, data distribution management, and underlying algorithms and software are described.},
keywords={Software performance;Computer networks;Distributed computing;Software packages;Runtime;Computational modeling;Computer architecture;Workstations;Wide area networks;Clustering algorithms},
doi={10.1109/DISRTA.2000.874067},
ISSN={1530-1990},
month={Aug},}
@INPROCEEDINGS{7781807,
author={Balogh, Gergő and Gergely, Tamás and Beszédes, Árpád and Gyimóthy, Tibor},
booktitle={2016 IEEE 16th International Working Conference on Source Code Analysis and Manipulation (SCAM)},
title={Are My Unit Tests in the Right Package?},
year={2016},
volume={},
number={},
pages={137-146},
abstract={The software development industry has adopted written and de facto standards for creating effective and maintainable unit tests. Unfortunately, like any other source code artifact, they are often written without conforming to these guidelines, or they may evolve into such a state. In this work, we address a specific type of issues related to unit tests. We seek to automatically uncover violations of two fundamental rules: 1) unit tests should exercise only the unit they were designed for, and 2) they should follow a clear packaging convention. Our approach is to use code coverage to investigate the dynamic behaviour of the tests with respect to the code elements of the program, and use this information to identify highly correlated groups of tests and code elements (using community detection algorithm). This grouping is then compared to the trivial grouping determined by package structure, and any discrepancies found are treated as "bad smells." We report on our related measurements on a set of large open source systems with notable unit test suites, and provide guidelines through examples for refactoring the problematic tests.},
keywords={Testing;Software;Guidelines;Packaging;Servers;Heuristic algorithms;Code coverage;unit testing;clusterization;package hierarchy;community detection;test smells and refactoring},
doi={10.1109/SCAM.2016.10},
ISSN={2470-6892},
month={Oct},}
@INPROCEEDINGS{7977087,
author={Sundharam, Sakthivel Manikandan and Havet, Lionel and Altmeyer, Sebastian and Navet, Nicolas},
booktitle={2016 Sixth International Symposium on Embedded Computing and System Design (ISED)},
title={A model-based development environment for rapid-prototyping of latency-sensitive automotive control software},
year={2016},
volume={},
number={},
pages={228-233},
abstract={The innovation in the field of automotive embedded systems has been increasingly relying on software-implemented functions. The control laws of these functions typically assume deterministic sampling rates and constant delays from input to output. However, on the target processors, the execution times of the software will depend on many factors such as the amount of interferences from other tasks, resulting in varying delays from sensing to actuating. Three approaches supported by tools, namely TrueTime, T-Res, and SimEvents, have been developed to facilitate the evaluation of how timing latencies affect control performance. However, these approaches support the simulation of control algorithms, but not their actual implementation. In this paper, we present a model interpretation engine running in a co-simulation environment to study control performances while considering the run-time delays in to account. Introspection features natively available facilitate the implementation of self-adaptive and fault-tolerance strategies to mitigate and compensate the run-time latencies. A DC servo controller is used as a supporting example to illustrate our approach. Experiments on controller tasks with injected delays show that our approach is on par with the existing techniques with respect to simulation. We then discuss the main benefits of our development approach that are the support for rapid-prototyping and the re-use of the simulation model at run-time, resulting in productivity and quality gains.},
keywords={Mathematical model;Delays;Software packages;Engines;Real-time systems;Tools;Servomotors;Model-Based Development;Control software;Controller model;Task release jitters;Varying execution-times;Co-simulation;Real-time scheduling;Control system performance},
doi={10.1109/ISED.2016.7977087},
ISSN={2473-9413},
month={Dec},}
@INPROCEEDINGS{504357,
author={Beletsky, V. and Bagaterenco, A. and Chemeris, A.},
booktitle={Programming Models for Massively Parallel Computers},
title={A package for automatic parallelization of serial C-programs for distributed systems},
year={1995},
volume={},
number={},
pages={184-188},
abstract={Problems arising due to run existent software in parallel computer systems are considered. The problem may be formulated as the serial programs should be analyzed first and then through modification of them are to be brought in to make them able to run in parallel computers. The problems that arise have been analyzed and ways to tackle them are given. The structure of programming package is given. It is substantiated that for most sequential programs the major share of time spent for their execution is accounted for by processing loops. Three loop parallelization methods have been selected for implementation of programs: method of coordinates, method of linear transformations, and modified method of linear-piece parallelization. The dependence graph construction principles are expounded and scheduling methods are enumerated.},
keywords={Packaging;Concurrent computing;Processor scheduling;Topology;Software packages;Computational modeling;Computer simulation;Power engineering;Distributed computing;Power engineering computing},
doi={10.1109/PMMPC.1995.504357},
ISSN={},
month={Oct},}
@INPROCEEDINGS{5712078,
author={Šmidl, Václav},
booktitle={2010 13th International Conference on Information Fusion},
title={Software analysis unifying particle filtering and marginalized particle filtering},
year={2010},
volume={},
number={},
pages={1-7},
abstract={Particle filtering has evolved into wide range of techniques giving rise to many implementations and specialized algorithms. In theory, all these techniques are closely related, however this fact is usually ignored in software implementations. In this paper, particle filtering is studied together with marginalized particle filtering and a generic software scheme unifying these two areas is proposed. It is presented in general terms of object-oriented programming so that it may be implemented in existing Bayesian filtering toolboxes that are briefly reviewed. The power of the approach is illustrated on a new variant of the marginalized particle filter. A range of new variants of the filter is obtained by plugging this class into the proposed software structure. The framework and the illustrative example is implemented in the BDM library.},
keywords={Bayesian methods;Proposals;Software;Filtering;Object oriented modeling;Software algorithms;Approximation methods;Marginalized particle filter;software analysis;Bayesian filtering},
doi={10.1109/ICIF.2010.5712078},
ISSN={},
month={July},}
@INPROCEEDINGS{4228498,
author={Lu, Zhonghai and Sicking, Jonas and Sander, Ingo and Jantsch, Axel},
booktitle={18th IEEE/IFIP International Workshop on Rapid System Prototyping (RSP '07)},
title={Using Synchronizers for Refining Synchronous Communication onto Hardware/Software Architectures},
year={2007},
volume={},
number={},
pages={143-149},
abstract={We have presented a formal set of synchronization components called synchronizers for refining synchronous communication onto HW/SW codesign architectures. Such an architecture imposes asynchronous communication between HW-HW, SW-SW and HW-SW components. The synchronizers enable local synchronization, thus satisfy the synchronization requirement of a typical IP core. In this paper, we present their implementations in HW, SW and HW/SW, as well as their application. To validate our concepts, we conduct a case study on a Nios FPGA that comprises a processor, memory and custom logic. The final HW/SW implementation achieves equivalent performance to pure HW implementation. Our prototyping experience suggests that the synchronizers can be standardized as library modules and effectively separate the design of computation from that of communication.},
keywords={Hardware;Software architecture;Synchronization;Computer architecture;Prototypes;Clocks;Object oriented modeling;Asynchronous communication;Field programmable gate arrays;Communication system control},
doi={10.1109/RSP.2007.38},
ISSN={2150-5519},
month={May},}
@INPROCEEDINGS{746666,
author={Deconinck, G. and Truyens, M. and De Florio, V. and Rosseel, W. and Lauwereins, R. and Belmans, R.},
booktitle={Proceedings of the Seventh Euromicro Workshop on Parallel and Distributed Processing. PDP'99},
title={A framework backbone for software fault tolerance in embedded parallel applications},
year={1999},
volume={},
number={},
pages={189-195},
abstract={The DIR net (detection-isolation-recovery net) is the main module of a software framework for the development of embedded supercomputing applications. This framework provides a set of functional elements, collected in a library, to improve the dependability attributes of the applications (especially the availability). The DIR net enables these functional elements to cooperate and enhances their efficiency by controlling and co-ordinating them. As a supervisor and the main executor of the fault tolerance strategy, it is the backbone of the framework, of which the application developer is the architect. Moreover, it provides an interface to which all detection and recovery tools should conform. Although the DIR net is meant to be used together within this fault tolerance framework, the adopted concepts and design decisions have a more general value, and can be applied in a wide range of parallel systems.},
keywords={Spine;Embedded software;Fault tolerance;Application software;Hardware;Fault tolerant systems;High performance computing;Availability;Parallel processing;Libraries},
doi={10.1109/EMPDP.1999.746666},
ISSN={},
month={Feb},}
@INPROCEEDINGS{5321675,
author={Adamczewski-Musch, J. and Essel, H. G. and Kurz, N. and Linev, S.},
booktitle={2009 16th IEEE-NPSS Real Time Conference},
title={First release of Data Acquisition Backbone Core},
year={2009},
volume={},
number={},
pages={388-392},
abstract={New experiments at FAIR require new concepts of data acquisition systems. Instead of building hardware trigger systems with strict latency limitations, it is intended to use self-triggered electronics. Front-end components should be time synchronized and will provide data with time stamps. Data streams from many of such components should be forwarded over a powerful sorting network to an event building farm. The Data Acquisition Backbone Core (DABC) is designed as a general purpose software framework for the implementation of such data acquisition systems. It is based on C++ and Java. A first version is now published and available.},
keywords={Data acquisition;Spine;Yarn;Sorting;Buildings;Computer architecture;Application software;Real time systems;Hardware;Delay;Data acquisition;software packages},
doi={10.1109/RTC.2009.5321675},
ISSN={},
month={May},}
@ARTICLE{5733835,
author={},
journal={ISO/IEC/IEEE 24765:2010(E)},
title={ISO/IEC/IEEE International Standard - Systems and software engineering -- Vocabulary},
year={2010},
volume={},
number={},
pages={1-418},
abstract={The systems and software engineering disciplines are continuing to mature while information technology advances. This International Standard was prepared to collect and standardize terminology. Its purpose is to identify terms currently in use in the field and standard definitions for these terms. It is intended to serve as a useful reference for those in the Information Technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute (PMI). This International Standard replaces IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, which was contributed by the IEEE as a source document. The approach and lexical exactitude of IEEE Std 610.12-1990 served as a model for this International Standard. Nevertheless, approximately two thirds of the definitions in this International Standard are new since IEEE Std 610.12 was last updated in 1990, a reflection of the continued evolution in the field.},
keywords={IEEE standards;ISO standards;IEC standards;Software engineering;Dictionaries;computer;dictionary;information technology;software engineering;systems engineering;terminology;vocabulary},
doi={10.1109/IEEESTD.2010.5733835},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6903604,
author={Huang, Zhen and Lie, David},
booktitle={2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks},
title={Ocasta: Clustering Configuration Settings for Error Recovery},
year={2014},
volume={},
number={},
pages={479-490},
abstract={Effective machine-aided diagnosis and repair of configuration errors continues to elude computer systems designers. Most of the literature targets errors that can be attributed to a single erroneous configuration setting. However, a recent study found that a significant amount of configuration errors require fixing more than one setting together. To address this limitation, Ocasta statistically clusters dependent configuration settings based on the application's accesses to its configuration settings and utilizes the extracted clustering of configuration settings to fix configuration errors involving more than one configuration settings. Ocasta treats applications as black-boxes and only relies on the ability to observe application accesses to their configuration settings. We collected traces of real application usage from 24 Linux and 5 Windows desktops computers and found that Ocasta is able to correctly identify clusters with 88.6% accuracy. To demonstrate the effectiveness of Ocasta, we evaluated it on 16 real-world configuration errors of 11 Linux and Windows applications. Ocasta is able to successfully repair all evaluated configuration errors in 11 minutes on average and only requires the user to examine an average of 3 screenshots of the output of the application to confirm that the error is repaired. A user study we conducted shows that Ocasta is easy to use by both expert and non-expert users and is more efficient than manual configuration error troubleshooting.},
keywords={Maintenance engineering;Libraries;Linux;Correlation;History;Electronic mail;Postal services;Fault diagnosis;System recovery;Clustering algorithms;Software tools},
doi={10.1109/DSN.2014.51},
ISSN={2158-3927},
month={June},}
@ARTICLE{6226815,
author={Wahl, Christopher G. and Jaworski, Jason M. and He, Zhong},
journal={IEEE Transactions on Nuclear Science},
title={UMImaging: A Software Package for Image Reconstruction From 3D-Position-Sensitive Gamma-Ray Detectors},
year={2012},
volume={59},
number={4},
pages={1672-1680},
abstract={In order to support analysis of data from 3D-position-sensitive gamma-ray detectors, a software package, UMImaging, has been designed and implemented. UMImaging is designed to apply to a wide range of hardware configurations and analysis needs. Its framework centers around reconstruction methods that perform analysis including spectroscopy, imaging, and detection. These methods are supported by classes that supply events, describe geometry, set options, store and manipulate results, and interact with the user. The ability to bin and display highly multidimensional data is presented, drawing numerous examples from the analysis of data from a CdZnTe array system. Parallel computing integrated into the structure of UMImaging is shown to provide almost a seven-fold speedup on a six-core computer with hyper-threading, and the parallel implementation of iterative reconstruction is described. Design choices that make UMImaging platform independent and easily extendable are also discussed.},
keywords={Detectors;Image reconstruction;Geometry;Reconstruction algorithms;Real-time systems;User interfaces;Compton imaging;data analysis software;image reconstruction;position-sensitive gamma-ray detector},
doi={10.1109/TNS.2012.2196803},
ISSN={1558-1578},
month={Aug},}
@ARTICLE{9645184,
author={Garcia-Alonso, Jose and Rojo, Javier and Valencia, David and Moguel, Enrique and Berrocal, Javier and Murillo, Juan Manuel},
journal={IEEE Internet Computing},
title={Quantum Software as a Service Through a Quantum API Gateway},
year={2022},
volume={26},
number={1},
pages={34-41},
abstract={As quantum computers mature, the complexity of quantum software increases. As we move from the initial standalone quantum algorithms toward complex solutions combining quantum algorithms with traditional software, new software engineering methods and abstractions are needed. Nowadays, quantum computers are usually offered in the cloud, under a pay-per-use model, leading to the adoption of the service-oriented good practices that dominate the cloud today. However, specific adaptations are needed to reap the benefits of service-oriented computing while dealing with quantum hardware limitations. In this article, we propose the Quantum API Gateway—an adaptation of the API Gateway pattern that takes into account the fact that quantum services cannot be deployed as traditional services. Instead, the Quantum API Gateway recommends the best quantum computer to run a specific quantum service at run time. As proof of concept, we provide an implementation of the Quantum API Gateway for the Amazon Braket platform.},
keywords={Quantum computing;Logic gates;Software;Computers;Cloud computing;Hardware;Computational modeling;Application programming interfaces},
doi={10.1109/MIC.2021.3132688},
ISSN={1941-0131},
month={Jan},}
@INPROCEEDINGS{9751271,
author={Kozma, Nina and Krstić, Dušan},
booktitle={2022 21st International Symposium INFOTEH-JAHORINA (INFOTEH)},
title={Design of Information System for Bookstore support Student paper},
year={2022},
volume={},
number={},
pages={1-6},
abstract={The paper presents techniques, methods and tools for web application development using MERN stack. A real system that is modeled and improved is described, as well as an analysis of user requirements, design, implementation, testing and presentation of the web application, developed in order to support the business of bookstores. The architecture of the developed web application is explained in detail and a description of its work is presented. Conclusions were drawn based on the results of work and performances of the developed application. This work also includes possible ways of improvement and further development, as well as the advantages in relation to other, similar solutions.},
keywords={Technological innovation;Software packages;Companies;Passwords;Standardization;User experience;Service-oriented architecture;Information System;ERP;software development;web application;e-commerce},
doi={10.1109/INFOTEH53737.2022.9751271},
ISSN={2767-9470},
month={March},}
@INPROCEEDINGS{323895,
author={Pope and Lowe},
booktitle={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
title={Vista: a software environment for computer vision research},
year={1994},
volume={},
number={},
pages={768-772},
abstract={Vista is a software environment supporting the modular implementation and execution of computer vision algorithms. Because it is extensible, portable, and freely available, Vista is an appropriate medium for the exchange of standard implementations of algorithms. This paper, an overview of Vista, describes its file format, its data abstraction, its conventions for UNIX filter programs and library routines, and its user interface toolkit. Unlike systems that are designed principally to support image processing, Vista provides for the easy creation and use of arbitrary data types, such as are needed for many areas of computer vision research.<>},
keywords={Machine vision;Data structures;Software development environments},
doi={10.1109/CVPR.1994.323895},
ISSN={1063-6919},
month={June},}
@INPROCEEDINGS{5328797,
author={Laval, Jannik and Denier, Simon and Ducasse, Stephane and Bergel, Alexandre},
booktitle={2009 16th Working Conference on Reverse Engineering},
title={Identifying Cycle Causes with Enriched Dependency Structural Matrix},
year={2009},
volume={},
number={},
pages={113-122},
abstract={Dependency structure matrix (DSM) has been successfully applied to identify software dependencies among packages and subsystems. A number of algorithms were proposed to compute the matrix so that it highlights patterns and problematic dependencies between subsystems. However, existing DSM implementations often miss important information to fully support reengineering effort. For example, they do not clearly qualify and quantify problematic relationships, information which is crucial to support remediation tasks.In this paper we present enriched DSM (eDSM) where cells are enriched with contextual information about (i) the type of dependencies (inheritance, class reference...), (ii) the proportion of referencing entities, (iii) the proportion of referenced entities. We distinguish independent cycles and stress potentially simple fixes for cycles using coloring information. This work is language independent and has been implemented on top of the Moose reengineering environment. It has been applied to non-trivial case studies among which ArgoUML, and Morphic the UI framework available in two open-source Smalltalks, Squeak and Pharo. Solution to problems identified by eDSM have been performed and retrofitted in Pharo main distribution.},
keywords={Packaging;Open source software;Visualization;Application software;Software packages;Reverse engineering;Europe;Stress;Computer architecture;Linux;software visualization;reengineering;dependency structural matrix;package;dependency},
doi={10.1109/WCRE.2009.11},
ISSN={2375-5369},
month={Oct},}
@INPROCEEDINGS{977282,
author={Kilgore, R.A.},
booktitle={Proceeding of the 2001 Winter Simulation Conference (Cat. No.01CH37304)},
title={Open-source SML and Silk for Java-based, object-oriented simulation},
year={2001},
volume={1},
number={},
pages={262-268 vol.1},
abstract={Silk(R) and SML are software libraries of Java, C++, C# and VB.Net classes that support object-oriented, discrete-event simulation. SML/sup TM/ is a new open-source or "free" software library of simulation classes that enable multi-language development of complex, yet manageable simulations through the construction of usable and reusable simulation objects. These objects are usable because they express the behavior of individual entity-threads from the system object perspective using familiar process-oriented modeling within an object-oriented design supported by a general purpose programming language. These objects are reusable because they can be easily archived, edited and assembled using professional development environments that support multilanguage, cross-platform execution and a common component architecture. The article describes the fundamentals of designing and creating an SML or Silk model.},
keywords={Open source software;Java;Object oriented modeling;Assembly;Power system modeling;Software libraries;Computer languages;Computational modeling;Discrete event simulation;Software development management},
doi={10.1109/WSC.2001.977282},
ISSN={},
month={Dec},}
@INPROCEEDINGS{1467875,
author={Xiang Xue},
booktitle={10th IEEE International Conference on Engineering of Complex Computer Systems (ICECCS'05)},
title={A formal specification constructing tool for SOFL},
year={2005},
volume={},
number={},
pages={12-13},
abstract={The development of powerful software tools that apply and facilitate the use of formal notations and methodologies effectively has been crucial. This paper introduces a new software tool that fully supports the construction of SOFL specifications in a user-friendly manner. With this tool it would be helpful to construct a SOFL specification that consists of condition data flow diagrams and specification modules, as well as take advantage of build in features that improve the correctness and integrity of specifications.},
keywords={Formal specifications;Software tools;Formal languages;Software engineering;Petri nets;Flow graphs;Packaging;Proposals;Buildings;Guidelines},
doi={10.1109/ICECCS.2005.10},
ISSN={},
month={June},}
@INPROCEEDINGS{9708743,
author={Sun, Xu and Yu, Hao and Solvang, Wei Deng},
booktitle={2022 IEEE/SICE International Symposium on System Integration (SII)},
title={System Integration for Smart Reverse Logistics Management},
year={2022},
volume={},
number={},
pages={821-826},
abstract={To maximize the value and material recovery from waste products, smart reverse logistics aims at managing the complex flows of physical items, cash, data, and information. The effective management of these flows requires optimal decision making at strategic, tactical, and operational levels. To support the decision making, predictive, prescriptive, and descriptive analytics have been proved to be valuable at all three levels. However, because these analytical tools require different software packages, different coding languages, and different structures of data, the decision support for complex problems combining various analytical methods is usually an ad-hoc process and requires thus significant efforts. There is a lack of standardized solutions that comprise all the necessary modules for smart reverse logistics management. Thus, this paper proposes a conceptual framework with the purpose of guiding the next-generation system integration for smart reverse logistics management. It goes further with the design of six criteria for evaluating the integration maturity of a system. The initial concept is shown with existing software solutions through a case study in Norway, and several challenges are identified for future improvements.},
keywords={Software packages;Databases;Soft sensors;Decision making;Reverse logistics;System integration;Data models},
doi={10.1109/SII52469.2022.9708743},
ISSN={2474-2325},
month={Jan},}
@INPROCEEDINGS{9872951,
author={Ruberg, Priit and Meinberg, Erki and Ellervee, Peeter},
booktitle={2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)},
title={Software Parser and Analyser for Hardware Performance Estimations},
year={2022},
volume={},
number={},
pages={1-6},
abstract={In this paper, we conclude the work on a novel energy consumption and performance estimation methodology as we complete our toolchain with the development of a parser and an analyser. An embedded software estimation model is created by physical measurements and benchmarking of a hardware platform. To obtain the physical measurements, a specialised semiautomated process has been developed. Although, the model based estimations show promising results as the estimation error is low the estimation process for an arbitrary software has since been a manual labour. Therefore in this work we present a software parser and an analyser for a C-language source code that is also able to preprocess system level as well as custom libraries. Although some C-language parsers are freely available, our estimation methodology requires a more custom solution, as specific data must be obtained by the parser from the abstract syntax tree (AST). In addition to the parser, an analyser is presented in this work that is able to fuse data from both the parser and the software profiler in order to present the number of different atomic operations and the number of repetitions for each atomic operation in the software. Additionally, both the parser and the analyser could be used as standalone products for software assessment. As a result, the construction of the estimation toolchain is complete.},
keywords={Energy consumption;Codes;Estimation;Manuals;Switches;Syntactics;Hardware;C-parser;performance estimation;hardware;software;abstract syntax tree},
doi={10.1109/ICECET55527.2022.9872951},
ISSN={},
month={July},}
@INPROCEEDINGS{5564048,
author={Shufen Liu and Ji Liu and Xinjia Zhang},
booktitle={2010 3rd International Conference on Computer Science and Information Technology},
title={Design and Implementation of Examination Evaluation System with Multimedia Training Simulation in the background},
year={2010},
volume={8},
number={},
pages={226-230},
abstract={this paper analyzes and contrasts the development of modern general examination systems first. We make a summary of existing Examination Evaluation Systems and indicate the shortage that exists in them. Design and Implementation an Examination Evaluation System which is base on a certain type of equipment's Multimedia Emulation Repair Training System. Use Visual Studio 2003 as a platform to develop the Examination Evaluation System. This paper focuses on the characteristics and methods of one kind of Examination Evaluation System which for the purpose of simulation training.},
keywords={Libraries;examination system;multimedia simulation;training software},
doi={10.1109/ICCSIT.2010.5564048},
ISSN={},
month={July},}
@INPROCEEDINGS{138715,
author={HadjAlouane, N.B. and Chaar, J.K. and Naylor, A.W.},
booktitle={Systems Integration '90. Proceedings of the First International Conference on Systems Integration},
title={The design and implementation of the control and integration software of a flexible manufacturing system},
year={1990},
volume={},
number={},
pages={494-502},
abstract={The concepts of a methodology for designing and implementing the control and integration software of computer-integrated manufacturing systems are presented. The goal of this methodology is to build flexible and reusable software. Software flexibility is obtained by decoupling the process plan models from the factory floor model and by designing generic control algorithms. Reusability is achieved by building self-contained software/hardware components with general, possibility parametrized, interfaces. These reusable components can be used to populate manufacturing software libraries. Off-the-shelf components can then be assembled into manufacturing systems. Moreover, the interplay between simulated and actual hardware internals of software/hardware components is used as the basis of a testing strategy that performs offline simulation followed by incremental online testing. The application of the methodology to the design and implementation of the control and integration software of a prismatic machining cell is reported. A highly efficient implementation of this software has been carried out in the Ada programming language and is fully operational.<>},
keywords={Hardware;Design methodology;Software reusability;Software testing;Control systems;Computer integrated manufacturing;Production facilities;Floors;Algorithm design and analysis;Software algorithms},
doi={10.1109/ICSI.1990.138715},
ISSN={},
month={April},}
@INPROCEEDINGS{6836357,
author={Jaekel, Steffen and Stelzer, Martin and Herpel, Hans-Juergen},
booktitle={2014 IEEE Aerospace Conference},
title={Robust and modular on-board architecture for future robotic spacecraft},
year={2014},
volume={},
number={},
pages={1-11},
abstract={This paper presents a novel approach for future robotic spacecraft by utilizing a modular and robust software architecture based on the time and space partitioning (TSP) concept. Classic satellites are characterized by a strict separation between platform and payload subsystems, both in hardware resources as well as in control software. Novel space-robotic applications such as on-orbit servicing (OOS) feature dexterous robotic devices attached onto the satellite that impose a direct physical feedback on their floating base. Through the high degree of interdependencies, the whole satellite turns into a space robot. Hence, the robot becomes an integral part of the spacecraft itself and needs to be integrated into the existing control and operations approach. The developed embedded on-board framework represents a modular and robust control and communication environment that allows both classic satellite as well as real-time and autonomous robotic operations. The framework features an integral fault detection, isolation and recovery (FDIR) concept in order to prevent overall system shutdown upon single-point failure. Single software components reside in separate logical modules, i.e. partitions, in order to avoid resource violations. Upon critical failure, partitions can be restarted without detracting the rest of the system. By applying explicit time scheduling of partitions, system resources can be optimally distributed and deterministic behavior be achieved. Core system functionality has been implemented by ECSS-tested components that are configurable and thus re-usable over multiple missions. As demonstrator, a realistic on-orbit servicing simulation was set up that comprises autonomous target satellite capture and fault management. The presented architecture follows an integrated approach that is required for safely operating future robotic spacecraft. Through re-usability of software components, fewer resources for the implementation and verification process are required as only additional, mission-specific components need to be taken care of. Application developers can use the core functionality and communication API and concentrate on their own task at hand.},
keywords={Space vehicles;Satellites;Software;Aerospace electronics;Computer architecture;Manipulators},
doi={10.1109/AERO.2014.6836357},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{6104556,
author={Miura, Shin'ichi and Hanawa, Toshihiro and Boku, Taisuke and Sato, Mitsuhisa},
booktitle={2011 IFIP 9th International Conference on Embedded and Ubiquitous Computing},
title={XMCAPI: Inter-core Communication Interface on Multi-chip Embedded Systems},
year={2011},
volume={},
number={},
pages={397-402},
abstract={Multi-core processor technology has been applied to the processors in embedded systems as well as in ordinary PC systems. In multi-core embedded processors, however, a processor may consist of heterogeneous CPU cores that are not configured with a shared memory and do not have a communication mechanism for inter-core communication. MCAPI is a highly portable API standard for providing inter-core communication independent of the architecture heterogeneity. In this paper, we extend the current MCAPI to a multi-chip in a distributed memory configuration and propose its portable implementation, named XMCAPI, on a commodity network stack. With XMCAPI, the inter-core communication method for intra-chip cores is extended to inter-chip cores. We evaluate the XMCAPI implementation, xmcapi/ip, on a standard socket in a portable software development environment.},
keywords={Message systems;Multicore processing;Sockets;Embedded systems;IP networks;Program processors;Receivers;Hardware/software interfaces;Interprocessor communications;Distributed architectures;Parallel programming},
doi={10.1109/EUC.2011.78},
ISSN={},
month={Oct},}
@INPROCEEDINGS{17199,
author={Hong, S. and Maryanski, F.},
booktitle={Proceedings COMPSAC 88: The Twelfth Annual International Computer Software & Applications Conference},
title={Database design tool generation via software reusability},
year={1988},
volume={},
number={},
pages={361-368},
abstract={Describes the Data Model Compiler (DMC) project. The goal of the DMC is to generate automatically data-model and application-specific database system software. A component of the DMC, called SeaWeed, automatically generates conceptual database design tool software for specific data models using the software reusability approach. The technique of design reuse is used to derive the requirement specification of the software being generated, and the mechanism of code reuse is adopted to produce the necessary reusable software components. The authors present SeaWeed's software generation paradigm including the derivation of requirement specifications, the formal representation of design reuse, and the implementation and organization of the reusable software component library.<>},
keywords={Software reusability;Data models;Database systems;Software systems;Application software;Software design;Software tools;Relational databases;Object oriented databases;Object oriented modeling},
doi={10.1109/CMPSAC.1988.17199},
ISSN={},
month={Oct},}
@ARTICLE{6994333,
author={Kreutz, Diego and Ramos, Fernando M. V. and Veríssimo, Paulo Esteves and Rothenberg, Christian Esteve and Azodolmolky, Siamak and Uhlig, Steve},
journal={Proceedings of the IEEE},
title={Software-Defined Networking: A Comprehensive Survey},
year={2015},
volume={103},
number={1},
pages={14-76},
abstract={The Internet has led to the creation of a digital society, where (almost) everything is connected and is accessible from anywhere. However, despite their widespread adoption, traditional IP networks are complex and very hard to manage. It is both difficult to configure the network according to predefined policies, and to reconfigure it to respond to faults, load, and changes. To make matters even more difficult, current networks are also vertically integrated: the control and data planes are bundled together. Software-defined networking (SDN) is an emerging paradigm that promises to change this state of affairs, by breaking vertical integration, separating the network's control logic from the underlying routers and switches, promoting (logical) centralization of network control, and introducing the ability to program the network. The separation of concerns, introduced between the definition of network policies, their implementation in switching hardware, and the forwarding of traffic, is key to the desired flexibility: by breaking the network control problem into tractable pieces, SDN makes it easier to create and introduce new abstractions in networking, simplifying network management and facilitating network evolution. In this paper, we present a comprehensive survey on SDN. We start by introducing the motivation for SDN, explain its main concepts and how it differs from traditional networking, its roots, and the standardization activities regarding this novel paradigm. Next, we present the key building blocks of an SDN infrastructure using a bottom-up, layered approach. We provide an in-depth analysis of the hardware infrastructure, southbound and northbound application programming interfaces (APIs), network virtualization layers, network operating systems (SDN controllers), network programming languages, and network applications. We also look at cross-layer problems such as debugging and troubleshooting. In an effort to anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts and challenges of SDN. In particular, we address the design of switches and control platforms - with a focus on aspects such as resiliency, scalability, performance, security, and dependability - as well as new opportunities for carrier transport networks and cloud providers. Last but not least, we analyze the position of SDN as a key enabler of a software-defined environment.},
keywords={Control systems;IP networks;Virtualization;Software defined networking;Computer networks;Communication networks;Carrier-grade networks;dependability;flow-based networking;network hypervisor;network operating systems (NOSs);network virtualization;OpenFlow;programmable networks;programming languages;scalability;software-defined environments;software-defined networking (SDN)},
doi={10.1109/JPROC.2014.2371999},
ISSN={1558-2256},
month={Jan},}
@INPROCEEDINGS{927956,
author={Chen, C.-T. and Zhao, J. and Chen, Q.},
booktitle={2001 Proceedings. 51st Electronic Components and Technology Conference (Cat. No.01CH37220)},
title={A simulation study of simultaneous switching noise},
year={2001},
volume={},
number={},
pages={1102-1106},
abstract={This paper describes a new methodology for simultaneous switching noise (SSN) simulations by using a system level signal integrity (SI) analysis software, which is combinations of a quick full wave electromagnetic field solver for multiple-layer structure based on FDTD (Finite Difference Time Domain) and a circuit solver. The solution is based on the geometry, material, stack-up structure, and basic circuit information. The simultaneous switching noise issue is studied for two types of chipset packages-OLGA (Organic Land Grid Array) and WBGA (Wirebond Ball Grid Array)-with 40 drivers switching simultaneously. Different simulation conditions, such as with or without on-die interconnection model, different on-die decoupling capacitor values, are imposed during the simulations. Simultaneous switching noise (SSN) effects such as skew, signal overshoot, ring back, and power-ground voltage fluctuations, are obtained and compared. These data can be used for a design guideline specification or for package performance improvement purposes. It is believed that all these studies are very informative to chip and package analysis and design for high-speed system applications.},
keywords={Circuit noise;Circuit simulation;Packaging;Finite difference methods;Time domain analysis;Switching circuits;Electromagnetic interference;Noise level;Analytical models;Electromagnetic analysis},
doi={10.1109/ECTC.2001.927956},
ISSN={0569-5503},
month={May},}
@ARTICLE{9427497,
author={Rashid, Nasir and Khan, Siffat Ullah and Khan, Habib Ullah and Ilyas, Muhammad},
journal={IEEE Access},
title={Green-Agile Maturity Model: An Evaluation Framework for Global Software Development Vendors},
year={2021},
volume={9},
number={},
pages={71868-71886},
abstract={Agile methods are extensively adapted by software development organizations due to the competitive benefits it offers. In recent years global software development (GSD) projects practice agile methods as prominent methods to deliver the software in increments with utmost user satisfaction and affordable cost. Beside the use of agile methods, the software industry has also considered the green aspect of software, to be in line with the demands of the organizations and the world technological ecosystem. The green and sustainable feature of software should focus both the energy and resource efficiency key factors. This phenomenon of embedding the green flavor in software has emerged a new research area, green software engineering, that promises the development of eco-friendly software with minimum energy and use of less computing resources, to trim down the adverse effects on both society and environment. The principal objective of this research study is to design and develop a multi-level Green-Agile Maturity Model (GAMM) to assess the GSD vendors' agile maturity in terms of green software development. The model has been built in four phases. In phase I and II, systematic literature review (SLR) was performed to identify the success factors and risk factors that either supports or hinders the green and sustainable software development respectively by practicing the agile methods in GSD. The results have been validated from 106 relevant experts, dealing with agile and green software projects, through questionnaire survey. The experts' demographic represents 25 different countries. We also identified the industry practices through SLR and survey, to address our identified critical factors. Phase III of this research deals with development of the GAMM by categorizing the identified factors into seven Green-Agile maturity levels. A similar approach has been used in other models such as Capability Maturity Model Integration (CMMI), Implementation Maturity Model (IMM) and Software Outsourcing Vendors Readiness Model (SOVRM). In phase IV of this research, five case studies were conducted at GSD organizations, to evaluate the structure and efficacy of the GAMM, while as a major contribution, this paper presents our developed model, the GAMM, which aims to assess the green-agile maturity of the GSD vendors in terms of green and sustainable software development.},
keywords={Software;Green products;Organizations;Capability maturity model;Sustainable development;Computational modeling;Energy efficiency;Agile software development;green and sustainable software;green-agile maturity model (GAMM);global software development (GSD);agile methods},
doi={10.1109/ACCESS.2021.3079194},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{1049692,
author={Fill, T.S. and Gulak, P.G.},
booktitle={IEEE Workshop on Signal Processing Systems},
title={An assessment of VLSI and embedded software implementations for Reed-Solomon decoders},
year={2002},
volume={},
number={},
pages={99-102},
abstract={This paper examines Reed-Solomon time-domain and frequency-domain decoder implementations in both software and hardware. The focus was on designing area-efficient, low-power and low-complexity decoders suitable for today's moderate data-rate applications. Two decoder chips were designed using a synthesized standard cell library in a 0.18 /spl mu/m CMOS process, targeting a 160 Mbps decoding rate. The time-domain decoder was fabricated with a core area of 1.50 mm/sup 2/.},
keywords={Very large scale integration;Embedded software;Reed-Solomon codes;Decoding;Error correction;Time domain analysis;Digital video broadcasting;Hardware;Error correction codes;DSL},
doi={10.1109/SIPS.2002.1049692},
ISSN={1520-6130},
month={Oct},}
@INPROCEEDINGS{9122100,
author={Cao, Zijian and Zhang, Yong and Cao, Shukun and Zhao, Lin},
booktitle={2020 3rd International Conference on Electron Device and Mechanical Engineering (ICEDME)},
title={Construction of Computer-Aided Safety Analysis System for Amusement Facilities},
year={2020},
volume={},
number={},
pages={731-735},
abstract={The safety analysis and evaluation of amusement facilities has always been a major concern of the amusement equipment industry. This paper combines the cause of the amusement equipment accidents, the HAZOP analysis process, and the statistical analysis of accident cases over the years to form a computer-aided amusement equipment. security analysis system. This system is a safety analysis system in the field of amusement facilities. It is a software analysis system that integrates analysis-evaluation-management-inquiry. It not only includes the basic method of HAZOP analysis, but also includes error and accident analysis database, cause database, result database, and recommended measures. library, etc. This paper uses C # language, SQL Server and other tools to implement the construction of computer-assisted security analysis system. It can be used in the design, use, maintenance, safety analysis, evaluation and structural improvement of recreation facilities. At the same time, through the accumulation of data, a knowledge base for decision makers can be formed, which provides a good platform for further improvement of the safety of recreation facilities.},
keywords={Structured Query Language;Databases;Statistical analysis;Knowledge based systems;Maintenance engineering;Software;Safety;amusement facilities;HAZOP analysis;security analysis system;SQL Server},
doi={10.1109/ICEDME50972.2020.00172},
ISSN={},
month={May},}
@ARTICLE{8272351,
author={Chen, Chao-Chun and Hung, Min-Hsiung and Li, Po-Yi and Lin, Yu-Chuan and Liu, Yu-Yang and Cheng, Fan-Tien},
journal={IEEE Robotics and Automation Letters},
title={A Novel Automated Construction Scheme for Efficiently Developing Cloud Manufacturing Services},
year={2018},
volume={3},
number={3},
pages={1378-1385},
abstract={Cloud manufacturing (CMfg) has emerged as a next-generation manufacturing paradigm that has potential to revolutionize the manufacturing industry. In further promotion of CMfg, how to build CMfg services in an automatic and efficient manner is an essential and challenging subject. Currently, there is no literature addressing such issue. Aimed at facilitating rapid construction of CMfg services, this letter proposes a novel automated construction scheme for developing CMfg services, called Manufacturing Service Automated Construction Scheme (MSACS). First, we develop a three-phase workflow of MSACS to address the issues of how to construct CMfg services automatically using standalone software library package (SSLP). Next, we design a system architecture of MSACS to delineate how to implement MSACS. Then, we depict the designs of MSACS's core components. Finally, we apply MSACS to conduct industrial case studies to build the automatic virtual metrology cloud service and intelligent yield management cloud service for an intelligent manufacturing platform. Testing results demonstrate that MSACS can automatically construct the target CMfg services in a very efficient manner after uploading the required SSLPs. Thus, MSACS can significantly alleviate the burden of engineers in building CMfg services, and in turn can facilitate the promotion of CMfg.},
keywords={Manufacturing;Cloud computing;Graphical user interfaces;Libraries;Web servers;Intelligent and flexible manufacturing;middleware and programming environments;cloud manufacturing service;fast automated construct scheme},
doi={10.1109/LRA.2018.2799420},
ISSN={2377-3766},
month={July},}
@ARTICLE{4112130,
author={Waclo, J. B. and Roslund, C. J.},
journal={IEEE Transactions on Power Apparatus and Systems},
title={Software Developement Experiences in a Nuclear Safety System Environment},
year={1983},
volume={PAS-102},
number={6},
pages={1706-1711},
abstract={This paper deals with the development of micro-computer software for Nuclear Safety Systems. More specifically, it describes the Software Design and Verification process which was followed for a Class 1E safety grade system.},
keywords={Software safety;Software design;Programming profession;Microcomputers;Application software;Guidelines;Software libraries;Power engineering and energy;Density measurement;Fluctuations},
doi={10.1109/TPAS.1983.317909},
ISSN={0018-9510},
month={June},}
@INPROCEEDINGS{8990885,
author={Croitoru, B. S. M. and Tulbure, A. and Filip, A. I.},
booktitle={2019 IEEE 25th International Symposium for Design and Technology in Electronic Packaging (SIITME)},
title={Developing Software-Based Plug&Play Capabilities for Analog Sensors over a Network Using a Microcontroller Development Board},
year={2019},
volume={},
number={},
pages={90-93},
abstract={The present paper describes a standard C algorithm (mathematical equations + software implementation) for making analog sensors Plug & Play over TCP/IP - Ethernet protocol. This algorithm represents a beginning step for creating a prototype of smart transducer system according to IEEE 1451 family of standards. The sensors are connected to the Analog Input Ports of a microcontroller (MCU) development board. The standard C program running on the microcontroller will automatically detect the connected sensors and will send a list of sensor information over TCP/IP - Ethernet to a remote location. The MCU algorithm is able to detect when a sensor is connected to any of its I/O Analog Ports by monitoring some external and internal parameters like: the default I/O port voltage value, the voltage value of a port when a sensor is connected to that port, the influence between analog ports when connecting a sensor to a port. The microcontroller development board is partially programmed to be an HTML Web Server. In a Web Browser will be displayed the status of all Analog Input Ports. When a sensor is detected, a text file containing sensor data will be created on a local micro-SD card (data logging capabilities). The sensor data can be accessed through a Web Browser by using the IP address of the Web Server.},
keywords={plug&play;sensors;network;algorithm;microcontroller},
doi={10.1109/SIITME47687.2019.8990885},
ISSN={2642-7036},
month={Oct},}
@INPROCEEDINGS{4662656,
author={Goodman, Ronald and Black, Scott},
booktitle={2008 IEEE AUTOTESTCON},
title={Design challenges for realization of the advantages of embedded multi-core processors},
year={2008},
volume={},
number={},
pages={447-452},
abstract={The computer industry is undergoing a continuing paradigm shift from ever increasingly faster single-core processor systems to the hyper-threaded and multi-core systems that we are seeing today. To continue leveraging the advantage of these systems, the programmers must also undergo a paradigm shift in the way that they design and develop software for these systems. The availability of additional cores and threads does not in itself guarantee increased performance, and in some cases may actually impede it. Concurrency, a software term for using resources at the same time, is the most important factor in achieving optimum performance in today's computing systems. Multi-core systems provide parallelism in addition to concurrency by providing additional processing elements (CPUs) that allow multiple threads to run simultaneously. This comes at a cost though, because the threads must be synchronized with the overall program flow. This paper discusses the reasoning behind the successful design of a multiprocessor program, the relationship between multi-core architectures and program performance, and provides several techniques for implementing synchronization and coordination methods without any special tools or packages.},
keywords={Magnetic cores;Program processors;Operating systems;Parallel processing;Switches;Concurrent computing;System recovery;multi-core;multithreaded;multitasking;multiprocessing;embedded software parallelism},
doi={10.1109/AUTEST.2008.4662656},
ISSN={1558-4550},
month={Sep.},}
@INPROCEEDINGS{863662,
author={Milton, C.E. and Russell, C.D. and Schroeder, J.},
booktitle={Gateway to the New Millennium. 18th Digital Avionics Systems Conference. Proceedings (Cat. No.99CH37033)},
title={Technical architecture for RF open system realization},
year={1999},
volume={2},
number={},
pages={9.A.3-9.A.3},
abstract={RF functions can be effectively realized as open systems. Application of open system architecture (OSA) principles must be done at the function level, encompassing both software and hardware. Building upon the generic open architecture foundation, the additional layers necessary for RF function realization have been defined. The RF technical architecture is described with reference model that identifies the functional partitioning and key interfaces that embody the OSA approach. Realization of these key interfaces is described, and an example integrated sensor system application presented. This technical architecture approach is described in a formal draft specification that has been prepared for the OS-JTF to provide guidelines to developers of RF open systems.},
keywords={Radio frequency;Open systems;Computer architecture;Application software;Hardware;Radiofrequency identification;Systems engineering and theory;Stress;Government;Design engineering},
doi={10.1109/DASC.1999.863662},
ISSN={},
month={Oct},}
@INPROCEEDINGS{266620,
author={Shore, J.},
booktitle={International Conference on Acoustics, Speech, and Signal Processing,},
title={An extensible file system for signal processing software},
year={1989},
volume={},
number={},
pages={1083-1086 vol.2},
abstract={The author describes the file system that was developed for the Entropic Signal Processing System (ESPS), a UNIX-based software package that supports speech and signal processing research and development. He discusses the major goals of the ESPS file system, namely, that it be efficient, that it fit well with UNIX, that it should maintain a history of parameters and processing steps, that users should be able to modify existing file types and introduce new types without having to rewrite existing programs, and that the file system should facilitate distributed computation on UNIX networks. He then describes the design and implementation of the ESPS file system with emphasis on the foregoing goals and on the use of modern software engineering techniques. He closes with a description of desirable additions and generalizations.<>},
keywords={File systems;Signal processing;Electrostatic precipitators;Software packages;Speech processing;Research and development;History;Computer networks;Distributed computing;Software engineering},
doi={10.1109/ICASSP.1989.266620},
ISSN={1520-6149},
month={May},}
@ARTICLE{663784,
author={Maiden, N.A. and Ncube, C.},
journal={IEEE Software},
title={Acquiring COTS software selection requirements},
year={1998},
volume={15},
number={2},
pages={46-56},
abstract={Commercial off the shelf software can save development time and money if you can find a package that meets your customer's needs. The authors propose a model for matching COTS product features with user requirements. To support requirements acquisition for selecting commercial off the shelf products, we propose a method we used recently for selecting a complex COTS software system that had to comply with over 130 customer requirements. The lessons we learned from that experience refined our design of PORE (procurement oriented requirements engineering), a template based method for requirements acquisition. We report 11 of these lessons, with particular focus on the typical problems that arose and solutions to avoid them in the future. These solutions, we believe, extend state of the art requirements acquisition techniques to the component based software engineering process.},
keywords={Software tools;Software engineering;Design engineering;Systems engineering and theory;Testing;Software packages;Packaging;Guidelines;Iterative methods;Software systems},
doi={10.1109/52.663784},
ISSN={1937-4194},
month={March},}
@INPROCEEDINGS{1181515,
author={Aaltonen, T. and Mikkonen, T.},
booktitle={Eighth IEEE International Conference on Engineering of Complex Computer Systems, 2002. Proceedings.},
title={Managing software evolution with a formalized abstraction hierarchy},
year={2002},
volume={},
number={},
pages={224-231},
abstract={Complex computer systems are seldom made from scratch but they contain significant amounts of legacy code, which then is under continuous pressure for evolution. Therefore, a need for a rigorous method for managing evolution in this setting is evident. We propose a management method for reactive and distributed systems. The method is based on creating a formal abstraction hierarchy to model the system with abstractions that exceed those that are used as implementation facilities. This hierarchy is then used to assess the cost of a modification by associating the modification to appropriate abstractions in the hierarchy and by determining the abstractions that need to be revisited to retain the hierarchy consistent.},
keywords={Switches;Computer architecture;Costs;Software quality;Software architecture;Packaging;Computer languages;Software engineering;Robustness;Software design},
doi={10.1109/ICECCS.2002.1181515},
ISSN={},
month={Dec},}
@INPROCEEDINGS{648054,
author={Tso, K.S. and Shokri, E.H. and Dziegiel, R.J.},
booktitle={Proceedings 1997 High-Assurance Engineering Workshop},
title={ReSoFT: a reusable testbed for development and evaluation of software fault-tolerant systems},
year={1997},
volume={},
number={},
pages={149-154},
abstract={The Reusable Software Fault-tolerance Testbed (ReSoFT) has been developed to facilitate the development and evaluation of high-assurance systems that require tolerance of both hardware and software faults. Central to ReSoFT is a library of reusable software components from which a wide variety of software fault tolerance (SWFT) techniques can be utilized to construct highly dependable systems. The reusable components include: (1) SWFT executive components, (2) SWFT support components, (3) SWFT interface components, (4) fault-tolerant network communication components, and (5) fault-injection components. A set of graphical tools are also provided to build, monitor and test the SWFT systems. The ReSoFT testbed is developed and hosted on a network of Sun workstations running the standard Solaris operating system. The workstations are connected with dual-redundant networks to tolerate communication faults. To ensure effective reuse, object-oriented analysis and design based on the Booch method have been used to develop the reusable components. The components were implemented in Ada 95 to take advantage of its new object-oriented and real-time support features. The graphical tools were implemented in Java which provides object-oriented and platform-independent features.},
keywords={Software reusability;System testing;Fault tolerant systems;Workstations;Software testing;Hardware;Software libraries;Fault tolerance;Monitoring;Sun},
doi={10.1109/HASE.1997.648054},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9494557,
author={Sharma, Deepak and Gupta, Prashant K. and Andreu-Perez, Javier and Mendel, Jerry M. and López, Luis Martínez},
booktitle={2021 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
title={A Python Software Library for Computing with Words and Perceptions},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Computing with Words (CWW) methodology has been used to design intelligent systems which make decisions by manipulating the linguistic information, like human beings. Human beings naturally understand (and express) themselves linguistically, and hence can reason (and make decision) just with linguistic information without any numerical measure. Perceptual Computing makes use of type 2 fuzzy sets for modeling the words in the CWW paradigm. This use of type-2 fuzzy sets enables better representation of the inherent uncertainty in the fuzzy linguistic semantics on numerous problems. To realise the potential of Perceptual Computing, its MATLAB implementation has been made freely available to the end-users/ researchers, and MATLAB is a proprietary development environment. Therefore, this contribution aims at proposing a python implementation of the Perceptual Computing, or its main processing element the perceptual computer that consists of three components viz., encoder, CWW engine and decoder. Our python implementation provides the end user with a seamless blending amongst all three components, which does not exist yet, to the best of our knowledge.},
keywords={Fuzzy sets;Uncertainty;Software libraries;Semantics;Linguistics;Numerical models;Intelligent systems;Computing with Words;Fuzzy Sets;Interval Approach;Perceptual Computing;Python toolbox},
doi={10.1109/FUZZ45933.2021.9494557},
ISSN={1558-4739},
month={July},}
@INPROCEEDINGS{1690236,
author={Grassi, S. and Barrett, S.},
booktitle={International Conference on Autonomic and Autonomous Systems (ICAS'06)},
title={Dynamic Architecture Adaptation in WS Environment},
year={2006},
volume={},
number={},
pages={26-26},
abstract={Coordination research aims to increase flexibility in software by constructing software from autonomous functional components, assembled and allowed to interact according to a separate and distinct coordination specification. Concepts of coordination and orchestration are increasingly included in standards for Web Services. Moreover, semantic WS specifications have emerged as the basis for automatic composition of services. In this paper we apply a coordination approach to the construction of web services that enables clients to specify substantial adaption of web service behavior, in order to better integrate with client requirements. We illustrate by way on a simple example how this approach can be practically applied and propose platform support for dynamic runtime adaption of web services.},
keywords={Books;Software libraries;Engines;Web services;Educational institutions;Service oriented architecture;Computer architecture;Software systems},
doi={10.1109/ICAS.2006.24},
ISSN={2168-1872},
month={July},}
@INPROCEEDINGS{8719429,
author={Chi, Shuqi and Li, Shanshan and Guo, Yong and Dong, Wei and Jia, Zhouyang and He, Haochen and Liao, Qing},
booktitle={2018 25th Asia-Pacific Software Engineering Conference (APSEC)},
title={NotOnlyLog: Mining Patch-Log Associations from Software Evolution History to Enhance Failure Diagnosis Capability},
year={2018},
volume={},
number={},
pages={189-198},
abstract={Log messages are widely used in the diagnosis of software failures. Existing studies of failure diagnosis based on log messages tend to use rule-based methods or execution-path-based methods. Rule-based methods generate bug-fixing rules using either human expertise, which is time consuming, or machine learning methods, which may lack the precision of failure diagnosis. To remedy these problems, researchers propose execution-path-based methods that reconstruct execution paths by analyzing source code and run-time logs. These methods, however, may lead to path explosion. To fill this gap, our work focuses on solving the path explosion problem in execution-path-based methods. We assume that run-time logs may have a relationship with their corresponding patches in real-world bug reports. We conduct empirical studies on seven open-source software packages and obtain two findings: (1) 80% of similar bugs have similar patches, and (2) 70% of faulty code is found to lie near the code where the first failure message is printed. Based on these two observations, we design and implement a practical tool NotOnlyLog for bug diagnosis. NotOnlyLog is able to mine the relationships between failure logs and their corresponding patches, in order to reduce both the number and length of uncertain execution paths in bug diagnosis. We evaluate the performance of NotOnlyLog on nine real-world bugs from three large open-source projects. Our experimental results show that, compared with SherLog, NotOnlyLog can achieve a reduction of 86.9% in the number of execution paths.},
keywords={Computer bugs;Open source software;Data mining;Explosions;Feature extraction;History;Bug Diagnosis, Software Evolution, Log},
doi={10.1109/APSEC.2018.00033},
ISSN={2640-0715},
month={Dec},}
@INPROCEEDINGS{8540737,
author={Abaceoae, Constantin and Postolache, Mihai},
booktitle={2018 22nd International Conference on System Theory, Control and Computing (ICSTCC)},
title={Design and Implementation of a CAN-USB Interface for Networked Embedded Systems},
year={2018},
volume={},
number={},
pages={123-128},
abstract={Controller Area Network (CAN) is the most used protocol for intra-vehicle communication between Electronic Control Units (ECUs) for decades. Moreover, there are several implementations of industrial networks built on top of CAN, (i.e. CANopen and DeviceNet) that expanded even more its area of application to almost any industrial automation field. The growing needs for data in today's modern and safe applications led to CAN Flexible Data Rate (CAN FD) in order to increase the network throughput and pushed the data field of the CAN frames beyond the 1Mbps limit of the high speed CAN chips. A low cost CAN-USB interface application for dual CAN bus network monitoring, diagnose and maintenance is proposed which can be easily ported on any member of the ARM Cortex-M microcontroller family with built-in CAN or CAN-FD communication.},
keywords={Universal Serial Bus;Microcontrollers;Task analysis;Message systems;Libraries;Microprogramming;Microsoft Windows;Controller Area Network;CAN-USB adapter;embedded software application},
doi={10.1109/ICSTCC.2018.8540737},
ISSN={2372-1618},
month={Oct},}
@ARTICLE{1327592,
author={Seinstra, F.J. and Koelma, D. and Bagdanov, A.D.},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Finite state machine-based optimization of data parallel regular domain problems applied in low-level image processing},
year={2004},
volume={15},
number={10},
pages={865-877},
abstract={A popular approach to providing nonexperts in parallel computing with an easy-to-use programming model is to design a software library consisting of a set of preparallelized routines, and hide the intricacies of parallelization behind the library's API. However, for regular domain problems (such as simple matrix manipulations or low-level image processing applications-in which all elements in a regular subset of a dense data field are accessed in turn) speedup obtained with many such library-based parallelization tools is often suboptimal. This is because interoperation optimization (or: time-optimization of communication steps across library calls) is generally not incorporated in the library implementations. We present a simple, efficient, finite state machine-based approach for communication minimization of library-based data parallel regular domain problems. In the approach, referred to as lazy parallelization, a sequential program is parallelized automatically at runtime by inserting communication primitives and memory management operations whenever necessary. Apart from being simple and cheap, lazy parallelization guarantees to generate legal, correct, and efficient parallel programs at all times. The effectiveness of the approach is demonstrated by analyzing the performance characteristics of two typical regular domain problems obtained from the field of low-level image processing. Experimental results show significant performance improvements over nonoptimized parallel applications. Moreover, obtained communication behavior is found to be optimal with respect to the abstraction level of message passing programs.},
keywords={Image processing;Parallel processing;Parallel programming;Software design;Software libraries;Runtime;Memory management;Communication system operations and management;Law;Legal factors;Parallel processing;data communications aspects;optimization;image processing software.},
doi={10.1109/TPDS.2004.55},
ISSN={1558-2183},
month={Oct},}
@INPROCEEDINGS{1199400,
author={Ojima, Y. and Sato, M. and Harada, H. and Ishikawa, Y.},
booktitle={CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.},
title={Performance of cluster-enabled OpenMP for the SCASH software distributed shared memory system},
year={2003},
volume={},
number={},
pages={450-456},
abstract={OpenMP has attracted widespread interest because it is an easy-to-use parallel programming model for shared memory multiprocessor systems. Implementation of a "cluster-enabled" OpenMP compiler is presented. Compiled programs are linked to the page-based software distributed-shared-memory system, SCASH, which runs on PC clusters. This allows OpenMP programs to be run transparently in a distributed memory environment. The compiler converts programs written for OpenMP into parallel programs using the SCASH static library, moving all shared global variables into SCASH shared address space at runtime. As data mapping has a great impact on the performance of OpenMP programs compiled for software distributed-shared-memory, extensions to OpenMP directives are defined for specifying data mapping and loop scheduling behavior, allowing data to be allocated to the node where it is to be processed. Experimental results of benchmark programs on PC clusters using both Myrinet and fast Ethernet are reported.},
keywords={Software performance;Software systems;Ethernet networks;Communication system software;Parallel programming;Multiprocessing systems;Software libraries;Runtime;Workstations;Message passing},
doi={10.1109/CCGRID.2003.1199400},
ISSN={},
month={May},}
@INPROCEEDINGS{514713,
author={Harris, D.R. and Reubenstein, H.B. and Yeh, A.S.},
booktitle={Proceedings of 2nd Working Conference on Reverse Engineering},
title={Recognizers for extracting architectural features from source code},
year={1995},
volume={},
number={},
pages={252-261},
abstract={Architectural representation can play a pivotal role throughout the life cycle of any software program. In particular, we are interested in the role it plays in the maintenance/evolution of legacy programs. During these phases, analysts often describe programs using architectural terminology (e.g., "interfaces", "interprocess communication", "layers", "objects"). Our research and development goals center on supporting such activities through architectural recovery tools that are based on reverse engineering technology. These tools start with existing source code and extract architecture-level descriptions. We have implemented a framework for architectural recovery and our experience leads us to several observations about the representational needs of a library that is populated with families of architecture recognition rules. This paper characterizes the kinds of recognizers we have developed and describes an approach for rule parameterization and retrieval.},
keywords={Feature extraction;Software maintenance;Software libraries;Computer architecture;Reverse engineering;Indexing;Terminology;Research and development;Character recognition;Maintenance engineering},
doi={10.1109/WCRE.1995.514713},
ISSN={},
month={July},}
@INPROCEEDINGS{1656860,
author={D'Errico, J. and Wei Qin},
booktitle={Proceedings of the Design Automation & Test in Europe Conference},
title={Constructing Portable Compiled Instruction-set Simulators-An ADL-driven Approach},
year={2006},
volume={1},
number={},
pages={1-6},
abstract={Instruction set simulators are common tools used for the development of new architectures and embedded software among countless other functions. This paper presents a framework that quickly generates fast and flexible instruction-set simulators from a specification based on a C-like architecture-description language. The framework provides a consistent platform for constructing and evaluating different classes of simulators, including interpreters, static-compiled simulators, and dynamic-compiled simulators. The framework also features a new construction method for dynamic-compiled simulator that involves no low-level programming. It profiles and translates frequently executed regions of simulated binary to C++ code and invokes GCC to compile such code into dynamically loaded libraries, which are then loaded into the simulator at run time to accelerate simulation. Our experimental results based on the MIPS architecture and the SPEC CPU2000 benchmarks show that our dynamic-compiled simulator is capable of achieving up to 11 times speedup compared to our fast interpreter. Compared to other dynamic-compiled simulators requiring significant system programming expertise to construct, the proposed approach is simpler to implement and more portable.},
keywords={Computational modeling;Decoding;Runtime;Computer architecture;Dynamic programming;Libraries;Computer simulation;Embedded software;Acceleration;Software design},
doi={10.1109/DATE.2006.244006},
ISSN={1558-1101},
month={March},}
@INPROCEEDINGS{885156,
author={Tewissen, F. and Baloian, N. and Hoppe, U. and Reimberg, E.},
booktitle={Proceedings Sixth International Workshop on Groupware. CRIWG 2000},
title={"MatchMaker": synchronising objects in replicated software-architectures},
year={2000},
volume={},
number={},
pages={60-67},
abstract={The authors present an approach and an existing implementation to support the object-wise synchronisation of general software entities. The software toolkit "MatchMaker" allows for synchronising already existing software applications by plugging in transparent event listener mechanisms that distribute information via a central server to other remote applications. Based on the original approach that was presented in 1995, the current implementation of "MatchMaker" serves as the communication basis in real world applications of three computer-integrated classrooms in Europe. Current developments are oriented towards the integration of promising technologies in the field of distributed computing. The main goal of "MatchMaker" is the provision of a powerful yet easily applicable high-level API for synchronising distributed objects.},
keywords={Application software;Collaborative software;User interfaces;Distributed computing;Software libraries;Problem-solving;Collaborative work;Java;Software tools;Computer applications},
doi={10.1109/CRIWG.2000.885156},
ISSN={},
month={Oct},}
@INPROCEEDINGS{762596,
author={Fairley, R.E.},
booktitle={COMPSAC 79. Proceedings. Computer Software and The IEEE Computer Society's Third International Applications Conference, 1979.},
title={Software development tools},
year={1979},
volume={},
number={},
pages={763-763},
abstract={Software development tools include pre-imple mentation tools for automated analysis and design of software, post-implementation tools for auto mated verification and validation of software, and the familiar implementation tools such as compilers, text editors, loaders, and diagnostic packages.},
keywords={Programming;Software tools;Computer science;Costs;Mathematics;Laboratories;Management information systems;Software design;Software packages;Packaging},
doi={10.1109/CMPSAC.1979.762596},
ISSN={},
month={Nov},}
@INPROCEEDINGS{622361,
author={Topcuoglu, H. and Hariri, S. and Furmanski, W. and Valente, J. and Ra, I. and Kim, D. and Kim, Y. and Bing, X. and Ye, B.},
booktitle={Proceedings. The Sixth IEEE International Symposium on High Performance Distributed Computing (Cat. No.97TB100183)},
title={The software architecture of a virtual distributed computing environment},
year={1997},
volume={},
number={},
pages={40-49},
abstract={The requirements of grand challenge problems and the deployment of gigabit networks makes the network computing framework an attractive and cost effective computing environment with which to interconnect geographically distributed processing and storage resources. Our project, Virtual Distributed Computing Environment (VDCE), provides a problem-solving environment for high-performance distributed computing over wide area networks. VDCE delivers well-defined library functions that relieve end-users of tedious task implementations and also support reusability. In this paper we present the conceptual design of VDCE software architecture, which is defined in three modules: (a) the Application Editor, a user-friendly application development environment that generates the Application Flow Graph (AFG) of an application; (b) the Application Scheduler, which provides an efficient task-to-resource mapping of AFG; and (c) the VDCE Runtime System, which is responsible for running and managing application execution and monitoring the VDCE resources.},
keywords={Software architecture;Distributed computing;Application software;Computer networks;Costs;Distributed processing;Problem-solving;Wide area networks;Software libraries;Software design},
doi={10.1109/HPDC.1997.622361},
ISSN={1082-8907},
month={Aug},}
@INPROCEEDINGS{7024285,
author={Rodrigues, Romulo and Sampaio, Rafael C.B. and Aguiar, A. Pedro and Becker, Marcelo},
booktitle={2014 Joint Conference on Robotics: SBR-LARS Robotics Symposium and Robocontrol},
title={FVMS Software-in-the-Loop Flight Simulation Experiments: Guidance, Navigation and Control},
year={2014},
volume={},
number={},
pages={223-228},
abstract={This paper proposes a new and powerful methodology to the evaluation of guidance, navigation and control algorithms (GNC) in Software-in-the-Loop (SiL) flight simulation using Microsoft Flight Simulator (MSFS). The SiL was assisted by the Flight Variables Management System (FVMS), a Graphic User Interface (GUI) that fully interfaces communication between MSFS and general purpose custom GNC algorithms. The originality of this new approach is to make the FVMS communication layer completely transparent to the designer so that full attention may be focused exclusively on guidance algorithm development and the debugging process as well. Furthermore, the application may be extended to both multi-engine fixed and rotary wing aircraft. When it comes to the design, development and validation of brand new control algorithms of GNC for unmanned systems, SiL flight simulation becomes an exceedingly useful tool since end-product may misbehave in-flight. It impacts over avoiding hazard situation of crew and population in the ground and on preserving expensive equipment of being damaged. To illustrate FVMS capabilities and assets on GNC systems design, a nonlinear path following algorithm is set up. FVMS GNC module is endowed with a full map interface and a mission management through which one may build/rebuild the UAV path on-line. The results demonstrate the potential of the framework on the implementation of either simple or more complex solutions for the GNC problem.},
keywords={Vehicles;Libraries;Navigation;Aircraft;Algorithm design and analysis;Computer architecture;Vehicle dynamics;Aerial Robotics;Guidance;Navigation;Control;Flight Simulation},
doi={10.1109/SBR.LARS.Robocontrol.2014.48},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7777284,
author={Dobre, Robert Alexandru and Elisei-Iliescu, Cameila and Paleologu, Constantin and Negrescu, Cristian and Stanomir, Dumitru},
booktitle={2016 IEEE 22nd International Symposium for Design and Technology in Electronic Packaging (SIITME)},
title={Robust audio forensic software for recovering speech signals drowned in loud music},
year={2016},
volume={},
number={},
pages={232-235},
abstract={Audio evidence, when accepted by the court, can decide the final verdict in a trial. In order to be evaluated, these materials must be authenticated, but also the intelligibility of the message must be undoubtable. Two main categories of multimedia forensics solve these problems: content authentication and noise reduction. The application presented in this paper is part of the latter category. In order to conceal a conversation, the first action that comes into mind is also the easiest one: turn loud a nearby audio source. Since the most available audio sources play musical materials, if a microphone was placed in the room, it would record the speech signal heavily masked by music. A classical adaptive filtering method could be applied to recover the speech only if the speakers and the musical source remain perfectly still or, in other words, the acoustic environment does not change in time. This ideal situation is not to be found very often in real situations. This paper presents a method for recovering speech signals masked by loud music that is robust to acoustic environment variations. The method is thoroughly described, tested, and compared with a solution based on the recursive least-squares (RLS) adaptive algorithm using a variable forgetting factor.},
keywords={Adaptive filters;Speech;Music;Filtering algorithms;Multiple signal classification;Finite impulse response filters;multimedia forensics;adaptive filters;recursive least-squares (RLS) algorithm},
doi={10.1109/SIITME.2016.7777284},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9435773,
author={Belova-Plonienė, Diana and Katkevičius, Andrius},
booktitle={2020 IEEE 8th Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE)},
title={Analysis of Frequency Characteristics of Meander Structures with Different Connecting Electrodes},
year={2021},
volume={},
number={},
pages={1-4},
abstract={Meander structures are often used in microwave devices because of small dimensions and positive features. The features of the meander structures like passband, characteristic impedance, delay time and others could be adjusted by using different materials or structures of the meander conductor. The construction of the connecting electrodes of the meander conductor has a significant impact to the operation of the meander structure. The frequency characteristics of the planar and hybrid meander structures are calculated using the method of moment (MoM) in the Sonnet® software package. The created meander structure with different connecting electrodes are lossless. The results of passband, input impedance, delay time and electric field distribution are discussed. Different sets of design parameters are presented in order to obtain the same electrical characteristics.},
keywords={Electrodes;Inductance;Spirals;Fluctuations;Conductors;Delays;Passband;hybrid structures;meander structures;method of moments;frequency characteristics},
doi={10.1109/AIEEE51419.2021.9435773},
ISSN={2689-7342},
month={April},}
@INPROCEEDINGS{5440093,
author={Sudhakar, P. and Valli, S.},
booktitle={2010 International Conference on Innovative Computing Technologies (ICICT)},
title={Design rationale to source graph [DRG] approach for developing Legacy Code Conversion Kit (LCCK)},
year={2010},
volume={},
number={},
pages={1-5},
abstract={Due to the prominent improvements in the present software engineering, conversion from one programming language to another programming language becomes important task of the industry. Industrial survey shows that major components of development cost of all software goes to maintaining and updating the system software or application package for meeting the current scenario and / or user's satisfaction. In this paper, proposed a Software Development tool (SDT) called `Legacy Code Conversion Kit (LCCK)' for conversion of one object oriented programming language (Source Language) to another object oriented programming language (Destination Language). Design Rationale to Source Graph (DR-SG) is our proposed model that formed a graph from Design Pattern documentation and linked to a source code base. The DR-SG allows developers to trace design concepts through design documentation. This proposed work, completely and confidently satisfying high-level design goals when performing software change tasks. The result of our implementation, from C++ to Java conversion is shown in the chapters.},
keywords={Computer languages;Computer industry;Software maintenance;Object oriented programming;Documentation;Software engineering;Costs;System software;Application software;Software packages;Software Engineering;Mitigation;Legacy code;Code conversion},
doi={10.1109/ICINNOVCT.2010.5440093},
ISSN={},
month={Feb},}
@ARTICLE{5473172,
author={},
journal={IEEE Std 1666 IEC61691-7 Edition 1.0 2009-12},
title={Behavioural languages - Part 7: SystemC Language Reference Manual},
year={2009},
volume={},
number={},
pages={1-447},
abstract={SystemC® is defined in this standard. SystemC is an ANSI standard C++ class library for system and hardware design for use by designers and architects who need to address complex systems that are a hybrid between hardware and software. This standard provides a precise and complete definition of the SystemC class library so that a SystemC implementation can be developed with reference to this standard alone. The primary audiences for this standard are the implementors of the SystemC class library, the implementors of tools supporting the class library, and users of the class library.},
keywords={IEEE standards;Electronic mail;Licenses;Scheduling algorithm;System-on-a-chip;Embedded computing;61691-7:2009;1666-2005;C++;computer languages;digital systems;discrete event simulation;electronic design automation;electronic systems;electronic system level;embedded software;fixed-point;hardware description language;hardware design;hardware verification;SystemC;system modeling;system-on-chip;transaction level},
doi={10.1109/IEEESTD.2009.5473172},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6188173,
author={Wei, Dong and Jing, Zhang and Xu, Chen},
booktitle={2012 International Conference on Computer Science and Electronics Engineering},
title={The Grid Parallel Computing in Information Retrieval Research and Application},
year={2012},
volume={3},
number={},
pages={89-93},
abstract={This paper describes in detail construction of The Grid Parallel Computing of books and documents, system solves the problems and methods, as well as design to realization of MDS module. Scientific data grid software adopt SOA, through the standardization of metadata and metadata-based resource discovery to make users can be achieved uniform access to distributed heterogeneous data resources in two phases of query.},
keywords={Distributed databases;Books;Software;Libraries;Catalogs;Grid;Information Retrieval;Metadata;MDS},
doi={10.1109/ICCSEE.2012.421},
ISSN={},
month={March},}
@INPROCEEDINGS{758431,
author={Anjum, F. and Caruso, F. and Jain, R. and Missier, P. and Zordan, A.},
booktitle={1999 IEEE Second Conference on Open Architectures and Network Programming. Proceedings. OPENARCH '99 (Cat. No.99EX252)},
title={ChaiTime: a system for rapid creation of portable next-generation telephony services using third-party software components},
year={1999},
volume={},
number={},
pages={22-31},
abstract={We present the architecture, design and experimental research prototype implementation of ChaiTime, an open system architecture for the rapid development of advanced next generation telephony services that overcomes some of the limitations of the current closed PSTN architecture and service model. ChaiTime allows communication sessions to be set up over the PSTN, the Internet, or a combination of both. Services can be provided by multiple cooperating distributed service providers, some of whom may use third party software components which can be "plugged in" or even dynamically downloaded from the network as needed. This allows advanced services to be deployed and delivered to users rapidly; a crucial requirement in the increasingly competitive telecommunications services marketplace. ChaiTime is built upon an object oriented call model called Java Call Control (JCC) which we have defined as a small set of extensions to the standard Java Telephony API (JTAPI) call model that allows support for distributed providers as well as advanced services. JCC hides details of underlying call state management, protocols and hardware from applications. In our prototype, we have designed a small set of extensions to SIP, called Extended SIP, for supporting advanced services. The ChaiTime prototype software is currently operational in our laboratory. We briefly describe its current implementation as well as future work to address issues such as fault tolerance.},
keywords={Object oriented modeling;Prototypes;Java;Software prototyping;Open systems;Internet telephony;Computer architecture;Telecommunication services;Telecommunication control;Protocols},
doi={10.1109/OPNARC.1999.758431},
ISSN={},
month={March},}
@INPROCEEDINGS{971869,
author={Wang Shuhong and Li Qingfu and Qiu Jie and Shi Shan},
booktitle={ICEMS'2001. Proceedings of the Fifth International Conference on Electrical Machines and Systems (IEEE Cat. No.01EX501)},
title={A new parametric finite element analysis software for electrical machine electromagnetic fields and its implementation},
year={2001},
volume={2},
number={},
pages={1098-1101 vol.2},
abstract={In this paper, a new parametric finite element analysis (FEA) software for electrical machine electromagnetic fields is developed. The software architecture is analyzed with the IDEF0 model, and the conceptual data model is designed by IDEF1X model. It is suggested that integrity of functions and data in the software system can be assured by IDEF methods. From IDEFO model, the Client/Server system is presented. Programming in AutoCAD can reduce the time of software developing, and is valuable in practical applications and function extension.},
keywords={Finite element methods;Electromagnetic analysis;Electromagnetic fields;Object oriented modeling;Packaging machines;Graphical user interfaces;Data models;Software packages;Parametric statistics;Power system modeling},
doi={10.1109/ICEMS.2001.971869},
ISSN={},
month={Aug},}
@INPROCEEDINGS{10178,
author={Miller, K.W. and Morell, L.J. and Collins, W.R.},
booktitle={Proceedings. Conference on Software Maintenance, 1988.},
title={Maintaining FORTRAN software by enforcing abstract data types},
year={1988},
volume={},
number={},
pages={286-291},
abstract={The principles of data abstraction facilitate maintenance and enhance software reliability. However, FORTRAN includes features that undermine data abstraction. A FORTRAN preprocessor called FAD enforces data abstraction when reusing FORTRAN-callable subprograms. Using FAD, reusable software is organized as the implementation of abstract data types (ADTs). FAD users access the reusable software by declarations and subprogram invocations based on the ADTs. The FAD preprocessor translates ADT references into FORTRAN code and prohibits inappropriate manipulation of ADT instances. With the FAD system, ADT implementations can be changed without changing FORTRAN code that uses the ADTs. A maintenance strategy using FAD facilitates detailed control of reusable software.<>},
keywords={Software maintenance;Software libraries;Software design;Software reusability;Programming profession;Programming environments;User interfaces;Computer science;Educational institutions;Software reliability},
doi={10.1109/ICSM.1988.10178},
ISSN={},
month={Oct},}
@INPROCEEDINGS{515279,
author={Gaing, Z.L. and Lu, C.N. and Chang, B.S. and Cheng, C.L.},
booktitle={Proceedings of Power Industry Computer Applications Conference},
title={An object-oriented approach for implementing power system restoration package},
year={1995},
volume={},
number={},
pages={467-473},
abstract={Due to many unforeseen circumstances that could happen in today's bulk power systems, there is a possibility of a system wide outage. In order to provide aids to power system dispatchers following a complete collapse of the power system, a prototype expert system software package has been developed. Through an interactive and friendly graphic interface, the package suggests a guideline for the dispatcher to restore the power system. With the aim of improving ease of maintenance, object-oriented techniques were adopted to implement the package. The development of the software involved three stages: (1) object oriented analysis; (2) object oriented design; and (3) integration and testing. In this paper, the structure and the development procedure of the prototype system are presented.},
keywords={Power systems;Power system restoration;Software prototyping;Packaging;Expert systems;Software packages;Graphics;Guidelines;Power system analysis computing;Software testing},
doi={10.1109/PICA.1995.515279},
ISSN={},
month={May},}
@INPROCEEDINGS{4736892,
author={Kollias, Giorgos and Georgiou, Konstantinos and Gallopoulos, Efstratios},
booktitle={2008 IEEE Fourth International Conference on eScience},
title={Jylab Meets Eclipse: Integrating PSEs with Multicomponent Platforms},
year={2008},
volume={},
number={},
pages={735-742},
abstract={Jylab is a PSE architecture emphasizing portable computing over distributed platforms. It captures the idea of reusing some of the best open source software projects' functionality within the context of a single, net-aware, interactive environment. The original implementation of this idea resulted in a system built around a portable interpreter supported by a carefully selected suite of libraries spanning a comprehensive set of applications including scripting, numerical linear algebra, distributed/grid computing and Internet algorithmics. Because Jylab is a multicomponent PSE system, it is quite natural to base its implementation on a robust platform automating the management of complex stacks of software components, i.e. self-describing objects. The Eclipse platform meets this basic prerequisite, additionally providing many other interesting integration facilities, an extensive set of ready-to-use plug-ins and is also embraced by a vibrant community of users, developers and leading software companies. In this paper we describe the design and basic implementation of a flexible environment resulting from the integration of Jylab into Eclipse. To this effect, we survey relevant aspects of the rich Eclipse ecosystem as well as the Jylab approach to PSE construction. To illustrate our environment we present case studies from grid computing, neural network training and native libraries integration.},
keywords={Grid computing;Computer architecture;Distributed computing;Portable computers;Open source software;Software libraries;Application software;Linear algebra;Internet;Robustness;eclipse;grid;python},
doi={10.1109/eScience.2008.11},
ISSN={},
month={Dec},}
@INPROCEEDINGS{480122,
author={Winograd, J.M. and Hamid Nawab, S.},
booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
title={A C++ software environment for the development of embedded signal processing systems},
year={1995},
volume={4},
number={},
pages={2715-2718 vol.4},
abstract={A new environment for the rapid development of embedded signal processing software is described. The environment encourages incremental design via modular and hierarchical structuring of applications, and additional features are included which support the prototyping, testing, implementation, and integration stages of the system design cycle. Written in C++, the environment is comprised of a scripting language for the definition of system components and a class library which includes a basic application framework. Support is provided for incorporating both numeric and symbolic signal representations, as well as integrating multiple signal processing techniques within a single application. A sophisticated control mechanism allows dynamic scheduling of signal processing operations according to algorithmically defined schema. Signal processing applications developed in this environment are themselves objects, and are suitable for embedding within a larger overall system.},
keywords={Embedded software;Signal processing algorithms;Signal processing;Application software;Software prototyping;Prototypes;System testing;Libraries;Signal representations;Dynamic scheduling},
doi={10.1109/ICASSP.1995.480122},
ISSN={1520-6149},
month={May},}
@INPROCEEDINGS{7062891,
author={Wang, Feng and Wang, Heyu and Lei, Baohua and Ma, Wenting},
booktitle={2014 International Conference on Cloud Computing and Big Data},
title={A Research on High-Performance SDN Controller},
year={2014},
volume={},
number={},
pages={168-174},
abstract={Software Defined Networking (SDN) is a new programmable network construction technology that enables centrally management and control, which is considered to be the future evolution trend of networks. A modularized carrier-grade SDN controller according to the characteristics of carrier-grade networks is designed and proposed, resolving the problem of controlling large-scale networks of carrier. The modularized architecture offers the system flexibility, scalability and stability. Functional logic of modules and core modules, such as link discovery module and topology module, are designed to meet the carrier's need. Static memory allocation, multi-threads technique and stick-package processing are used to improve the performance of controller, which is C programming language based. Processing logic of the communication mechanism of the controller is introduced, proving that the controller conforms to the OpenFlow specification and has a good interaction with OpenFlow-based switches. A controller cluster management system is used to interact with controllers through the east-west interface in order to manage large-scale networks. Furthermore, the effectiveness and high performance of the work in this paper has been verified by the testing using Cbench testing program. Moreover, the SDN controller we proposed has been running in China Telecom's Cloud Computing Key Laboratory, which showed the good results is achieved.},
keywords={Control systems;Network topology;Topology;Process control;Message systems;Computer architecture;Protocols;Software Defined Networking;controller;carrier-grade networks},
doi={10.1109/CCBD.2014.41},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8976669,
author={Yakimov, Vladimir and Zaberzhinskij, Borislav and Mashkov, Andrey and Bukanova, Yuliya},
booktitle={2019 XXI International Conference Complex Systems: Control and Modeling Problems (CSCMP)},
title={Multi-threaded Approach to Software High-speed Algorithms for Spectral Analysis of Multi-component Signals},
year={2019},
volume={},
number={},
pages={698-701},
abstract={The article discusses the development of specialized software measuring-computing system, designed to operational spectral analysis of multicomponent signals based on data processing, obtained by simulating the procedure of binary sign-function quantization. The need to create specialized software measuring-computing system that implements the evaluation of the spectral components of multicomponent processes is caused by the fact that existing proprietary software products either have redundant functionality to solve highly specialized tasks or do not provide the necessary flexibility in the provision, support and modification of libraries that meet specific requirements. The software structure consists of the following main software components: a module for visualization of measurement data, a module for implementing the algorithm for spectral analysis of multicomponent signals, and a data processing converter between the user interface and the module for implementing algorithms. The graphical user interface is implemented using the high-tech integrated development environment Intellij IDEA in the Java 8 multi-platform programming language, which allows extending the functionality of the measurement system. The modules of the metrologically significant part of the software that perform the functions of processing, storing and transmitting measurement data and spectral analysis results are implemented in the resource efficient C ++ 17 language. The use of C ++ provided an opportunity to apply a multi-threaded programming approach in order to improve the performance of the procedures for calculating spectral estimates. Using the mechanism of multithreaded algorithm execution, it became possible to parallelize processor calculations and input-output operations and, as a result, reduce the computational costs of obtaining estimates of the time-frequency characteristics of signals by introducing alternation mechanisms for performing various weakly interconnected subtasks requiring simultaneous execution into a separate multithreading subsystem. The results of experimental testing showed the resource efficiency of the software implementation of complex data processing algorithms based on the sign model of analog-stochastic quantization in the process of complex analysis of signals.},
keywords={digital signal processing;spectral analysis;binary sign-function analog-stochastic quantization;software measuring-computing system;resource-efficient algorithms;multithreaded programming},
doi={10.1109/CSCMP45713.2019.8976669},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{7518886,
author={Veeramanickam, M. R. M. and Mohanapriya, M.},
booktitle={2016 International Conference on Information Communication and Embedded Systems (ICICES)},
title={Research paper on E-Learning application design features: Using cloud computing & software engineering approach},
year={2016},
volume={},
number={},
pages={1-6},
abstract={For several years, the importance of Cloud computing influences in many areas including E-Learning. Education is seen as important for every individual and country's growth. Basics objective is to design an Application Model to support eLearning Services. The current e-learning systems lack the appropriate infrastructures & efficacy integrated Application Model. A cloud technology gives platform to run our e-learning applications on services basis to any end users using the internet from cloud infrastructure. It will provide optimum affordable price package to educational organizations in particular for trainer and learners. We need to combine various technologies to achieve this particular objective. Further explains about importance of the E-Learning Design features and analyses the need of cloud computing. So, we need to figure out cloud based application model implementation's importance for e-learning system, and which made an active research on following manner: its working method, architecture design, Development tools and external interface with the application model, Software Engineering approaches. This paper describes about importance using of cloud environments for any institutes and learners usage, to underscore its possible benefits and offerings in term design.},
keywords={Cloud computing;Electronic learning;Computational modeling;Business;E-Learning;Cloud Computing;Application model},
doi={10.1109/ICICES.2016.7518886},
ISSN={},
month={Feb},}
@INPROCEEDINGS{6034311,
author={Šaletić, Dragan Z. and Anđelković, Mihajlo},
booktitle={2011 IEEE 9th International Symposium on Intelligent Systems and Informatics},
title={A perceptual computer software model applied to hierarchical decision making},
year={2011},
volume={},
number={},
pages={145-150},
abstract={Perceptual computer (Per-C) is a concept introduced in year 2001 by Mendel. It employs the Zadeh's theory of Computing With Words to provide a model for computer and software architectures able to aid people making subjective judgments. It can be used for variety of tasks like investment decision making, social judgment making, hierarchical decision making and so on. In this paper the topic of hierarchical decision making and related introductory terms are summarized and partly reinterpreted. A newly developed application programming interface (API) for software implementations of Per-C is presented, along with several new technical details. The API has been tested on the well known problem of missile system selection from the literature. The results have been compared with those from Wu and Mendel.},
keywords={Frequency selective surfaces;Uncertainty;Decision making;Fuzzy sets;Computational modeling;Arrays;Computers},
doi={10.1109/SISY.2011.6034311},
ISSN={1949-0488},
month={Sep.},}
@INPROCEEDINGS{8257940,
author={Arge, Lars and Rav, Mathias and Svendsen, Svend C. and Truelsen, Jakob},
booktitle={2017 IEEE International Conference on Big Data (Big Data)},
title={External memory pipelining made easy with TPIE},
year={2017},
volume={},
number={},
pages={319-324},
abstract={When handling large datasets that exceed the capacity of the main memory, movement of data between main memory and external memory (disk), rather than actual (CPU) computation time, is often the bottleneck in the computation. Since data is moved between disk and main memory in large contiguous blocks, this has led to the development of a large number of I/O-efficient algorithms that minimize the number of such block movements. However, actually implementing these algorithms can be somewhat of a challenge since operating systems do not give complete control over movement of blocks and management of main memory. TPIE is one of two major libraries that have been developed to support I/O-efficient algorithm implementations. It relies heavily on the fact that most I/O-efficient algorithms are naturally composed of components that stream through one or more lists of data items, while producing one or more such output lists, or components that sort such lists. Thus TPIE provides an interface where list stream processing and sorting can be implemented in a simple and modular way without having to worry about memory management or block movement. However, if care is not taken, such streaming-based implementations can lead to practically inefficient algorithms since lists of data items are typically written to (and read from) disk between components. In this paper we present a major extension of the TPIE library that includes a pipelining framework that allows for practically efficient streaming-based implementations while minimizing I/O-overhead between streaming components. The framework pipelines streaming components to avoid I/Os between components, that is, it processes several components simultaneously while passing output from one component directly to the input of the next component in main memory. TPIE automatically determines which components to pipeline and performs the required main memory management, and the extension also includes support for parallelization of internal memory computation and progress tracking across an entire application. Thus TPIE supports efficient streaming-based implementations of I/O-efficient algorithms in a simple, modular and maintainable way. The extended library has already been used to evaluate I/O-efficient algorithms in the research literature, and is heavily used in I/O-efficient commercial terrain processing applications by the Danish startup SCALGO.},
keywords={Memory management;Pipeline processing;Libraries;Software algorithms;Algorithm design and analysis;Operating systems;Hardware;I/O-efficient algorithms;C++;software framework},
doi={10.1109/BigData.2017.8257940},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9753030,
author={Soni, Gaurav},
booktitle={2022 IEEE Delhi Section Conference (DELCON)},
title={Implementation of LM35 Interfacing of Temperature Sensor with Arduino using LabVIEW 2015},
year={2022},
volume={},
number={},
pages={1-3},
abstract={LabVIEW is a graphical programming language, used in many research fields for designing communication algorithms and simulating traditional as well as real time signals. Arduino kit can be interfaced with LabVIEW for a large number of applications. In this article, a project based on temperature sensor using Arduino Uno and LabVIEW is implemented. We have used LM35 temperature sensor whose output voltage varies in linear proportion to the temperature in centigrade. Thus, providing us an advantage over other sensors to measure the temperature conveniently in degree Celsius. The LabVIEW 2012 provides a simple interface between temperature sensor and Arduino Uno to read output voltage where LabVIEW further plots the measured temperature data obtained in real time in the graphical form.},
keywords={Temperature sensors;Temperature measurement;Temperature distribution;Voltage measurement;Instruments;Soil moisture;Real-time systems;Arduino Uno;Laboratory Virtual Instrument Engineering Workbench;Virtual Instrument;Universal Serial Bus;Virtual Instrument Software Architecture API},
doi={10.1109/DELCON54057.2022.9753030},
ISSN={},
month={Feb},}
@INPROCEEDINGS{7916375,
author={Infantolino, Jamie and Ross, James and Richie, David},
booktitle={2017 International Applied Computational Electromagnetics Society Symposium - Italy (ACES)},
title={Portable high-performance software design using templated meta-programming for EM calculations},
year={2017},
volume={},
number={},
pages={1-2},
abstract={The Finite Difference Time Domain (FDTD) Method is used for full-wave electromagnetic (EM) simulations. FDTD is computationally intensive with performance depending critically on architecture-specific optimizations that have become more challenging given the rapidly changing architectures in modern high-performance computing platforms. We examine a templated meta-programming technique to implement the computational kernels in canonical form, without any architecture-specific optimizations, such that data layout and loop order optimizations can be applied through code transformations. These transformations are abstracted behind a simple yet flexible API for the application developer and require no special tools, relying only on a modern optimizing C++ compiler. Optimizations for data layout and loop order are selected at compile-time using C++ typedefs without the need to modify source code implementations of the algorithm.},
keywords={Optimization;Layout;Finite difference methods;Time-domain analysis;C++ languages;Arrays;FDTD;optimizations},
doi={10.23919/ROPACES.2017.7916375},
ISSN={},
month={March},}
@INPROCEEDINGS{5306272,
author={Adams, Bram},
booktitle={2009 IEEE International Conference on Software Maintenance},
title={Co-evolution of source code and the build system},
year={2009},
volume={},
number={},
pages={461-464},
abstract={A build system breathes life into source code, as it configures and directs the construction of a software system from textual source code modules. Surprisingly, build languages and tools have not received considerable attention by academics and practitioners, making current build systems a mysterious and frustrating resource to work with. Our dissertation presents a conceptual framework with tool support to recover, analyze and refactor a build system. We demonstrate the applicability of our framework by analyzing the evolution of the Linux kernel build system and the introduction of AOSD technology in five legacy build systems. In all cases, we found that the build system is a complex software system of its own, trying to co-evolve in a synchronized way with the source code while working around shortcomings of the underlying build technology. Based on our findings, we hypothesize four conceptual reasons of co-evolution to guide future research in the area of build systems.},
keywords={Software systems;Programming;Modular construction;Linux;Kernel;Spine;Software development management;Computer architecture;Joining processes;Libraries},
doi={10.1109/ICSM.2009.5306272},
ISSN={1063-6773},
month={Sep.},}
@INPROCEEDINGS{8791389,
author={Yang, Weiyong and Liu, Wei and Wei, Xingshen and Lv, Xiaoliang and Qi, Yunlong and Sun, Boyan and Liu, Yin},
booktitle={2019 IEEE International Conference on Energy Internet (ICEI)},
title={Micro-Kernel OS Architecture and its Ecosystem Construction for Ubiquitous Electric Power IoT},
year={2019},
volume={},
number={},
pages={179-184},
abstract={The operating system is extremely important for both "Made in China 2025" and ubiquitous electric power Internet of Things. By investigating of five key requirements for ubiquitous electric power Internet of Things at the OS level (performance, ecosystem, information security, functional security, developer framework), this paper introduces the intelligent NARI microkernel Operating System and its innovative schemes. It is implemented with microkernel architecture based on the trusted computing. Some technologies such as process based fine-grained real-time scheduling algorithm, sigma0 efficient message channel and service process binding in multicore are applied to improve system performance. For better ecological expansion, POSIX standard API is compatible, Linux container, embedded virtualization and intelligent interconnection technology are supported. Native process sandbox and mimicry defense are considered for security mechanism design. Multi-level exception handling and multidimensional partition isolation are adopted to provide High Reliability. Theorem-assisted proof tools based on Isabelle/HOL is used to verify the design and implementation of NARI microkernel OS. Developer framework including tools, kit and specification is discussed when developing both system software and user software on this IoT OS.},
keywords={Security;Real-time systems;Computer architecture;Virtualization;Task analysis;Containers;IoT;real-time OS;microkernel;network security},
doi={10.1109/ICEI.2019.00038},
ISSN={},
month={May},}
@INPROCEEDINGS{9007311,
author={Belkin, Ilya and Tkachenko, Sergey and Yudin, Dmitry},
booktitle={2019 International Conference on Artificial Intelligence: Applications and Innovations (IC-AIAI)},
title={Traffic Sign Recognition on Video Sequence using Deep Neural Networks and Matching Algorithm},
year={2019},
volume={},
number={},
pages={35-354},
abstract={The paper analyzes data sets containing images with labeled traffic signs, as well as modern approaches for their detection and classification on images of urban scenes. Particular attention is paid to the recognition of Russian types of traffic signs. Various modern architectures of deep neural networks for the simultaneous object detection and classification were studied, including Faster R-CNN, Mask R-CNN, Cascade R-CNN, RetinaNet. To increase the efficiency of neural network recognition of objects in a video sequence, the Seq-BBox Matching algorithm is used. Training and testing of the proposed approach was carried out on Russian Traffic Sign Dataset and IceVision Dataset containing over 150 types of road signs and more than 65,000 marked images. For all the approaches considered, quality metrics are defined: mean average precision mAP, mean average recall mAR and processing time of one frame. The highest quality performance was demonstrated by the architecture of Faster R-CNN with Seq-BBox Matching, while the highest performance is provided by the architecture of RetinaNet. Implementation was carried out using the Python 3.7 programming language and PyTorch deep learning library using NVidia CUDA technology. Performance indicators were obtained on the workstation with the NVidia Tesla V-100 32GB video card. The obtained results demonstrate the possibility of applying the proposed approach both for the resource-intensive procedure for automated labeling of road scene images for new data sets preparation, and for traffic sign recognition in on-board computer vision systems of unmanned vehicles.},
keywords={Neural networks;Measurement;Computer architecture;Training;Detectors;Object detection;Testing;image recognition;detection;traffic sign;deep learning;neural network;matching algorithm;software},
doi={10.1109/IC-AIAI48757.2019.00013},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8317069,
author={Prokhorov, Andrey S. and Chudinov, Maksim A. and Bondarev, Sergei E.},
booktitle={2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)},
title={Control systems software implementation using open source SCADA-system OpenSCADA},
year={2018},
volume={},
number={},
pages={220-222},
abstract={Currently, SCADA-systems are the most promising method for complex dynamical systems (processes) automatic control in critical areas. On the supervisory control principles are built large automated systems in industry and energy, transport, aerospace and various state structures. Using of SCADA-technology allows to achieve a high level of automation in solving the problems of control systems development, processing, transmission, storage and display of information. The OpenSCADA system is intended for: gathering, archivation, visualization of the information, delivery of operating influences, and also other related operations, characteristic for full-function SCADA systems. The main advantages of SCADA-packages include: reducing time to develop the large and distributed systems due to existing pre-built components, as well as the convenience and ease of local operating system modifications through the built-in setting tools and configuration.},
keywords={Tools;Control systems;Containers;Software;Automation;Visualization;Real-time systems;SCADA-system;OpenSCADA;mimic diagram;graphical user interface},
doi={10.1109/EIConRus.2018.8317069},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9212077,
author={Wehrmeister, Marco Aurelio},
booktitle={2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
title={Generating ROS-based Software for Industrial Cyber-Physical Systems from UML/MARTE},
year={2020},
volume={1},
number={},
pages={313-320},
abstract={This work proposes an approach to generate automatically the embedded software for distributed Cyber-Physical Systems implemented using the Robotic Operating System (ROS) framework. For that, the Aspect-oriented Model Driven Engineering for Real-Time systems (AMoDE-RT) design approach has been extended in order to support the C++ code generation using the semantics and libraries available in ROS framework which is widely used in both academia and industry to implement the embedded software for robotic systems. The system architecture, behavior, requirements and constraints are specified in a UML/MARTE model. The information specified in the high-level model is used as input for a tool that generates a great part of the embedded software for all distributed computing devices. The main goal is to foster the use of Model-Driven Engineering in the context of cyber-physical systems design aiming the rapid prototyping via simulation and also the generation of the actual implementation of the system components. The proposed approach has been validated through a case study that demonstrates the feasibility to implement a ROS/C++ software for industrial systems. The results indicate that the proposed approach can be applied to complex systems comprising a larger number of interacting devices, whereas keeping the high-level of abstraction for system specification in UML/MARTE models.},
keywords={Service robots;Computational modeling;Operating systems;Unified modeling language;Semantics;Systems architecture;Cyber-physical systems;Model-Driven Engineering;embedded software;code generation;UML;MARTE;Robot Operating System},
doi={10.1109/ETFA46521.2020.9212077},
ISSN={1946-0759},
month={Sep.},}
@INPROCEEDINGS{6632568,
author={Ramdan, Dadan and Harahap, Usman and Abdillah, Mohd. Zulkifli},
booktitle={2013 International Conference on QiR},
title={Fluid structure interaction simulation in IC encapsulation process},
year={2013},
volume={},
number={},
pages={220-225},
abstract={This paper presents three-dimensional (3D) fluid structure interaction (FSI) technique; using Mesh based Parallel Code Coupling Interface (MpCCI), for the visualization of wire sweep during encapsulation. The effects of number of mold cavity outlet vents on the melt flow behavior, wire sweep, and von Mises stress distributions, are mainly studied. 3D model of mold and wire were designed using GAMBIT, simulated fluid flow and structural using FLUENT and ABAQUS. Three types of mold cavity simple model namely Type D1, Type D2 and Type D3 with different outlet vents were studied to analyze wire sweep deformation. Polymer rheology model with curing effect (Castro-Macosko model) have been used in the fluid flow modeling and Volume of Fluid (VOF) technique was applied for melt front tracking for the Epoxy Molding Compound (EMC). In the present study, Type D3 with minimum outlet vent area of mold cavity shows the highest deformation of wire and highest stress distributions. The numerical results of wire deformation pattern were compared with the analytical method and found in good conformity. The strength of MpCCI software in handling FSI problems is proved to be excellent. This present work is expected to be the reference and guideline for microelectronics industry.},
keywords={Wires;Vents;Encapsulation;Mathematical model;Solid modeling;Fluids;Computational modeling;Fluid Structure Interaction;Wire Sweep;MpCCI;Castro-Macosco model;Epoxy Molding Compound (EMC);Volume of Fluid (VOF)},
doi={10.1109/QiR.2013.6632568},
ISSN={},
month={June},}
@INPROCEEDINGS{367074,
author={Walker, M.},
booktitle={Proceedings of the First International Conference on Massively Parallel Computing Systems (MPCS) The Challenges of General-Purpose and Special-Purpose Computing},
title={On scientific research, applications software development, and industrial use of massively parallel computing systems},
year={1994},
volume={},
number={},
pages={217-219},
abstract={A healthy massively parallel computing system industry requires a well-defined market for their products. The market for massively parallel computing systems has remained stubbornly ill-defined for at least a decade. The primary reason for this is that industrial corporations have not been able to measure value in the new computing technology, due to the absence of commercially supported application software packages for these systems. It is essential for the well-being of everyone engaged in massively parallel computing, from research institutions to industrial end users, and particularly the computer builders themselves, that ways be found to ameliorate this state of affairs. This paper analyses the situation, and proposes some procedures whose implementation would ease the transfer of newly developed application technologies from research groups into the hands of end users, who can then employ massively parallel computers to solve practical industrial problems.<>},
keywords={Application software;Computer industry;Parallel processing;Concurrent computing;Chemical industry;Costs;Computer architecture;Software measurement;Software packages;Packaging},
doi={10.1109/MPCS.1994.367074},
ISSN={},
month={May},}
@INPROCEEDINGS{5413114,
author={Anderson, J. Michael and Tsen, Charles and Wang, Liang-Kai and Compton, Katherine and Schulte, J. Michael},
booktitle={2009 IEEE International Conference on Computer Design},
title={Performance analysis of decimal floating-point libraries and its impact on decimal hardware and software solutions},
year={2009},
volume={},
number={},
pages={465-471},
abstract={The IEEE Standards Committee recently approved the IEEE 754-2008 Standard for Floating-point Arithmetic, which includes specifications for decimal floating-point (DFP) arithmetic. A growing number of DFP solutions have emerged, and developers now have many DFP design choices including arbitrary or fixed precision, binary or decimal significand encodings, 64-bit or 128-bit DFP operands, and software or hardware implementations. There is a need for accurate analysis of these solutions on representative DFP benchmarks. In this paper, we expand previous DFP benchmark and performance analysis research. We employ a DFP benchmark suite that currently supports several DFP solutions and is easily extendable. We also present performance analysis that (1) provides execution profiles for various DFP encodings and types, (2) gives the average number cycles for common DFP operations and the total number of each DFP operation in each benchmark, and (3) highlights the tradeoffs between using 64-bit and 128-bit DFP operands for both binary and decimal significand encodings. This analysis can help guide the design of future DFP hardware and software solutions.},
keywords={Performance analysis;Software libraries;Hardware;Software performance;Encoding;Application software;Floating-point arithmetic;Digital arithmetic;Software standards;Computer errors},
doi={10.1109/ICCD.2009.5413114},
ISSN={1063-6404},
month={Oct},}
@INPROCEEDINGS{8071580,
author={Vayada, Mohammed G. and Patel, Hepi R. and Muduli, Bikash R.},
booktitle={2017 Third International Conference on Sensing, Signal Processing and Security (ICSSS)},
title={Hardware software co-design simulation modeling for image security concept using Matlab-Simulink with Xilinx system generator},
year={2017},
volume={},
number={},
pages={134-137},
abstract={In recent scenario, the hardware design is becoming a very complex task because programmable hardware like FPGA has become complex with regards to the increasing number of transistors. In this paper, an overview of tool for model based hardware design is mentioned. This tool enable to describe an algorithm in a model based description without going in to complex low-level VHDL or Verilog description. It is efficient in translating model based description to HDL automatically. These kind of high level tools bring hardware implementation such as FPGA to a wider aspects with increasing designing productivity. In this paper an image security model using Matlab-Simulink with Xilinx system generator is developed. The use is to secure image, i.e. secret image is kept behind the cover image. The concealed image is imposible to retrive from the cover image and user can only see cover image.},
keywords={Generators;Field programmable gate arrays;Hardware;Software packages;Tools;Mathematical model;Image color analysis;Colour Imag;Gray Scale Image;Image Security;Spatial Domain;XUinx System Generator},
doi={10.1109/SSPS.2017.8071580},
ISSN={},
month={May},}
@INPROCEEDINGS{9111766,
author={Mladzievskiy, Evgeniy and Ryzhkova, Elena},
booktitle={2020 V International Conference on Information Technologies in Engineering Education ( Inforino )},
title={The Use of Building Information Modeling Technology in Designing},
year={2020},
volume={},
number={},
pages={1-4},
abstract={A modern approach to the design of industrial and public buildings requires the use of the latest technology. The most promising area in this industry is Building Information Modeling (BIM). Thanks to the use of BIM technologies, the design process is significantly accelerated and much fewer errors occur. In this article, the Revit software package is selected as an example of a 3D design environment. This program has a fairly convenient and functional interface, allows you to configure connections with other programs, and it has a Dynamo visual programming module that allows you to speed up and automate many standard functions.},
keywords={Industries;Visualization;Three-dimensional displays;Software packages;Buildings;Urban areas;Task analysis;BIM;modeling;designing;3d;Dynamo;Revit},
doi={10.1109/Inforino48376.2020.9111766},
ISSN={},
month={April},}
@INPROCEEDINGS{6924478,
author={Nursetia, Panji and Handoko, Dwi and Taruno, Warsito. P. and Baidillah, Marlin R.},
booktitle={2014 Asia-Pacific Conference on Computer Aided System Engineering (APCASE)},
title={On the development of integrated real time data acquisition and volume data processing software for ECVT},
year={2014},
volume={},
number={},
pages={93-96},
abstract={ECVT has been widely used in different fields including oil refinery systems, chemical processes, space shuttles and medicals. The technique generates a whole volumetric image from the measured capacitance of the region enclosed by the geometrically three-dimensional sensor. However, the data acquisition and data processing of the ECVT are done on separate applications, which makes a real time measurement and visualization cannot be achieved. This paper describes a design and development of an Integrated Data Acquisition and Data Processing application for ECVT. The application implements data acquisition and data processing in one platform. Furthermore, the designed software also provides parallel implementation of the image reconstruction to speed up the image reconstruction. The software is developed using Python language, and open source Python library for scientific computing.},
keywords={Data acquisition;Image reconstruction;Capacitance;Libraries;Parallel processing;Real-time systems;Data processing;ECVT;Realtime DAS Application;Parallel;Python;MPI},
doi={10.1109/APCASE.2014.6924478},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8548291,
author={Gaury, Benoit and Sun, Yubo and Bermel, Peter and Haney, Paul},
booktitle={2018 IEEE 7th World Conference on Photovoltaic Energy Conversion (WCPEC) (A Joint Conference of 45th IEEE PVSC, 28th PVSEC & 34th EU PVSEC)},
title={Sesame: A Numerical Simulation Tool for Polycrystalline Photovoltaics},
year={2018},
volume={},
number={},
pages={1882-1885},
abstract={We present a new software simulation tool “Sesame”, which solves the drift-diffusion-Poisson equations in 1 and 2-dimensions. Sesame is distributed both as an open source Python package and as a standalone executable for Windows. The software is designed to enable easy construction of systems with extended defects such as grain boundaries and sample surfaces. In this paper, we present an overview of Sesame's capabilities along with results benchmarking Sesame against commercial software packages. The source code, executable, and full documentation with tutorials is available at https://pages.nist.gov/sesame.},
keywords={Grain boundaries;Graphical user interfaces;Software packages;Photovoltaic cells;Tools;Python;numerical simulation;polycrystalline solar cell;software},
doi={10.1109/PVSC.2018.8548291},
ISSN={0160-8371},
month={June},}
@ARTICLE{345964,
author={Bass, J.M. and Brown, A.R. and Hajji, M.S. and Marriott, D.G. and Croll, P.R. and Fleming, P.J.},
journal={IEEE Parallel & Distributed Technology: Systems & Applications},
title={Automating the development of distributed control software},
year={1994},
volume={2},
number={4},
pages={9-19},
abstract={The Development Framework translates application-specific system specifications into parallel, hard real-time implementations, using methods that are both familiar to developers and optimal for the application. The Development Framework approach applies CASE tools-as well as several new tools-to the development of distributed systems, so designers can concentrate on the control-engineering aspects of their systems. The approach addresses three development phases: specification, software design, and implementation. In the specification phase, the control engineer refines behavioral requirements through simulation and analysis, thereby verifying that the system meets its functional requirements prior to implementation. Once the simulated behavior is satisfactory, the specified behavior is translated into a design. Finally, our tools produce source code, either by automatically generating it or by drawing it from a library. We describe the new and existing tools we apply during each phase. We then demonstrate our approach using an example of a linearized roll-pitch-yaw autopilot and airframe model.<>},
keywords={Distributed control;Real time systems;Application software;Computer aided software engineering;Control systems;Software design;Automatic control;Analytical models;Engineering drawings;Libraries},
doi={10.1109/88.345964},
ISSN={1558-1861},
month={Winter},}
@INPROCEEDINGS{8416274,
author={Li, Xiaoyao and Wang, Xiuxiu and Liu, Fangming and Xu, Hong},
booktitle={2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)},
title={DHL: Enabling Flexible Software Network Functions with FPGA Acceleration},
year={2018},
volume={},
number={},
pages={1-11},
abstract={Network function virtualization (NFV) aims to run software network functions (NFs) in commodity servers. As CPU is general-purpose hardware, one has to use many CPU cores to handle complex packet processing at line rate. Owing to its performance and programmability, FPGA has emerged as a promising platform for NFV. However, the programmable logic blocks on an FPGA board are limited and expensive. Implementing the entire NFs on FPGA is thus resource-demanding. Further, FPGA needs to be reprogrammed when the NF logic changes which can take hours to synthesize the code. It is thus inflexible to use FPGA to implement the entire NFV service chain. We present dynamic hardware library (DHL), a novel CPU-FPGA co-design framework for NFV with both high performance and flexibility. DHL employs FPGA as accelerators only for complex packet processing. It abstracts accelerator modules in FPGA as a hardware function library, and provides a set of transparent APIs for developers. DHL supports running multiple concurrent software NFs with distinct accelerator functions on the same FPGA and provides data isolation among them. We implement a prototype of DHL with Intel DPDK. Experimental results demonstrate that DHL greatly reduces the programming efforts to access FPGA, brings significantly higher throughput and lower latency over CPU-only implementation, and minimizes the CPU resources.},
keywords={Field programmable gate arrays;Software;Hardware;Noise measurement;Throughput;Libraries;Programming;NFV;FPGA;CPU FPGA co design;Acceleration;DPDK;API},
doi={10.1109/ICDCS.2018.00011},
ISSN={2575-8411},
month={July},}
@INPROCEEDINGS{1199587,
author={Hwang, J.-K.},
booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},
title={Innovative communication design lab based on PC sound card and Matlab: a software-defined-radio OFDM modem example},
year={2003},
volume={3},
number={},
pages={III-761},
abstract={An innovative software-defined radio (SDR) approach to advanced communication design lab courseware is proposed and illustrated by an audio-band OFDM transceiver design example. Implementation of this new approach needs only the most common PC sound card and Matlab software, making such a lab course extremely easy to setup at a minimum cost. Moreover, all system parameters and algorithms are embodied in the form of high-level RX and TX programs, which can be modified and tested very flexibly. In this aspect, this approach has all the advantages of simulation-based experiments. However, it further touches real-world implementation issues. A real-world passband signal in the audio band can be physically generated and simultaneously recorded by the full-duplex sound card, and then the received digitized signal can be demodulated by an SDR receiver which implements all the required DSP algorithms in Matlab code.},
keywords={MATLAB;OFDM;Modems;Digital signal processing;Mathematical model;Courseware;System testing;Passband;Signal generators;Packaging machines},
doi={10.1109/ICASSP.2003.1199587},
ISSN={1520-6149},
month={April},}
@INPROCEEDINGS{992902,
author={Sahasranaman, V. and Buddhikot, M.M.},
booktitle={Proceedings Ninth International Conference on Network Protocols. ICNP 2001},
title={Comparative evaluation of software implementations of layer-4 packet classification schemes},
year={2001},
volume={},
number={},
pages={220-228},
abstract={The availability of fast network processors and general purpose CPUs has made software implementation of per-packet processing in network elements an attractive option. Given this, a-priori knowledge of performance of software implementations of the well known Layer-4 packet classification will be very useful. We compare the performance of three state-of-the-art packet classification schemes namely, Grid-of-Tries (GOT), Packet Classification Algorithms using Recursive Space-decomposition (PACARS) , and Tuple-Space-Search (TSS), implemented in FreeBSD 3.3 UNIX kernel. We developed two new OS extensions, namely, the Virtual Filter Database (VFD) framework and the new routing socket API to implement these algorithms. We used real-life as well as synthetic rule databases to evaluate their performance. Our key conclusions are: (1) compression of trie data structure that is central to a lot of classification algorithms has limited benefits on general purpose CPUs; (2) static algorithms such as GOT that do not support dynamic updates support very fast search performance of the order of a few microseconds per search and may be adequate for static firewalls; and (3) with medium sized databases, PACARS and TSS schemes provide update times of the order of 100s of microseconds and search performance of the order of 10s of microseconds. These algorithms are adequate for dynamic firewalls, traffic directors, and network monitoring applications in enterprise networks.},
keywords={Databases;Classification algorithms;Availability;Software performance;Kernel;Filters;Routing;Sockets;Data structures;Telecommunication traffic},
doi={10.1109/ICNP.2001.992902},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6783445,
author={Keswani, Raman and Joshi, Salil and Jatain, Aman},
booktitle={2014 Fourth International Conference on Advanced Computing & Communication Technologies},
title={Software Reuse in Practice},
year={2014},
volume={},
number={},
pages={159-162},
abstract={By software reusing we can expedite the development of a software product by re-using the components of another software product in a different behavior. The concept of systematic software reuse is simple: the idea of building and using "software preferred parts". By building systems out of carefully designed, pre-tested components, one will save the cost of designing, writing and testing new code. The practice of reuse has not proven to be this simple however, and there are many misconceptions about how to implement and gain benefit from software reuse. This paper briefly summarizes software reuse research and discusses major research contributions.},
keywords={Software reusability;Guidelines;Libraries;Systematics;Organizations;Documentation},
doi={10.1109/ACCT.2014.57},
ISSN={2327-0659},
month={Feb},}
@INPROCEEDINGS{6843800,
author={Oueslati, Mohamed Mehdi and Dahmouni, Anouar Wajdi and Ben Nasrallah, Sassi},
booktitle={2014 International Conference on Composite Materials & Renewable Energy Applications (ICCMREA)},
title={Numerical study of pitching wind turbine airfoil},
year={2014},
volume={},
number={},
pages={1-5},
abstract={The original incentive for developing the software package was the identification of the unsteady wake structure generation, and the prediction of aerodynamic performances of an airfoil. In fact, one of the key features of Laplace's Equation is the property that allows the equation governing the flow field to be converted from a 3D problem throughout the field to a 2D problem for finding the potential on the surface. The aim of this work is to evaluate the aerodynamic performances of wind turbine airfoils NACA 23015 and NACA 4412 in pitching motion. Therefore, two dimensional inviscid flow codes is developed based on the Unsteady Panel Method to predict the oscillatory flow field and the aerodynamic propriety of the oscillating airfoil for different amplitude of oscillation and reduced frequency respectively.},
keywords={Accuracy;Computational modeling;Oscillators;Shape;Unsteady Panel method;wind turbine airfoils;wake structure;pitching motion},
doi={10.1109/ICCMREA.2014.6843800},
ISSN={},
month={Jan},}
@INPROCEEDINGS{6087185,
author={Farkas, David K. and Larson, Jerrod and Naranjo, Steven J.},
booktitle={2011 IEEE International Professional Communication Conference},
title={LabelPatterns.org: A comprehensive pattern library for consumer-decision labels},
year={2011},
volume={},
number={},
pages={1-9},
abstract={Consumer-decision labels are relatively small panels of information, placed where consumers make decisions, that help those consumers make informed choices and, at times, motivate desired behaviors. They provide information about environmental impact/sustainability, nutrition, health, safety, the quality and suitability of consumer goods, and other domains. Design patterns are expanded guidelines that follow a problem-solution structure, provide more context than standard guidelines, and are supported when possible by citations to relevant research and professional literature. Pattern libraries are sets of coordinated patterns that strive to comprehensively support the design process in a particular domain. Pattern libraries have proven successful and are now used in such domains as urban planning, object-oriented programming, software user interface design, and web design. LabelPatterns.org is a newly launched website currently hosting over 75 design patterns that support the design of consumer-decision labels. It also offers other kinds of information about these labels and related messaging. The patterns and the website were begun as student projects in the Department of Human Centered Design & Engineering at the University of Washington, USA. It is now being managed and expanded by a volunteer project team.},
keywords={Libraries;Guidelines;Labeling;Educational institutions;Web design;Water heating;Safety;Design patterns;environmental labels;consumer-decision labels;pattern libraries},
doi={10.1109/IPCC.2011.6087185},
ISSN={2158-1002},
month={Oct},}