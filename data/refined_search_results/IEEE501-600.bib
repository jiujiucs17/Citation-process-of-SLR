@INPROCEEDINGS{681704,
author={Frigo, M. and Johnson, S.G.},
booktitle={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
title={FFTW: an adaptive software architecture for the FFT},
year={1998},
volume={3},
number={},
pages={1381-1384 vol.3},
abstract={FFT literature has been mostly concerned with minimizing the number of floating-point operations performed by an algorithm. Unfortunately, on present-day microprocessors this measure is far less important than it used to be, and interactions with the processor pipeline and the memory hierarchy have a larger impact on performance. Consequently, one must know the details of a computer architecture in order to design a fast algorithm. In this paper, we propose an adaptive FFT program that tunes the computation automatically for any particular hardware. We compared our program, called FFTW, with over 40 implementations of the FFT on 7 machines. Our tests show that FFTW's self-optimizing approach usually yields significantly better performance than all other publicly available software. FFTW also compares favorably with machine-specific, vendor-optimized libraries.},
keywords={Software architecture;Microprocessors;Pipelines;Computer architecture;Algorithm design and analysis;Hardware;Automatic testing;Software testing;Software performance;Software libraries},
doi={10.1109/ICASSP.1998.681704},
ISSN={1520-6149},
month={May},}
@INPROCEEDINGS{8622912,
author={Shahzadi, Sonia and Ubakanma, George and Iqbal, Muddesar and Dagiuklas, Tasos},
booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)},
title={Autonomous, Seamless and Resilience Carrier Cloud Brokerage Solution for Business Contingencies During Disaster Recovery},
year={2018},
volume={},
number={},
pages={1048-1053},
abstract={The challenge of disaster recovery management for cloud based services is constantly evolving. The costs of cloud service downtime in the event of disaster striking is the subject of much international research. The key issue to resolve is developing suitably resilient and seamless live/realtime mechanisms for disaster recovery. In this paper, we have implemented a proof of concept for an autonomous and fault tolerant carrier cloud brokerage solution with resilient provisioning of on-the-fly cloud resources. When a disaster strikes, the proposed solution will trigger the migration of an entire IaaS from one cloud to another without causing any disruption to the business. In the event of non-availability of hosts for the deployment of virtual network functions for different business processes, an on-the-fly host selection mechanism is proposed and implemented to locate other active compute hosts without any disruptions. In order to evaluate the performance of the proposed solution, we defined several use-case scenarios for each cloud service. This proposed solution will not only reduce the capital expenditure but also provides a reliable and efficient way to access the data during disaster.},
keywords={Cloud computing;Libraries;Computer architecture;Licenses;Servers;Business continuity;Cloud Computing, Business Continuity, Infrastructure as a Service, Platform as a Service, Software as a Service},
doi={10.1109/HPCC/SmartCity/DSS.2018.00174},
ISSN={},
month={June},}
@ARTICLE{1702573,
author={Hughes, C.E. and Pfleeger, C.P.},
journal={IEEE Transactions on Software Engineering},
title={ASSIST-V: An Environment Simulator for IBM 360 Systems Software Development},
year={1978},
volume={SE-4},
number={6},
pages={526-530},
abstract={This paper describes ASSIST-V, a software tool designed for use in the teaching of operating systems, fie management, and machine architecture courses. ASSIST-V is a program that provides an environment for the implementation, testing, and evaluation of systems software for the IBM 360 series machines. This capability is achieved by simulating all relevant aspects of the machine's architecture. In particular, ASSIST-V simulates interrupts, I/O channels, and I/O devices, as well as all IBM 360 machine instructions. In addition, ASSIST-V provides extensive debugging and statistics-gathering aids.},
keywords={System software;Operating systems;Programming profession;Computer architecture;System testing;Packaging machines;Virtual manufacturing;Software testing;Debugging;Program processors;Educational software;IBM 360/370;interrupt handling;I/O channel programming;operating systems;simulation;systems software},
doi={10.1109/TSE.1978.234139},
ISSN={1939-3520},
month={Nov},}
@INPROCEEDINGS{8936300,
author={Martyn, Richard and Jin, Lingling and Todd, Clarence Malcolm},
booktitle={2019 IEEE 10th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)},
title={Development and Application of a Software Tool/Package for Pan-Genomic Analysis},
year={2019},
volume={},
number={},
pages={1038-1042},
abstract={Continuing scientific progress in genetics allows us to better understand how structural variations in an organism's gene content can lead to diversity within a species. By analyzing the sum of the genes for an entire species, we can construct a pangenome for the species. The pangenome of a species is the set of all genes present in all sub-species of a species. It consists of the core genome, which represents the genes present in all sub-species, and a variable genome, which refers to genes not present in all sub-species. micropan is an R package designed for the study of microbial pan-genomics. The genomes of prokaryotes (microbes) are relatively simple, leading to relatively simple construction of their pangenome. By comparison, plant genomes are highly repetitive and complex in comparison, and there is no general tool/package developed for pangenome construction for plant species. Due to the computational requirements of constructing such a pangenome, the tool/package required needs to be more flexible, efficient and robust than micropan. In this paper, we developed a pangenome construction pipeline that works for both prokaryotes and eukaryotes. The design of this pipeline will allow it to adapt to different selections of gene annotation and gene clustering methods. With a more efficient and robust tool/package constructed, future research can discover how to extend it from draft or finished genomes to sequencing reads.},
keywords={Genomics;Bioinformatics;Pipelines;Strain;Proteins;Software;Tools;Genome;pangenome;genes;gene prediction;gene clustering},
doi={10.1109/IEMCON.2019.8936300},
ISSN={2644-3163},
month={Oct},}
@INPROCEEDINGS{8432198,
author={Klaasse, Sebastiaan and Kwintenberg, Geert and Barosan, Ion},
booktitle={2018 IEEE International Conference on Software Architecture Companion (ICSA-C)},
title={Development of a Functional Safety Software Layer for the Control of an Electric In-Wheel Motor Based Powertrain},
year={2018},
volume={},
number={},
pages={144-147},
abstract={This paper describes the development of a software layer which monitors the functional behavior of an electric in-wheel motor controller. Due to the large amount of software, sensors and actuators present in such a powertrain system, the risk of E/E failures that cause hazardous situations needs to be considered. To this end, a software safety layer is developed which detects and controls safety goal violations during runtime. This is realized using a model-based design methodology in accordance with ISO 26262 part 6: Product Development on the Software Level. This paper describes the steps taken in the design and implementation of this functional safety monitoring layer, from requirements modelling in SysML to a MATLAB Simulink model suitable for production code generation.},
keywords={Safety;Torque;Monitoring;Wheels;Mathematical model;Software packages;functional safety;in-wheel motor;model-based design;ISO 26262;torque monitoring},
doi={10.1109/ICSA-C.2018.00043},
ISSN={},
month={April},}
@INPROCEEDINGS{5969051,
author={Huang, Haifeng and Liu, Wei},
booktitle={Proceedings 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services},
title={Development of three dimensional digital tourism presentation system based on Google Earth API},
year={2011},
volume={},
number={},
pages={300-302},
abstract={Three-dimensional digital tourism presentation system (3D-DTPS) is a crucial part of digital tourism. As a relatively mature digital earth software and platform, Google Earth (GE) has been widely used in various fields include digital tourism. Especially the release of GE Plug-in and API makes it possible to build sophisticated 3D web map applications which are just like 3D-DTPS. “Ecological-cultural tourism circle in western Hubei Province” (ECTC-WH) is a regional development policy and planning, and building 3D-DTPS of ECTC-WH (3D-DTPS/ECTC-WH) is the basic informatization construction task. By taking 3D-DTPS/ECTC-WH as an example, this paper expounded the development and implementation of 3D digital map web applications based on GE API, which mainly include 3D scene modeling and main functions implementation, the former is realized by overlaying different professional geospatial data such as HD remote sensing images, thematic vector data, 3D models, tours data to GE and then exporting to KML files, the latter mainly include 3D scene loading, query and location and flight tour. And the result shows that building 3D-DTPS based on GE API is effective, because it can not only make full use of the advantages of GE resources and technologies, but also can easily integrate professional data and functions to build sophisticated 3D web map applications.},
keywords={Three dimensional displays;Earth;Solid modeling;Load modeling;Remote sensing;Google;Data models;Digital earth;digital tourism;3D digital tourism presentation system;Google Earth;ecological-cultural tourism circle in western Hubei Province},
doi={10.1109/ICSDM.2011.5969051},
ISSN={},
month={June},}
@INPROCEEDINGS{13763,
author={Rugheimer, M.K. and Morgan, M.L. and Stymfal, G.T.},
booktitle={IEEE International Conference on Communications, - Spanning the Universe.},
title={Configurable software for advanced telephony applications},
year={1988},
volume={},
number={},
pages={1312-1316 vol.3},
abstract={The term configurable software refers to a concept in which part of the software in a system can be dynamically added or removed as dictated by the needs of the system. The authors describe the GTD-5 EAX, a large class-4/5 digital switching system that uses distributed architecture, and explain the reasons behind its implementation of configurable software. Configurable software helps minimize architectural changes needed to accommodate any additional software needed for system evolution. Also, configurable software provides a foundation and capability for feature packaging. This allows the system to be offered in a variety of packages assigned to meet diversified customer needs.<>},
keywords={Telephony;Application software;Hardware;Packaging;Computer architecture;Software packages;Switches;Databases;Communication system software;Software systems},
doi={10.1109/ICC.1988.13763},
ISSN={},
month={June},}
@INPROCEEDINGS{508976,
author={Wong, A.K.Y. and Yeung, D.S.},
booktitle={Proceedings Second International Symposium on Parallel Architectures, Algorithms, and Networks (I-SPAN'96)},
title={A communication layer for the construction of global, transparent and quasi-optimal virtual machines for distributed computing},
year={1996},
volume={},
number={},
pages={161-167},
abstract={The proposed communication layer is a software building block for constructing virtual machines. The construction process is user-transparent. Many distributed communication layers cooperate automatically to form a single global, quasi-optimal virtual machine to be shared by different parallel programs. The virtual machine conceptually sits between the running parallel processes and the underlying physically-distributed processors. It enables inter-process interaction and utilization of physical resources. Its nodes are mapped to different physical processors, and its performance depends on how echo packets are managed in the system. We combine three mechanisms to facilitate the operations in the communication layer; namely the forward rippling mechanism, the echoing mechanism, and the adaptive breadth-first forward successive inferencing mechanism.},
keywords={Virtual machining;Peer to peer computing;Kernel;Distributed computing;Runtime;Libraries;Parallel programming;Load management;Parallel processing;Computer architecture},
doi={10.1109/ISPAN.1996.508976},
ISSN={1087-4089},
month={June},}
@ARTICLE{486137,
author={Gaing, Z.L. and Lu, C.N. and Chang, B.S. and Cheng, C.L.},
journal={IEEE Transactions on Power Systems},
title={An object-oriented approach for implementing power system restoration package},
year={1996},
volume={11},
number={1},
pages={483-489},
abstract={Due to many unforeseen circumstances that could happen in today's bulk power system, there is a possibility of a system wide outage. In order to provide aids to the power system dispatchers following a complete collapse of the power system, a prototype package has been developed. Through an interactive and friendly graphic interface, the package suggests a guideline for the dispatcher to restore the power system. With an aim to increase the ease of maintenance, an object-oriented technique was adopted to implement the package. The development of the software involved three stages: (1) object oriented analysis, (2) object oriented design, and (3) integration and testing. In this paper, the structure and the development procedure of the prototype system are presented.},
keywords={Power system restoration;Packaging;Prototypes;Object oriented modeling;Guidelines;Transient analysis;Software prototyping;Graphics;Power system analysis computing;Power system transients},
doi={10.1109/59.486137},
ISSN={1558-0679},
month={Feb},}
@INPROCEEDINGS{1631131,
author={Sartipi, K. and Lingdong Ye and Safyallah, H.},
booktitle={14th IEEE International Conference on Program Comprehension (ICPC'06)},
title={Alborz: An Interactive Toolkit to Extract Static and Dynamic Views of a Software System},
year={2006},
volume={},
number={},
pages={256-259},
abstract={Alborz is a multi-view, interactive, and wizard-based software architecture reconstruction and evaluation toolkit that takes advantage of the Eclipse plug-in technology to provide feature extensibility, and uses GXL format to interoperate with other reverse engineering tools. The current version of Alborz toolkit supports static and dynamic views of a software system. For the static view, the toolkit extracts the structure of a software system using wizard-guided forms that allow to define the high-level view of the system. The static view represents abstract components and connectors which are then mapped onto the low-level source graph to find approximate matching within the software system. For the dynamic view, the toolkit extracts high-frequent execution patterns by running feature specific task scenarios on the software system. Subsequently, the implementations of the software features in the source code are identified as a means to evaluate the structure of software. The toolkit will be available as an Eclipse plug-in to serve the software reverse engineering community.},
keywords={Software systems;Software tools;Reverse engineering;Visualization;Software architecture;Connectors;Packaging;Java;Councils;Information analysis},
doi={10.1109/ICPC.2006.8},
ISSN={1092-8138},
month={June},}
@INPROCEEDINGS{5873960,
author={Cattaneo, Paolo W. and Sawada, Ryu},
booktitle={IEEE Nuclear Science Symposuim & Medical Imaging Conference},
title={MEG simulation and analysis software},
year={2010},
volume={},
number={},
pages={1209-1213},
abstract={MEG (Mu to Electron Gamma) is an experiment dedicated to search for the μ+ → e+γ decay that is strongly suppressed in the Standard Model. MEG is a small-size experiment (≈ 50-60 physicists at any time) with a life span of about 10 years. The limited human resource available, in particular in the core offline group, emphasized the importance of reusing software and exploiting already existing expertise. Great care has been devoted to provide a simple system that hides implementation details to the average programmer. That allowed many members of the collaboration to contribute to the development of the software of the experiment with limited technical skill. The software architecture is based on two frameworks: REM in FORTRAN 77 used for the event generation and detector simulation package GEM, based on GEANT 3, and ROME in C++ used in the readout simulation Bartender, reconstruction and analysis program Analyzer. Event display in the simulation is realized relying on GEANT graphics libraries and in the reconstruction on ROOT graphics libraries. Data are stored in different formats in various stage of the processing. The frameworks include utilities for input/output and format conversion transparent to the user.},
keywords={Software;Databases;Analytical models;Libraries;Object oriented modeling;Detectors;Calibration},
doi={10.1109/NSSMIC.2010.5873960},
ISSN={1082-3654},
month={Oct},}
@INPROCEEDINGS{6195200,
author={Panjkov, Zdravko and Katona, Mihajlo and Spasojevic, Danijel and Pele, Zoltan},
booktitle={2012 IEEE 19th International Conference and Workshops on Engineering of Computer-Based Systems},
title={A Case Study in Software Reengineering for a DSP-based System on a Chip: Adaptation of Dolby Virtual Speaker},
year={2012},
volume={},
number={},
pages={303-307},
abstract={An increased complexity of modern computer based systems is accompanied by advanced software architectures embedded into a system. Common approach for designing consumer electronic products includes usage of legacy code with some modifications in order to run it on the targeted platform. Shorter development time and budget constraints are also influencing the process of system design. Thus, reuse of existing legacy source codes as well as inclusion of available open source contributions is widely used in industrial practice. Since each embedded system is having its specific limitations, reuse of embedded software without adaptation to the new platform is not always possible. This paper describes a case study of software reengineering of Dolby Virtual Speaker from the reference platform to the required DSP based system on a chip, including system verification and system validation in real-time conditions. The critical reengineering decisions are elaborated with given results and lessons learned during project implementation.},
keywords={Digital signal processing;Software;Clocks;Conferences;Libraries;Real time systems;Distortion measurement;software reengineering;DSP;audio;validation},
doi={10.1109/ECBS.2012.3},
ISSN={},
month={April},}
@INPROCEEDINGS{8572051,
author={Bezzubtsev, S. and Miroshnik, V. and Skobtsova, Y and Smelyanskiy, R. and Vasin, V. and Volkanov, D. and Zhailauova, S.},
booktitle={2018 International Scientific and Technical Conference Modern Computer Network Technologies (MoNeTeC)},
title={An Approach to the Construction of a Network Processing Unit},
year={2018},
volume={},
number={},
pages={1-12},
abstract={In this paper we consider an approach to designing of a network processing unit (NPU). The paper contains description of proposed NPU architecture with functionally specific processing pipeline stages. It is designed for the set of common use case scenarios, but can be easily extended to other ones. We implemented a simulation model of the proposed NPU architecture using SystemC library and evaluated its performance. Model implementation uses SystemC library. NPU performance evaluation was carried out with simulation model of the proposed NPU architecture.},
keywords={Switches;Pipelines;Computer architecture;Object oriented modeling;Computational modeling;Task analysis;Data models;network processing unit;computer networks;software defined networks;computer architecture;simulation modeling},
doi={10.1109/MoNeTeC.2018.8572051},
ISSN={},
month={Oct},}
@ARTICLE{5876334,
author={Heitmann, Benjamin and Cyganiak, Richard and Hayes, Conor and Decker, Stefan},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
title={An Empirically Grounded Conceptual Architecture for Applications on the Web of Data},
year={2012},
volume={42},
number={1},
pages={51-60},
abstract={We present a component-based, conceptual architecture for Semantic Web applications. It describes the high-level functionality that substantially differentiates Resource Description Framework (RDF)-supported applications from database-driven applications. We provide a strong empirical grounding for this architecture through a survey of Semantic Web applications over most of the past decade. Our empirical approach allows us to describe the current state of the art for the development and deployment of applications on the Web of Data. In addition, we determine how far the adoption of signature research topics of the Semantic Web, such as, data reuse, data integration, and reasoning, has progressed. We, then, discuss the main implementation challenges that developers using Semantic technologies are facing, as observed in the survey. We build on this in order to suggest future approaches to facilitate the standardization of components and the development of software engineering tools to increase the uptake of the Web of Data.},
keywords={Resource description framework;Computer architecture;Service oriented architecture;Libraries;Standards;Semantics;Conceptual architecture;empirical survey;semantic web;software engineering;web of data},
doi={10.1109/TSMCC.2011.2145370},
ISSN={1558-2442},
month={Jan},}
@INPROCEEDINGS{4529434,
author={Seifzadeh, Habib and Kermani, Mostafa and Sadighi, Mohsen},
booktitle={2008 Third International Conference on Availability, Reliability and Security},
title={Dynamic Maintenance of Software Systems at Runtime},
year={2008},
volume={},
number={},
pages={859-865},
abstract={Software systems suffer one basic problem: They are frequently adapted and updated due to changes in requirements and new bugs surfacing. The result of these adaptations is lower availability and missing state of the program. In addition, applying these adaptations requires professional developers which inflict high costs on the organization. In this article, we introduce several methods for adapting programs at run-time without disrupting program execution. This increases system availability. Also, in order to reduce the need for professionals for program modification, some methods that simplify the implementation of new or changed requirements will be offered. As an example, an application written in Java 1.6 has been produced in which both simplification of requirements implementation and hot-swapping (adapting programs at run-time) have been integrated. In this application, we do hot-swapping by using "Java Platform Debugger Architecture API" and attain simplification of presenting new requirements by using "XML-based languages ".},
keywords={Software maintenance;Software systems;Java;Runtime;Programming profession;XML;Availability;Transformers;Security;Computer bugs;Dynamic Software maintenance;Availability;Software requirements;Type-Safety},
doi={10.1109/ARES.2008.155},
ISSN={},
month={March},}
@INPROCEEDINGS{4068564,
author={Su, Jian and Guo, Wei},
booktitle={2006 6th International Conference on ITS Telecommunications},
title={Development of Routing Application of SCA-Based Software Defined Radio},
year={2006},
volume={},
number={},
pages={198-201},
abstract={Software communications architecture (SCA) has become the standard framework followed by the current developing software defined radios (SDR) all over the world. So it is significant for us to develop some essential applications in such an SCA-based SDR. In this paper, we propose an implementation scheme of routing application based on SCA. First, the framework and functions of SCA are introduced briefly. In the following, routing technology is discussed in such a software radio network with multi-layer dynamic topology. Based on SCA, the system architecture on which the routing application depends is presented. We put emphasis on the design of routing components and application program interface (API). Using a sequence diagram, the interaction among routing selection component, adaptive channel selection component and MAC components, is shown clearly},
keywords={Routing;Application software;Software radio;Computer architecture;Hardware;Laboratories;Communication system software;Military standards;Communication standards;Software standards},
doi={10.1109/ITST.2006.288833},
ISSN={},
month={June},}
@INPROCEEDINGS{10053055,
author={Hussain, Razeen and Pizzo, Marianna and Ballestin, Giorgio and Chessa, Manuela and Solari, Fabio},
booktitle={2022 IEEE 5th International Conference on Image Processing Applications and Systems (IPAS)},
title={Experimental Validation of Photogrammetry based 3D Reconstruction Software},
year={2022},
volume={Five},
number={},
pages={1-6},
abstract={3D reconstruction is of interest to several fields. However, obtaining the 3D model is usually a time-consuming task that involves manual measurements and reproduction of the object using CAD software, which is not always feasible (e.g. for organic shapes). The necessity of quickly obtaining a dimensionally accurate 3D model of an object has led to the development of several reconstruction techniques, either vision based (with photogrammetry), using laser scanners, or a combination of the two. The contribution of this study is in the analysis of the performances of currently available 3D reconstruction frameworks with the aim of providing a guideline to novice users who may be unfamiliar with 3D reconstruction technologies. We evaluate various software packages on a synthetic dataset representing objects of various shapes and sizes. For comparison, we consider various metrics such as mean errors in the reconstructed cloud point and meshes and reconstruction time. Our results indicate that Colmap produces the best reconstruction.},
keywords={Solid modeling;Three-dimensional displays;Shape;Software packages;Shape measurement;Measurement by laser beam;Software measurement;3D reconstruction;mesh;photogrammetry;point cloud;structure from silhoutte;structure from motion},
doi={10.1109/IPAS55744.2022.10053055},
ISSN={},
month={Dec},}
@INPROCEEDINGS{72739,
author={Gilboa, U. and Tsabary, O.},
booktitle={[1989] Proceedings. The Fourth Israel Conference on Computer Systems and Software Engineering},
title={Software engineering-from theory to implementation: Ada-conclusions from an operational software development unit using Ada in the Israeli Air-Force},
year={1989},
volume={},
number={},
pages={185-188},
abstract={Conclusions based on the use of the Ada programming language in an air-force unit developing operational software are summarized. The conclusions are grouped according to the aspect of the system's life cycle to which they refer, namely, design, coding, integration, and maintenance. These are followed by some general conclusions. The satisfactory results obtained with Ada have led to the decision to use it as the language for every new system developed.<>},
keywords={Operating systems;Computer languages;Software maintenance;Packaging;System software;Control systems;Large-scale systems;Software systems;Educational institutions;Programming},
doi={10.1109/ICCSSE.1989.72739},
ISSN={},
month={June},}
@INPROCEEDINGS{336721,
author={Wilberg, J. and Camposano, R. and Rosenstiel, W.},
booktitle={Third International Workshop on Hardware/Software Codesign},
title={Design flow for hardware/software cosynthesis of a video compression system},
year={1994},
volume={},
number={},
pages={73-80},
abstract={The implementation of a cosynthesis design flow in the CASTLE (Codesign And Synthesis Tool Environment) system is presented. The design flow generates a synthesizable hardware description and a C, C++, or Fortran compiler for an application-oriented processor. The approach is illustrated by the design of an embedded video compression system which can be integrated into the video card of a PC. The design flow is structured as follows. First, the requirements of the application programs are analyzed. Based on these analysis results, the designer decides on the appropriate processor structure. The processor structure is entered on a block diagram level into the CASTLE system by using a schematic entry. The CASTLE system performs the processor cosynthesis based on a VHDL library of processor components. Several processor datapaths for the video compression system were synthesized to illustrate the trade-offs between flexibility and performance when designing application-oriented processors.<>},
keywords={Hardware;Video compression;Process design;Electronic switching systems;Application software;Libraries;Embedded system;Embedded computing;High performance computing;Performance analysis},
doi={10.1109/HSC.1994.336721},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8876895,
author={Strobel, Manuel and Radetzki, Martin},
booktitle={2019 Forum for Specification and Design Languages (FDL)},
title={A Backend Tool for the Integration of Memory Optimizations into Embedded Software},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Higher functionality combined with increasingly data-hungry and more complex applications make embedded system design steadily more complex. This situation, however, is in direct contrast to development effort in terms of cost and time. A central pillar to face these challenges is system design automation. In this context and regarding increasingly software-centric embedded applications, this work presents a design automation tool for the transparent integration of memory subsystem optimization results into the embedded software at hand. Our solution is based on the LLVM backend and neatly integrated into the LLVM low-level compiler llc. In this paper, the workflow of our code generation method is described in general and further discussed on the example of a concrete implementation for the ARMv6-M architecture. Experiments for this platform and using 10 representative embedded benchmarks prove the functionality of our method by targeted tests and show the successful application of the tool to selected use cases from the field of memory subsystem optimization.},
keywords={Optimization;Tools;Hardware;Libraries;System analysis and design;Embedded systems;Code Generation;LLVM;Static Memory Optimization;System Design Automation;Embedded System Design},
doi={10.1109/FDL.2019.8876895},
ISSN={1636-9874},
month={Sep.},}
@ARTICLE{605762,
author={Mili, R. and Mili, A. and Mittermeir, R.T.},
journal={IEEE Transactions on Software Engineering},
title={Storing and retrieving software components: a refinement based system},
year={1997},
volume={23},
number={7},
pages={445-460},
abstract={Software libraries are repositories which contain software components; as such, they represent a precious resource for the software engineer. As software libraries grow in size, it becomes increasingly difficult to maintain adequate precision and recall with informal retrieval algorithms. In this paper, we discuss the design and implementation of a storage and retrieval structure for software components that is based on formal specifications and on the refinement ordering between specifications.},
keywords={Software libraries;Formal specifications;Software algorithms;Information science;Application software;Information retrieval;Software maintenance;Humans;Maintenance engineering;Computer languages},
doi={10.1109/32.605762},
ISSN={1939-3520},
month={July},}
@INPROCEEDINGS{9449735,
author={Anshuman and Kandaperumal, Gowtham and Linli, Jia and Pannala, Sanjeev and Srivastava, Anurag},
booktitle={2020 52nd North American Power Symposium (NAPS)},
title={RT-RMS: A Real-Time Resiliency Management System for Operational Decision Support},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Power system resiliency has become a key priority for multiple stakeholders, given an observed increase in severe weather events in recent years and impact on the power distribution grid. Distribution network operators need to assess and analyze the resiliency of the system through carefully designed visualization driven by data and model based analytics. Operators require real-time data visualization of system states and resiliency indicators to make correct operational decisions and to control actions to minimize system impact. This paper describes a resilience-driven visualization tool, the Real-Time Resilience Management System Tool (RT-RMS), developed to assist operators in decision making and resilience assessment. RT-RMS utilizes multi-dimensional resilience metrics, geospatial visualization, and data monitors assessing resilience indicators and other key data points. This paper describes the basis of design, design considerations, open-source software components, and use cases demonstrating implementation and discusses the importance of the presented tool, especially in geographically isolated communities, where resilience is valued more than economic operation. The challenge of handling large amounts of data in a web-based application is analyzed by implementing a three-layered architecture and applying RESTful APIs in the back-end. Case studies are presented to highlight key RT-RMS features.},
keywords={Software packages;Data visualization;Restful API;Distribution networks;Computer architecture;Tools;Real-time systems;Power System Resiliency;Distribution Network;Visualization;Operator Support;Software architecture and design;Database},
doi={10.1109/NAPS50074.2021.9449735},
ISSN={},
month={April},}
@INPROCEEDINGS{7204003,
author={Dobrea, Dan Marius and Boţ, Paul},
booktitle={2015 International Symposium on Signals, Circuits and Systems (ISSCS)},
title={An embedded software development package platform for cloud OCR},
year={2015},
volume={},
number={},
pages={1-4},
abstract={In a world focused on the need of selling an increasingly large quantity of goods, quality, visual appearance, texture, flavor, taste etc. become central elements that support the global economic development. As a result, different types of food additives were and are still designed and used to fulfill such objectives. In what follows, the aim of this paper is to present the design and implementation of a new software package for embedded systems (smart phones) able to support a customer in the process of food purchasing. The developed software package runs on an Android platform and uses a cloud optical character recognition (OCR) algorithm. The information related to the product of interest and supplied at request to the customers are: the name and the code of the product's additives, the risks associated with each food additive, the source of each food components, the limit of its daily consumption and the side effects, diet restrictions etc.},
keywords={Optical character recognition software;Additives;Smart phones;Europe;Databases;Cancer},
doi={10.1109/ISSCS.2015.7204003},
ISSN={},
month={July},}
@INPROCEEDINGS{5748785,
author={Pan, Hongxiang},
booktitle={2011 Asia-Pacific Power and Energy Engineering Conference},
title={The Design and Implementation of Information Integration Platform Configure Software Based on Qt},
year={2011},
volume={},
number={},
pages={1-4},
abstract={With the research and development of information integration platform in smart grid, the configuration for dynamic modeling database and some advanced features also made new demands. In comparing the existing cross-platform GUI development tools the pros and cons, the proposed configuration using Qt to develop software, and briefly describes the features of Qt and Qt-based development approach. It focuses on key technologies used in design and implementation of the configuration software. The configuration software has been successfully applied to Smart Substation reconstruction project implementation.},
keywords={Software;Databases;Substations;Libraries;Relays;Object oriented modeling;Graphical user interfaces},
doi={10.1109/APPEEC.2011.5748785},
ISSN={2157-4847},
month={March},}
@INPROCEEDINGS{7444013,
author={Corraya, Anjela Diana and Sumi, Mousumi Akter and Shachi, Sadia Islam and Rahman, Ziaur},
booktitle={2015 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE)},
title={Guiding software developers by social networking application plug-in using the multiple bridge source repository through a data mining integrated approach},
year={2015},
volume={},
number={},
pages={118-121},
abstract={In today's world social networking is an important (powerful) medium of mass communication. People of almost all classes have been interacting each other and sharing their views, moments and ideas by using enormous user friendly applications in different social networking sites. It is really unbelievable to find a person who has never heard about the social networking system. The available social networking sites usually opportune their users to develop various customized applications through particular templates and embedded sources of codes. The users with average knowledge of development often encounter difficulties to reuse those resources and eventually lack guidelines and necessary API recommendations. In our work, we have proposed a framework and model to help those apps developer through a user assistance plug-in tool that is able to provide identical API usage patterns and sequences in response to a particular user query. We have titled our system as Social Networking Application Plug-in (SNAP). It searches social networking apps repository where multiple storage are bridged and apply respective mining algorithm to find the relevant sequences to fulfill the user needs. It provides similar, most relevant and functional API usage scenarios as well as gives an option to choose, reuse and modify the recommended sources. From the investigations we have ever made, the SNAP approach is capable to recommend error-free, understandable and minimal API patterns.},
keywords={Social network services;Data mining;Search engines;Pattern matching;Browsers;Context;Filtering;Bridged Source Repository;Customized Application;API Recommendations;Usage Scenario;Sequence Mining},
doi={10.1109/WIECON-ECE.2015.7444013},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5070827,
author={Moreira, Gabriel de_Souza Pereira and Montini, Denis Ávila and Fernandes, Danilo Douradinho and Cardoso, Felipe Rafael Motta and Dias, Luiz Alberto Vieira and da Cunha, Adilson Marques},
booktitle={2009 Sixth International Conference on Information Technology: New Generations},
title={Final Inspection for Design Pattern Homologation Using a Real Time Embedded Software in a Production Line},
year={2009},
volume={},
number={},
pages={1428-1435},
abstract={This paper summarizes a research process applied to final inspection (FI) and causal analysis for problems resolution (CAR) using a real time embedded software component in a production line. It uses C++ language in an IBM-rational rose real time (RRRT) environment. It tackles the creation of a consistent homologation process to eliminate componentspsila errors, imperfections, and defects even before design patternspsila publications in a library. Its major contribution is the construction of an FI artifact for a software component related to CAR. It proposes an industrial model for an FI process of design patternspsila homologation using an integrated computer aided software engineering environment (I-CASE-E). It considers a design pattern that was identified in a project, described, stored in a library, and successfully reused in another project. The use of rational unified process (RUP) has helped teams of undergrad and graduate students from the Brazilian Aeronautics Institute of Technology (Instituto Tecnologico de Aeronautica - ITA) to develop their components, during the second semester of 2007. The RUP utilization has provided a fertile scenario to create and apply design pattern concepts. At the end, different computer software components (CSC) were homologated with their attributes and generic methods allowing reusability.},
keywords={Inspection;Embedded software;Production;Software libraries;Computer errors;Computer industry;Construction industry;Process design;Computer aided software engineering;Software reusability;FI;CAR;Homologation;Testing;Design Patterns;Real Time Embedded System},
doi={10.1109/ITNG.2009.196},
ISSN={},
month={April},}
@INPROCEEDINGS{9282686,
author={Vassiliou-Gioles, Theofanis},
booktitle={2020 IEEE 20th International Conference on Software Quality, Reliability and Security Companion (QRS-C)},
title={A simple, lightweight framework for testing RESTful services with TTCN-3},
year={2020},
volume={},
number={},
pages={498-505},
abstract={Micro-service architecture has become a standard software architecture style, with loosely coupled, specified, and implemented services, owned by small teams and independently deployable. TTCN-3, as test specification and implementation language, allows an easy and efficient description of complex distributed test behavior and seems to be a natural fit to test micro-services. TTCN-3 is independent of the underlying communication and data technology, which is strength and weakness at the same time. While tools and frameworks are supporting micro-service developers to abstract from the underlying data, implementation, and communication technology, this support has to be modeled in a TTCN-3 based test system, manually. This paper discusses the concepts of a TTCN-3 framework on the four different levels of the Richardson-Maturity Model, introducing support for testing hypermedia controls, HATEOAS, proposes a TTCN-3 framework and open-source implementation to realize them and demonstrates its application by a concrete example.},
keywords={Software architecture;Software quality;Tools;Software reliability;Security;Standards;Testing;TTCN-3;Software testing;test automation;micro service;RESTful API;web service},
doi={10.1109/QRS-C51114.2020.00089},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5530095,
author={Chen, Ing-Yi and Ni, Guo-Kai and Kuo, Cheng-Hwa and Lin, Chau-Young},
booktitle={2010 7th International Conference on Service Systems and Service Management},
title={A service-oriented management framework for telecom operation support systems},
year={2010},
volume={},
number={},
pages={1-5},
abstract={Information systems are among the tools most frequently used by businesses in delivering and maintaining services. Yet the challenges faced by enterprises using information technology are not exclusively linked to system development, but are also derived from system operation and management. This paper describes a solution that was developed to address the importance of service operation management. The framework presented here was implemented by the Chunghwa Telecom Company in an effort to improve information system effectiveness and to reduce costs of system operation management. Since July 2008, the system has been providing complete support of the daily operations of the company's billing system. In consequence of the system's implementation, the company has experienced a large-scale improvement in both efficiency and cost reduction. Additionally, the number of incident occurrences has been reduced from an average of 50 monthly to 15. The average amount of time spent addressing individual incidents has also been reduced from approximately 20 hours to 26 minutes.},
keywords={Telecommunications;Technology management;Management information systems;Condition monitoring;Information technology;Companies;Guidelines;Engineering management;Costs;Information management;Service-Oriented Architecture;IT Service Management (ITSM);Information Technology Infrastructure Library (ITIL);Next Generation Operations System and Software (NGOSS);Service Operation Management;Service Operation Management Framework;Monitoring Technology},
doi={10.1109/ICSSSM.2010.5530095},
ISSN={2161-1904},
month={June},}
@INPROCEEDINGS{9828724,
author={Petrović, Nenad N.},
booktitle={2022 57th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)},
title={COVID-19 Prevention Systems within Hardware and Software Design Computer Science Courses},
year={2022},
volume={},
number={},
pages={1-4},
abstract={This paper proposes pandemic support system design exercises from both hardware and software perspective as constituent part of higher education computer science courses. Two case studies in context of computer science and automation study programmes at University of Niš, Faculty of Electronic Engineering in Serbia ae covered: Intelligent Information Systems and Microcontroller Programming. In case of the first one, the topics cover information system implementation relying on Java Enterprise Edition (JEE) technology with presence of machine learning elements provided by Weka API, so smart vaccination process support information system is presented as example. On the other side, the focus on the second course is on PIC16 family microcontrollers and RTOS-based system implementation using CCS C compiler and presented example represents control unit for indoor coronavirus safety control.},
keywords={COVID-19;Software design;Microcontrollers;Pandemics;Hardware;Vaccines;Programming profession;education;Java Enterprise Edition (JEE);pandemic;PIC16F84A;RTOS;Weka},
doi={10.1109/ICEST55168.2022.9828724},
ISSN={},
month={June},}
@INPROCEEDINGS{1585743,
author={Wyleczuk, R. and Meyer, L. and Babcock, G.},
booktitle={20th Design Automation Conference Proceedings},
title={The Transfer of University Software for Industry Use},
year={1983},
volume={},
number={},
pages={756-761},
abstract={Computer-aided engineering software is generated in abundance in educational institutions. As a major source of design automation software, universities have a lot to offer: a progressive research environment; a seemingly inexhaustible supply of software engineers in the form of undergraduates, graduate engineers, and professors; and a no-risk, multi-disciplinary design lab for experimentation. For these reasons, university software is being widely sought for use in production/commercial environments. This paper examines the interface between industry and the universities during the transfer of design automation software. A printed circuit board router, a graphics subroutine library, and a circuit simulation program are used to illustrate issues arising from the technology transfer. Guidelines to increase the likelihood of success in such transfers of software are provided.},
keywords={Computer industry;Design automation;Design engineering;Educational institutions;Production;Printed circuits;Graphics;Algorithms;Software libraries;Circuit simulation},
doi={10.1109/DAC.1983.1585743},
ISSN={0738-100X},
month={June},}
@INPROCEEDINGS{1443322,
author={Santoro, A. and Quaglia, F.},
booktitle={Workshop on Principles of Advanced and Distributed Simulation (PADS'05)},
title={Transparent state management for optimistic synchronization in the high level architecture},
year={2005},
volume={},
number={},
pages={171-180},
abstract={In this paper we present the design and implementation of a software architecture, namely Magic State Manager (MASM), to be employed within a run-time infrastructure (RTI) in support of HLA federations. MASM allows performing checkpointing/recovery of the state of a federate in a way completely transparent to the federate itself, thus providing the possibility of demanding to the RTI any task related to state management in optimistic synchronization. Differently from existing proposals, through our approach the federate programmer is neither required to supply modules for state management within the federate code, nor to explicitly interface the federate code with existing, third party checkpointing/recovery libraries. Hence, the federate programmer is completely relieved from the burden of facing state management issues. Some experimental results demonstrating minimal run-time overhead introduced by MASM are also reported for two case studies, namely an interconnection network simulation and a personal communication system simulation.},
keywords={Checkpointing;Middleware;Software architecture;Runtime;Computer architecture;Programming profession;Remuneration;Proposals;Libraries;Multiprocessor interconnection networks},
doi={10.1109/PADS.2005.34},
ISSN={1087-4097},
month={June},}
@INPROCEEDINGS{318464,
author={Wakefield, G.S. and Dziegiel, R. and Pullum, L.L.},
booktitle={Proceedings of COMPASS'94 - 1994 IEEE 9th Annual Conference on Computer Assurance},
title={Centurion software fault tolerance design and analysis tool},
year={1994},
volume={},
number={},
pages={93-100},
abstract={Describes the Centurion computer-aided software fault tolerance design and analysis tool. The tool is a product of a research and development project focused on automated tools for use in design, assessment, and insertion of software fault tolerance techniques into Air Force systems. The Centurion tool allows users to analyze developmental and fielded software, and the associated computer and communications hardware, to identify fault tolerance requirements and evaluate alternative fault tolerant designs. The Centurion capabilities include interactive graphic construction software, hardware, and fault tolerance models; storage and retrieval of template and model libraries; simulation of the constructed models, with data logging and run-time user inputs permitted; and post-processing with tabular and graphic output formats available. Actual software modules can be associated with nodes within Centurion graphs and linked into the model simulation. The current Centurion tool is available on Sun SPARCStations, and is currently being ported to DEC Alpha workstations.<>},
keywords={Software tools;Fault tolerance;Software design;Military computing;Hardware;Research and development;Fault tolerant systems;Fault diagnosis;Computer graphics;Information retrieval},
doi={10.1109/CMPASS.1994.318464},
ISSN={},
month={June},}
@INPROCEEDINGS{9276620,
author={Chen, Yang and Santosa, Andrew E. and Sharma, Asankhaya and Lo, David},
booktitle={2020 IEEE/ACM 42nd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
title={Automated Identification of Libraries from Vulnerability Data},
year={2020},
volume={},
number={},
pages={90-99},
abstract={Software Composition Analysis (SCA) has gained traction in recent years with a number of commercial offerings from various companies. SCA involves vulnerability curation process where a group of security researchers, using various data sources, populate a database of open-source library vulnerabilities, which is used by a scanner to inform the end users of vulnerable libraries used by their applications. One of the data sources used is the National Vulnerability Database (NVD). The key challenge faced by the security researchers here is in figuring out which libraries are related to each of the reported vulnerability in NVD. In this article, we report our design and implementation of a machine learning system to help identify the libraries related to each vulnerability in NVD. The problem is that of extreme multi-label learning (XML), and we developed our system using the state-of-the-art FastXML algorithm. Our system is iteratively executed, improving the performance of the model over time. At the time of writing, it achieves F1 @1 score of 0.53 with average F1 @k score for $k=1,2,3$ of 0.51 $(F_{1}$ @k is the harmonic mean of precision@k and recall@k). It has been deployed in Veracode as part of a machine learning system that helps the security researchers identify the likelihood of web data items to be vulnerability-related. In addition, we present evaluation results of our feature engineering and the FastXML tree number used. Our work formulates and solves for the first time library name identification from NVD data as XML, and deploys the solution in a complete production system.CCS CONCEPTS• Security and privacy → Software security engineering; • Software and its engineering → Software maintenance tools.},
keywords={Libraries;Training;Security;Databases;Machine learning;XML;Data models;application security;open source software;machine learning},
doi={},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9802464,
author={Vasiliev, Oleg V. and Zyabkin, Sergey A. and Peshko, Aleksandr S.},
booktitle={2022 XIX Technical Scientific Conference on Aviation Dedicated to the Memory of N.E. Zhukovsky (TSCZh)},
title={A Software Simulator of Signal and Interference Conditions for Aircraft Weather Radar Testing and Certification},
year={2022},
volume={},
number={},
pages={79-84},
abstract={This paper presents the problems of development and application of a software simulator of signal and interference conditions for domestic aircraft weather radar testing and certification introduction. The emphasis is placed on ensuring verification of radar performance in terms of detecting turbulence and wind shear zones. The relevance of the development of simulation models for certification according to the RTCA DO220A standard is grounded. The structure and features of the radar signals generation unit construction from hazardous weather events based on the Airborne Weather Doppler Radar Simulation software package are described. There is represented the methodology for the interference reflections from ground urban objects modeling by approximating satellite maps with a set of point reflectors with known RCS. GUI for analyzing input data is demonstrated.},
keywords={Meteorological radar;Radar cross-sections;Spaceborne radar;Atmospheric modeling;Airborne radar;Radar detection;Interference;aircraft weather radar;aircraft weather radar certification;RTCA DO220 standard;signal and interference conditions;simulation modeling},
doi={10.1109/TSCZh55469.2022.9802464},
ISSN={},
month={April},}
@INPROCEEDINGS{591815,
author={Neuhaus, J. and Janzen, W. and Backer, A.},
booktitle={Proceedings 8th Conference on Software Engineering Environments},
title={A case study in repository selection for a distributed software engineering environment},
year={1997},
volume={},
number={},
pages={35-41},
abstract={The German Ministers of Finance have set up a large-scale project for the development of a nationwide uniform tax management system. One phase of the initiation of this large software development effort was the construction of a distributed software engineering environment. The Fraunhofer ISST (Institut fu/spl uml/r Software- und Systemtechnik) and Partner Consult were involved in the selection process of the repository, and the change and configuration management tool for this environment. In this paper, we describe the selection process for the repository. We present a structured approach which tries to minimize the selection costs, and we discuss some of the lessons we learned about the process itself and the state of the market in repository technology.},
keywords={Computer aided software engineering;Software engineering;Programming;Financial management;Project management;Large-scale systems;Environmental management;Costs;Software development management;Computer architecture},
doi={10.1109/SEE.1997.591815},
ISSN={},
month={April},}
@INPROCEEDINGS{1583390,
author={Miani, S. and Savorgnan, C.},
booktitle={Proceedings of the 44th IEEE Conference on Decision and Control},
title={MAXIS-G: a software package for computing polyhedral invariant sets for constrained LPV systems},
year={2005},
volume={},
number={},
pages={7609-7614},
abstract={In this paper, a software package for computing the maximal invariant set of constrained linear parameter varying (LPV) systems is presented. The theoretical details at the basis of the proposed algorithm are first briefly illustrated along with the extensions which allow to deal with systems affected by disturbances and different kinds of uncertainty. Then, the algorithm is presented together with some comments on its actual implementation.},
keywords={Software packages;Robustness;Uncertainty;Software algorithms;Discrete time systems;Time varying systems;Bismuth;Control design;Switched systems},
doi={10.1109/CDC.2005.1583390},
ISSN={0191-2216},
month={Dec},}
@INPROCEEDINGS{624915,
author={Seung-Ki Ryu and Tae-Hwan Han and Jeong-Woong Ryu},
booktitle={Proceedings of the 36th SICE Annual Conference. International Session Papers},
title={A study on the multi-hierarchical maintenance system of electrical demand facilities for building intelligent},
year={1997},
volume={},
number={},
pages={1057-1060},
abstract={Large modern buildings have multihierarchical maintenance systems to control the facilities in them. The article considers especially the maintenance of electrical facilities. This is usually the job of a person in charge, but if the person in charge is insufficiently experienced in management work, he can't promote the efficiency of maintenance works in electrical facilities. In this paper, we've developed the multihierarchical maintenance system that processes maintenance data of electrical demand facilities. The maintenance system is an optimum control software package for building electrical facility.},
keywords={Control systems;Buildings;Software packages;Software maintenance;Productivity;Accidents;Switches;Databases;History;Intelligent structures},
doi={10.1109/SICE.1997.624915},
ISSN={},
month={July},}
@ARTICLE{5271529,
author={Zhang, Liang-Jie and Zhang, Jia},
journal={IT Professional},
title={An Integrated Service Model Approach for Enabling SOA},
year={2009},
volume={11},
number={5},
pages={28-33},
abstract={To effectively align business and IT using a service-oriented architecture (SOA), a proposed integrated service model divides service construction into three loosely coupled perspectives according to the service's business logic, interface, and implementation. The resulting hierarchical model and associated methodology can help software architects more effectively and efficiently design and develop services-oriented systems.},
keywords={Intserv networks;Service oriented architecture;Application software;Web services;Companies;Spine;Organizing;Software packages;Packaging;Large-scale systems;Service model;service-oriented architecture;SOA solutions},
doi={10.1109/MITP.2009.90},
ISSN={1941-045X},
month={Sep.},}
@INPROCEEDINGS{198782,
author={Draper, C.M. and Holding, D.J.},
booktitle={IEE Colloquium on Control Systems Software Reliability for Industrial Applications},
title={Specification and verification of the real-time synchronisation software for a modular independently driven high-speed machine},
year={1989},
volume={},
number={},
pages={6/1-6/4},
abstract={Describes research into the design of real-time synchronisation software for a high-speed packaging machine utilising independent drives. The machine is of a novel modular design which exploits the flexibility that is introduced by the use of software controlled independent drives. It is intended for use in flexible manufacturing applications in which large quantities of various products are produced by one high-speed machine. The research involved the specification of the control and synchronisation requirements of the machine using a concurrent language and the design and implementation of a transputer-based distributed control system capable of high-speed performance. This involved software design using the concurrent programming language Occam and software modelling and verification using Petri-nets.<>},
keywords={Distributed control;Flexible manufacturing systems;Microcomputer applications;Parallel languages;Packaging;Parallel processing;Petri nets;Software verification and validation;Real time systems;Synchronization;Microprocessors},
doi={},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6685794,
author={Eler, Marcelo Medeiros and Masiero, Paulo Cesar},
booktitle={2013 VII Brazilian Symposium on Software Components, Architectures and Reuse},
title={BISTFaSC: An Approach to Embed Structural Testing Facilities into Software Components},
year={2013},
volume={},
number={},
pages={89-98},
abstract={Component-based applications can be composed by in-house or COTS (Commercial off-the-shelf) components. In many situations, reused components should be tested before their integration into an operational environment. Testing components is not an easy task because they are usually provided as black boxes and have low testability. Built-in Testing (BIT) is an approach devised to improve component testability by embedding testing facilities into software components usually to support specification-based testing.Such components are called testable components. There are situations, however, in which combining specification and program-based testing is desirable. This paper proposes a BIT technique designed to introduce testing facilities into software components at the provider side to support structural testing at the user side, even when the source code is unavailable. An implementation to generate testable components written in Java is also presented. The approach was firstly evaluated by an exploratory study conducted to transform COTS components into testable components.},
keywords={Testing;Software;Probes;Java;Libraries;Maintenance engineering;Software component;structural testing;testable component},
doi={10.1109/SBCARS.2013.20},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6846443,
author={Rughetti, Diego and Sanzo, Pierangelo Di and Ciciani, Bruno and Quaglia, Francesco},
booktitle={2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
title={Analytical/ML Mixed Approach for Concurrency Regulation in Software Transactional Memory},
year={2014},
volume={},
number={},
pages={81-91},
abstract={In this article we exploit a combination of analytical and Machine Learning (ML) techniques in order to build a performance model allowing to dynamically tune the level of concurrency of applications based on Software Transactional Memory (STM). Our mixed approach has the advantage of reducing the training time of pure machine learning methods, and avoiding approximation errors typically affecting pure analytical approaches. Hence it allows very fast construction of highly reliable performance models, which can be promptly and effectively exploited for optimizing actual application runs. We also present a real implementation of a concurrency regulation architecture, based on the mixed modeling approach, which has been integrated with the open source Tiny STM package, together with experimental data related to runs of applications taken from the STAMP benchmark suite demonstrating the effectiveness of our proposal.},
keywords={Concurrent computing;Analytical models;Training;Proposals;Computational modeling;Reliability;Data models;Software Transactional Memory;Performance Models;Concurrency;Performance Optimization;Energy Optimization},
doi={10.1109/CCGrid.2014.118},
ISSN={},
month={May},}
@INPROCEEDINGS{985781,
author={Tarver, B. and Christensen, E. and Miller, A.},
booktitle={2001 MILCOM Proceedings Communications for Network-Centric Operations: Creating the Information Force (Cat. No.01CH37277)},
title={Software defined radios (SDR) platform and application programming interfaces (API)},
year={2001},
volume={1},
number={},
pages={153-157 vol.1},
abstract={A software defined radio, as defined by the Federal Communications Commission (FCC) Notice of Proposed Rule Making (NPRM), FCC 00-430, is fully software driven and performs all digital signal processing using programmable digital signal processors, general purpose microprocessors, or field programmable gate arrays. All functions, modes, and applications can be reconfigured by software. More importantly, new capability can be added without hardware changes enabling a new generation of communication waveform developers to create new applications without intimate alliances with radio manufacturers. However, to be successful, the union of the application with the platform must be clearly understood with well-defined application programming interfaces (APIs). The well-defined interfaces form the contract between the application developer and the platform developer. The well-defined interfaces allow an application developer to develop an application once, that executes on many different manufacturers' platforms and provides the platform developer consistent interfaces under which platform technologies can evolve separately from the application. An application is independent of the platform it runs on if it is not coupled to a specific platform implementation, i.e., does not require platform unique hardware or software components for execution. The application accesses platform services through well-defined public interfaces that support the entire lifecycle of the application, i.e., from installation of the application through removal of the application from any given platform. This paper discusses SDR software architecture features, the need and definition of a common set of APIs and their extensibility into classes addressing factors such as cost and capability.},
keywords={Software radio;Application software;FCC;Hardware;Manufacturing;Software performance;Digital signal processing;Digital signal processors;Microprocessors;Field programmable gate arrays},
doi={10.1109/MILCOM.2001.985781},
ISSN={},
month={Oct},}
@INPROCEEDINGS{4776621,
author={Sima, Vasile and Tits, Andre L. and Yang, Yaguang},
booktitle={2006 IEEE Conference on Computer Aided Control System Design, 2006 IEEE International Conference on Control Applications, 2006 IEEE International Symposium on Intelligent Control},
title={Computational experience with robust pole assignment algorithms},
year={2006},
volume={},
number={},
pages={36-41},
abstract={Two algorithms for robust pole assignment by state feedback, proposed by Kautsky, Nichols and Van Dooren (1985) and by Tits and Yang (1996) are briefly reviewed. MATLAB code implementations of these algorithms, place (from the MATLAB Control System Toolbox) and robpole (from SLICOT), are then numerically compared on randomly generated test data sets, as well as on examples from two benchmark collections, in terms of the robustness (insensitivity of poles to variations in plant parameters) of the closed-loop systems they produce. The functions place and robpole are also compared with each other, as well as with the (non robust) pole assignment code pass (from SLICOT) in terms of CPU time and accuracy of the pole assignment.},
keywords={Robustness;Eigenvalues and eigenfunctions;Control systems;State feedback;Robust control;MATLAB;System testing;Libraries;Benchmark testing;Linear feedback control systems;computer-aided control system design;numerical algorithms;numerical linear algebra;pole assignment;software library},
doi={10.1109/CACSD-CCA-ISIC.2006.4776621},
ISSN={2165-302X},
month={Oct},}
@INPROCEEDINGS{390395,
author={Ramachandran, M.},
booktitle={Proceedings of Twentieth Euromicro Conference. System Architecture and Integration},
title={Language-oriented reusability},
year={1994},
volume={},
number={},
pages={148-151},
abstract={Software component reuse is the key to significant gains in software productivity. Language-oriented reusability is a process of utilising language features effectively. Reuse guidelines should represent the characteristics of reusable components. Earlier works on reuse guidelines have concentrated mainly on managerial problems and general design issues. This paper identifies, in detail, Ada's support for various approaches to component reuse such as building blocks, object-based, parameterisation, and genericity. These investigations are integrated into a set of guidelines which provide objective detailed advice on how to construct reusable components. These guidelines are partially automated by a prototype tool called ARA (The Ada Reuse Assessor) which generates reusable Ada components and provides reuse advice and analysis.<>},
keywords={Guidelines;Productivity;Software engineering;Software systems;Costs;Software reusability;Object oriented programming;Software libraries;LAN interconnection;Encapsulation},
doi={10.1109/EURMIC.1994.390395},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8364043,
author={Fanguede, Jeremy and Paolino, Michele and Dimitrov, Dimitar and Virtual, Daniel Raho},
booktitle={2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)},
title={A novel pflua-based OpenFlow implementation for VOSYSwitch},
year={2018},
volume={},
number={},
pages={43-49},
abstract={Software Defined Network (SDN) along with Network Function Virtualization (NFV) paradigms are emerging as a viable alternative to traditional network architecture. The Fog and Mobile Edge computing network and the Internet of Things infrastructure are adopting these concepts as well. In this context, virtual and SDN-enabled switches are crucial. This paper presents the novel OpenFlow software implementation of VOSYSwitch, the high performance virtual switch solution developed by Virtual Open Systems. Written in Lua, such OpenFlow implementation takes advantage of the library pflua and of the LuaJIT just-in-time trace compiler to translate OpenFlow flows into Lua code via the PCAP Filter language. As a consequence, the code executed to perform the flow matching and actions is generated on demand and tailored to the flow entries of the forwarding tables of the dataplane. Benchmarking activities, whose results are included in this paper, have been performed to compare this new OpenFlow switch implementation with the de-facto standard OpenFlow switch solution OVS-DPDK. The results show that VOSYSwitch OpenFlow implementation is superior to OVS-DPDK for environments with simple flow configurations and low number of entries, typical of Edge Computing.},
keywords={Bridges;Instruction sets;Libraries;Edge computing;Open systems;Benchmark testing;Software Switch;OpenFlow;pflua;LuaJIT;software switch benchmark;VOSYSwitch;OVS-DPDK},
doi={10.1109/FMEC.2018.8364043},
ISSN={},
month={April},}
@ARTICLE{5221768,
author={Pau, L. F. and Toghrai, C.},
journal={IEEE Transactions on Reliability},
title={A Software Package for Statistical Quality Control of Instrumentation},
year={1984},
volume={R-33},
number={2},
pages={172-175},
abstract={The software package contains both usual and new acceptance sampling procedures (essentially by variables) especially for instrumentation and automatic test systems. The main newer procedures implemented in this package are: * By attributes: with finite lot sizes, with classification errors * By variables: bilateral test of the mean measurement, nonparametric sequential, Bayes with minimization of the mean global cost, multidimensional measurements on each sample item, with provision for the internal structure of the items. This software package is aimed at implementation on microprocessors or personal computers, for acceptance sampling by variables and for data logging of measurements. The past four years during which the package has been in use, have been very positive, especially for those applications to electronic instrumentation and automatic test systems, where more standard methods were unsatisfactory or unfit.},
keywords={Software packages;Quality control;Instruments;Sampling methods;Automatic testing;System testing;Packaging;Size measurement;Software testing;Computer errors;Acceptance sampling by variables;Instrumentation;Computer program},
doi={10.1109/TR.1984.5221768},
ISSN={1558-1721},
month={June},}
@INPROCEEDINGS{7339841,
author={Czumbil, Levente and Micu, Dan D. and Munteanu, Calin and Stet, Denisa and Tomoioaga, Bogdan},
booktitle={2015 50th International Universities Power Engineering Conference (UPEC)},
title={Optimal design of the pipeline right-of-way nearby high voltage transmission lines using genetic algorithms},
year={2015},
volume={},
number={},
pages={1-5},
abstract={Underground or above ground metallic pipeline placed in the vicinity of high voltage transmission lines are exposed to AC electromagnetic interference effects. Therefore, at design stage one should determine the proper pipeline right-of-way in order to minimize the level of induced AC current and voltages due to electromagnetic coupling effects, and in the same time to reduce construction costs. A genetic algorithm based pipeline right-of-way optimization tool box has been implemented in the InterfStud EMI software application, developed by the authors. Two different, underground pipeline next to overhead power line, case studies are analysed to test the implemented optimization tool box.},
keywords={Pipelines;Optimization;Genetic algorithms;Layout;Electromagnetic interference;Software;Power transmission lines;electromagnetic interference;genetic algorithms;optimal design;integrated software package;high voltage power lines;metallic pipelines},
doi={10.1109/UPEC.2015.7339841},
ISSN={},
month={Sep.},}
@ARTICLE{7829420,
author={Fischbach, Martin and Wiebusch, Dennis and Latoschik, Marc Erich},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Semantic Entity-Component State Management Techniques to Enhance Software Quality for Multimodal VR-Systems},
year={2017},
volume={23},
number={4},
pages={1342-1351},
abstract={Modularity, modifiability, reusability, and API usability are important software qualities that determine the maintainability of software architectures. Virtual, Augmented, and Mixed Reality (VR, AR, MR) systems, modern computer games, as well as interactive human-robot systems often include various dedicated input-, output-, and processing subsystems. These subsystems collectively maintain a real-time simulation of a coherent application state. The resulting interdependencies between individual state representations, mutual state access, overall synchronization, and flow of control implies a conceptual close coupling whereas software quality asks for a decoupling to develop maintainable solutions. This article presents five semantics-based software techniques that address this contradiction: Semantic grounding, code from semantics, grounded actions, semantic queries, and decoupling by semantics. These techniques are applied to extend the well-established entity-component-system (ECS) pattern to overcome some of this pattern's deficits with respect to the implied state access. A walk-through of central implementation aspects of a multimodal (speech and gesture) VR-interface is used to highlight the techniques' benefits. This use-case is chosen as a prototypical example of complex architectures with multiple interacting subsystems found in many VR, AR and MR architectures. Finally, implementation hints are given, lessons learned regarding maintainability pointed-out, and performance implications discussed.},
keywords={Semantics;Couplings;Software quality;Computer architecture;Data models;Virtual environments;Real-time interactive systems;virtual reality systems;software architecture;multimodal processing},
doi={10.1109/TVCG.2017.2657098},
ISSN={1941-0506},
month={April},}
@INPROCEEDINGS{5228210,
author={Xing Jinjiang and Li Jian and Zhou Hong and Yang Wen},
booktitle={2009 4th International Conference on Computer Science & Education},
title={Extendable expert rule model and implementations in manned space mission collaboration planning},
year={2009},
volume={},
number={},
pages={876-879},
abstract={In manned space mission collaboration planning, expert rules are used to raise the efficiency of automatic scheduling. A method based on stack is proposed in this paper to organize the rules in strict format so that they can be traced and maintained. Internal rule library is a collection of rules which defined within planning system. Due to mission variability, the rule library needs to be extended and extension solutions are proposed in three levels. With its support, the experts can use internal rules and also add additional rules which are more complex. Implementation techniques of extendable rules are also discussed in respects of data structure and extension resources. With rules and extendable rule libraries, collaboration plan are scheduled more easily.},
keywords={Space missions;Collaborative software;Timing;Scheduling;Libraries;Computer science;Computer science education;International collaboration;Aerospace control;Conference management;Expert Rule;Manned Space Mission;Collaboration Plan;Software Extendibility;VSTA;Python;LUA},
doi={10.1109/ICCSE.2009.5228210},
ISSN={},
month={July},}
@INPROCEEDINGS{4418143,
author={Murphy, Marguerite C. and Yildirim, Bilsay},
booktitle={2007 37th Annual Frontiers In Education Conference - Global Engineering: Knowledge Without Borders, Opportunities Without Passports},
title={Work in progress - testing right from the start},
year={2007},
volume={},
number={},
pages={F1H-25-F1H-26},
abstract={Writing syntactically correct code and understanding algorithm development are two essential skills mastered by most introductory computer science students. Another important component of professional programming is thorough testing to verify correct design and accurate coding; however this topic is frequently covered with less emphasis than it deserves in the core programming curricula. In this paper we describe instructional software that we are developing to support introductory level programming students in collaboratively and incrementally developing test cases for the class libraries they implement, as well as to automatically validate their implementations. This software is structured as an Internet application with a simplified user interface that allows distributed generation of a common library of test cases as well as remote testing of each student's individual implementation. By integrating testing and validation into the earliest stages of programming instruction, we anticipate that students will develop a better understanding of not only the syntax of the programming languages they are using but, more importantly, a deeper understanding of the semantics of the code they author and better success in debugging initial versions of their program solutions. Furthermore, using an Internet based infrastructure allows students to become familiar with having different aspects of the program development process itself performed by different (teams) of individuals, each of whom might be geographically distributed: an important practical component of global software engineering. A fully functional on-line version of our software is expected by the end of Summer 2007 and Human Subjects Protocol approval is expected for Fall 2007 evaluation of the effectiveness of our software in instructing introductory level programming students.},
keywords={Programming profession;Software testing;Collaborative software;Software libraries;Internet;Writing;Computer science;Automatic programming;Automatic testing;Application software;educational software;introductory programming instruction;program testing;web application},
doi={10.1109/FIE.2007.4418143},
ISSN={2377-634X},
month={Oct},}
@INPROCEEDINGS{514695,
author={Wells, C.H. and Brand, R. and Markosian, L.},
booktitle={Proceedings of 2nd Working Conference on Reverse Engineering},
title={Customized tools for software quality assurance and reengineering},
year={1995},
volume={},
number={},
pages={71-77},
abstract={Describes a new approach to developing tools for measuring and documenting source code compliance with design and coding standards. It also presents preliminary results of applying this approach to software developed for the electrical utility industry. The approach is based on an enabling technology for software evaluation and reengineering. The key technical ideas underlying the technology are to represent source code in the form of abstract syntax trees in an object-oriented database, and to use a library of utilities to analyze software represented in this way. This enabling technology supports rapid implementation and testing of customized design and coding standards. The standards were defined by the Electric Power Research Institute (EPRI). We describe a prototype toolset that we have used for measuring compliance of over 3 million lines of C and Fortran source code as part of evaluating legacy systems that are being reengineered, as well as for performing quality assurance of new applications.},
keywords={Software quality;Code standards;Measurement standards;Standards development;Computer industry;Object oriented databases;Software libraries;Testing;Software prototyping;Prototypes},
doi={10.1109/WCRE.1995.514695},
ISSN={},
month={July},}
@INPROCEEDINGS{5573594,
author={Du, Qiliang and Zhang, Qin and Tian, Lianfang},
booktitle={Proceedings of the 29th Chinese Control Conference},
title={Developing a control software for a miniaturerobot-based micromanipulation system},
year={2010},
volume={},
number={},
pages={3753-3757},
abstract={Multiple robot-based micromanipulation system is a very interesting term in the field of micro operation research recent years. A type of piezoelectric driven miniaturerobot was introduced and the corresponding micromanipulation system was designed. The robot was controlled directly by a computer with the help of an analog output card NI PCI-6723 and the real-time situation of the working area was obtained as feedback information by a CCD camera to the computer through a video capture card Winfast vc100 xp. Hence a control software which could fulfill these two tasks were basically discussed in this paper. A fundamental process of generating desired electric signals using DAQmx driver software was proposed, after which several methods of capturing video stream from the camera in OpenCV Library, an open source computer vision library widely used, were studied. The sampling rates of them were compared and CCameraDS Class was chosen for programming the software, which was proved feasible in the implementation process.},
keywords={Streaming media;Robots;Libraries;Cameras;Software;Microscopy;Computers;Micromanipulation System;Miniaturerobot;Analog Output Card;OpenCV Library},
doi={},
ISSN={2161-2927},
month={July},}
@ARTICLE{121478,
author={Jamieson, L.H. and Delp, E.J. and Wang, C.-C. and Li, J. and Weil, F.J.},
journal={Computer},
title={A software environment for parallel computer vision},
year={1992},
volume={25},
number={2},
pages={73-77},
abstract={A software environment tailored to computer vision and image processing (CVIP) that focuses on how information about the CVIP problem domain can make the high-performance algorithms and the sophisticated algorithm techniques being designed by algorithm experts more readily available to CVIP researchers is presented. The environment consists of three principle components: DISC, Cloner, and Graph Matcher. DISC (dynamic intelligent scheduling and control) supports experimentation at the CVIP task level by creating a dynamic schedule from a user's specification of the algorithms that constitute a complex task. Cloner is aimed at the algorithm development process and is an interactive system that helps a user design new parallel algorithms by building on and modifying existing library algorithms. Graph Matcher performs the critical step of mapping new algorithms onto the target parallel architecture. Initial implementations of DISC and Graph Matcher have been completed, and work on Cloner is in progress.<>},
keywords={Computer vision;Software algorithms;Algorithm design and analysis;Dynamic scheduling;Image processing;Intelligent control;Scheduling algorithm;Interactive systems;Parallel algorithms;Buildings},
doi={10.1109/2.121478},
ISSN={1558-0814},
month={Feb},}
@INPROCEEDINGS{1421042,
author={Wen, Z. and Tzerpos, V.},
booktitle={13th International Workshop on Program Comprehension (IWPC'05)},
title={Software clustering based on omnipresent object detection},
year={2005},
volume={},
number={},
pages={269-278},
abstract={The detection of omnipresent objects can be an important aid to the process of understanding a large software system. As a result, various detection techniques have been presented in the literature. However, these techniques do not take the subsystem structure into account when deciding whether an object is omnipresent or not. In this paper, we present a new set of detection methods for omnipresent objects that maintain that an object needs to be connected to a large number of subsystems before it is deemed omnipresent. We compare this novel approach to existing ones. We also introduce a framework that can improve the effectiveness of existing software clustering algorithms by combining them with an omnipresent object detection method. Experiments with two large software systems demonstrate the usefulness of this framework.},
keywords={Object detection;Software systems;Clustering algorithms;Software algorithms;Software libraries;Computer industry;Documentation;Robustness;Guidelines;Java},
doi={10.1109/WPC.2005.31},
ISSN={1092-8138},
month={May},}
@INPROCEEDINGS{6219018,
author={Marcinek, Krzysztof and Pleskacz, Witold A.},
booktitle={2012 IEEE 15th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)},
title={AGATE - towards designing a low-power chip multithreading processor for mobile software defined radio systems},
year={2012},
volume={},
number={},
pages={26-29},
abstract={Providing low power consumption, high throughput and flexible solution is a challenge during designing process of a mobile software defined radio (SDR) system. The need for simple software generation using common programming tools becomes also a very significant factor. The paper presents the design and implementation of a chip multithreading general-purpose processor core (GPP), as the first step towards designing a flexible and programmer friendly SDR processor platform. Software tools developed for the hardware are described. The future work will be focused on designing tightly-coupled coprocessor extensions (TCC) for an application specific digital signal processing (DSP) purposes. AGATE processor system is described in form of a highly configurable library using Verilog language. The concept verification process was performed on the Xilinx Virtex-6 ML605 FPGA evaluation board. The maximum achieved frequency for the 8-thread processor is 190 MHz. Gate level simulation along with Value Change Dump (VCD) power estimation analysis were performed using three CMOS technologies: 130 nm, 90 nm and 65 nm. AGATE is capable of performing up to 0.72 DMIPS/MHz/thread with the maximum frequency of over 700 MHz and the power consumption of about 3 mW/core using 65 nm process.},
keywords={Power demand;Hardware;Pipelines;Clocks;Instruction sets;Computer architecture;Registers},
doi={10.1109/DDECS.2012.6219018},
ISSN={},
month={April},}
@INPROCEEDINGS{666798,
author={Yau, S.S. and Bing Xia},
booktitle={Proceedings First International Symposium on Object-Oriented Real-Time Distributed Computing (ISORC '98)},
title={An approach to distributed component-based real-time application software development},
year={1998},
volume={},
number={},
pages={275-283},
abstract={Component-based software development would allow application software to be largely constructed rather than programmed. This approach would dramatically improve the productivity of software development. Although there are many reusable software packages available, the integration of the chosen parts remains a very difficult problem because there are many barriers of integration, including programming languages, operating systems, communication mechanism, interface, etc. In this paper, an approach to developing real-time application software based on a distributed component architecture and cross-platform and cross-language integration of these software components is presented. The Common Object Request Broker Architecture (CORBA) is used in the implementation. The distributed components will satisfy easy retrieval and integration over a heterogeneous distributed system environment. A component replication mechanism is used for providing fault-tolerance. Using object adapters with a real-time request monitor and scheduler that are transparently generated by a distributed component integration tool, real-time and fault-tolerance features can be easily incorporated in the application software.},
keywords={Application software;Programming;Fault tolerance;Productivity;Software packages;Computer languages;Operating systems;Component architectures;Computer architecture;Monitoring},
doi={10.1109/ISORC.1998.666798},
ISSN={},
month={April},}
@INPROCEEDINGS{478782,
author={Henriksen, J.O.},
booktitle={Winter Simulation Conference Proceedings, 1995.},
title={An introduction to SLX [simulation software]},
year={1995},
volume={},
number={},
pages={502-509},
abstract={This paper provides introduction to SLX (Henriksen, 1993) for readers who are already familiar with simulation. Comparisons with GPSS/H (Banks, Carson and Sy, 1989; Henriksen and Crain, 1989; Schriber, 1991; and Smith, Brunner and Crain, 1992) are used to provide a frame of reference for describing SLX features. The goal of the SLX project is to produce a simulation system which provides a multiplicity of layers, ranging from the SLX kernel, at the bottom, all the way up to layers which provide graphical model building "without programming." In this paper, only the "lower" layers of SLX are described. Accordingly, this paper will perhaps be of greater interest to simulation software package developers than to end users of simulation software. Six key concepts which underlie the SLX kernel are presented, and SLX's extensibility mechanisms, which facilitate the construction of higher layers from lower layers, are illustrated.},
keywords={Kernel;Rivers;Graphical models;Software packages;Computer architecture;Vents;Logic},
doi={10.1109/WSC.1995.478782},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6310958,
author={Kimpe, Dries and Carns, Philip and Harms, Kevin and Wozniak, Justin M. and Lang, Samuel and Ross, Robert},
booktitle={2012 IEEE Seventh International Conference on Networking, Architecture, and Storage},
title={AESOP: Expressing Concurrency in High-Performance System Software},
year={2012},
volume={},
number={},
pages={303-312},
abstract={High-performance computing (HPC) and distributed systems rely on a diverse collection of system soft-ware to provide application services, including file systems, schedulers, and web services. Such system software services must manage highly concurrent requests, interact with a wide range of resources, and scale well in order to be successful. Unfortunately, no single programming model for distributed system software currently offers optimal performance and productivity for all these tasks. While numerous libraries, languages, and language extensions have been developed in recent years to simplify parallel computation, they do not address the challenges of distributed system software in which concurrency control involves a variety of hardware and network devices, not just computational resources. In this work we present AESOP, a new programming language and programming model designed to implement distributed system software with high development productivity and run-time efficiency. AESOP is a superset of the C language that describes blocks of code to be executed concurrently without dictating whether that concurrency will be provided by a threading, event, or other model. This decoupling enables system software to adjust to different architectures, device APIs, and workloads without any change to the core algorithm implementation. AESOP also provides additional language constructs to simplify common system software development tasks. We evaluate AESOP by implementing a basic file server and comparing its performance, memory efficiency, and developer productivity with several thread-based and event-based implementations. AESOP is shown to provide competitive performance to traditional distributed system software development models while at the same time reducing code complexity and enhancing developer productivity.},
keywords={Concurrent computing;Instruction sets;Programming;Computer architecture;Servers;Libraries;programming model;High-performance computing;I/O},
doi={10.1109/NAS.2012.41},
ISSN={},
month={June},}
@INPROCEEDINGS{8934850,
author={Liu, Zhao and Wei, Jiangtao and Wei, Yongsong and Liu, Tong and Zhou, Xiaodeng},
booktitle={2019 18th International Conference on Optical Communications and Networks (ICOCN)},
title={Design and Implementation of Communication Data Quality Analysis Software System},
year={2019},
volume={},
number={},
pages={1-3},
abstract={This paper mainly introduces the design method of communication data quality analysis software based on Linux system, and implements the software under Qt environment. The software can automatically analyze the communication data generated by the ocean-going survey ship. It can automatically check the abnormal situation of communication data (including re-frame and frame loss) and identify the abnormal situation according to the content transcribed by users' needs. It can also provide the drawing function of specified format data and the auxiliary function of data analysis. The application results show that the data quality analysis software system can meet the daily use needs, greatly reduce the time of manual data analysis and improve the accuracy of the results.},
keywords={Data analysis;Data integrity;Delays;Graphics;Delay effects;Software systems;Communication data;Linux system;data quality;automatic analysis},
doi={10.1109/ICOCN.2019.8934850},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7082806,
author={Park, Young-Hwan and Prasad, Keshava and Lee, Yeonbok and Bae, Kitaek and Yang, Ho},
booktitle={2014 International Conference on Field-Programmable Technology (FPT)},
title={Scalable radio processor architecture for modern wireless communications},
year={2014},
volume={},
number={},
pages={310-313},
abstract={In this paper, we propose an architecture of scalable radio processor targeting an OFDM based wireless modem. The architecture is based on the coarse-grained reconfigurable array (CGRA), which provides programmable and flexible accelerators by reconfiguring hardware resources at run time. On the other hand, the architecture maximizes the data parallelism by implementing 32-way SEVTD operations. Other features considered in the current implementation include mini-core structure, dedicated vector memory, and simplified datapath. The proposed architecture is compared to the precedent 4×4 CGRA processor, and evaluated with several communication kernels in terms of cycle, area and power. The implementation result shows that the proposed architecture has 3.6 times better in cycle performance with 2 times better scheduling but with double area penalty, resulting in 1495 cycles for complex 2K-FFT, to the best of our knowledge, that is the best DSP cycles reported until today. The synthesized results with 32nm library also show that the proposed architecture is operational at 800MHz, which is capable of running maximum 128 GOPS of wireless applications.},
keywords={Computer architecture;Kernel;VLIW;Digital signal processing;Hardware;Parallel processing;Wireless communication;Reconfigurable Processor;CGRA;Modulo Scheduling;SIMD;Parallel Processing;Baseband Processor;Software Defined Radio},
doi={10.1109/FPT.2014.7082806},
ISSN={},
month={Dec},}
@INPROCEEDINGS{842641,
author={Fromme, M. and Hoffmann-Schulz, G. and Litvinenko, E.},
booktitle={1999 IEEE Conference on Real-Time Computer Applications in Nuclear Particle and Plasma Physics. 11th IEEE NPSS Real Time Conference. Conference Record (Cat. No.99EX295)},
title={BEAN-a new standard program for data analysis at BER-II},
year={1999},
volume={},
number={},
pages={354-358},
abstract={A program package BEAN (BENSC Analysis Program) has been developed to provide a standard for the analysis of one-dimensional neutron spectra gathered at the experiment facilities of BENSC. The main purpose was to replace the large number of heterogeneous software packages which has been developed in the past for each neutron spectrometer separately. BEAN runs on a UNIX application server which is embedded in a 3-tier computing architecture. Data display is performed by means of the PV-WAVE software tools. For easy use the graphical user interface follows the common styling guidelines of Windows programs.},
keywords={Data analysis;Neutrons;Packaging;Standards development;Software packages;Spectroscopy;Application software;Embedded computing;Computer architecture;Displays},
doi={10.1109/RTCON.1999.842641},
ISSN={},
month={June},}
@INPROCEEDINGS{8892216,
author={Farahmand, Farnoud and Nguyen, Duc Tri and Dang, Viet B. and Ferozpuri, Ahmed and Gaj, Kris},
booktitle={2019 29th International Conference on Field Programmable Logic and Applications (FPL)},
title={Software/Hardware Codesign of the Post Quantum Cryptography Algorithm NTRUEncrypt Using High-Level Synthesis and Register-Transfer Level Design Methodologies},
year={2019},
volume={},
number={},
pages={225-231},
abstract={When quantum computers become scalable and reliable, they are likely to break all public-key cryptography standards, such as RSA and Elliptic Curve Cryptography. The projected threat of quantum computers has led the U.S. National Institute of Standards and Technology (NIST) to an effort aimed at replacing existing public-key cryptography standards with new quantum-resistant alternatives. In December 2017, 69 candidates were accepted by NIST to Round 1 of the NIST Post-Quantum Cryptography (PQC) standardization process. NTRUEncrypt is one of the most well-known PQC algorithms that has withstood cryptanalysis. The speed of NTRUEncrypt in software, especially on embedded software platforms, is limited by the long execution time of its primary operation, polynomial multiplication. In this paper, we investigate speeding up NTRUEncrypt using software/hardware codesign on a Xilinx Zynq UltraScale+ multiprocessor system-on-chip (MPSoC). Polynomial multiplication is implemented in the Programmable Logic (PL) of Zynq using two approaches: traditional Register-Transfer Level (RTL) and High-Level Synthesis (HLS). The remaining operations of NTRUEncrypt are executed in software on the Processing System (PS) of Zynq, using the bare-metal mode. The speed-up of our software/hardware codesigns vs. purely software implementations is determined experimentally and analyzed in the paper. The results are reported for the RTL-based and HLS-based hardware accelerators, and compared to the best available software implementation, included in the NIST submission package. The speed-ups for encryption were 2.4 and 3.9, depending on the selected parameter set. For decryption, the corresponding speed-ups were 4.0 and 6.8. In addition, for the polynomial multiplication operation itself, the speed up was in excess of 75. Our code for the NTRUEncrypt polynomial multiplier accelerator is being made open-source for further evaluation on multiple software/hardware platforms.},
keywords={Software;NIST;Hardware;Software algorithms;Encryption;Field programmable gate arrays;Post-Quantum Cryptography;lattice-based;NTRU;hardware/software codesign;High-Level Synthesis},
doi={10.1109/FPL.2019.00042},
ISSN={1946-1488},
month={Sep.},}
@INPROCEEDINGS{8977883,
author={Vipin, Kizheppatt},
booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)},
title={ZyNet: Automating Deep Neural Network Implementation on Low-Cost Reconfigurable Edge Computing Platforms},
year={2019},
volume={},
number={},
pages={323-326},
abstract={Prevalence of internet of things (IoT) enabled applications provide a new opportunity to low-cost FPGA devices to act as edge computing neural network nodes. Although FPGA vendors provide neural network development environments, they often target high-end devices. At the same time these development platforms are not as user friendly as their software counterparts. In this work we introduce ZyNet, a Python package, which enables faster implementation of deep neural networks (DNNs) targeting low-cost hybrid FPGA platforms such as the Xilinx Zynq. Based on hardware-software co-design approach, this platform supports pre-trained or on-board trained networks with development environment very similar to the popular TensorFlow. Implementation results show that the DNNs generated by the platform achieve accuracy very close to software implementations at the same time gives throughput by an order of magnitude compared to other edge computing devices at lower energy footprint. The platform is integrated with Xilinx development tools and is distributed as open source.},
keywords={neural networks;hardware-software co-design},
doi={10.1109/ICFPT47387.2019.00058},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6211139,
author={Friedrich, Felix and Liu, Ling and Gutknecht, Jurg},
booktitle={2012 IEEE/ACIS 11th International Conference on Computer and Information Science},
title={Active Cells: A Computing Model for Rapid Construction of On-Chip Multi-core Systems},
year={2012},
volume={},
number={},
pages={463-469},
abstract={We present a novel computing model that allows to conveniently construct multi-core systems with different computer architectures, ranging from homogeneous many-core architectures to networks of heterogeneous general purpose processor cores or signal processing engines. A hardware library implemented on Field Programmable Gate Arrays (FPGAs) and a compiler provide a platform for prototyping and constructing distributed systems on a chip. A number of case studies have been carried out to prove the concept conveyed by the computing model.},
keywords={Hardware;Computational modeling;Engines;Programming;Field programmable gate arrays;Computer architecture;Vectors;Parallel programming;Concurrent computing;Distributed computing;Multicore processing;FPGA design;System-level design;Software-hardware co-design},
doi={10.1109/ICIS.2012.26},
ISSN={},
month={May},}
@INPROCEEDINGS{8797942,
author={Michailidis, Michail G. and Agha, Mohammed and Rutherford, Matthew J. and Valavanis, Kimon P.},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)},
title={A Software in the Loop (SIL) Kalman and Complementary Filter Implementation on X-Plane for UAVs},
year={2019},
volume={},
number={},
pages={1069-1076},
abstract={The paper presents a software in the loop (SIL) sensor study in simulation environments for traditional Kalman, linear and nonlinear complementary filters, which are derived, tested and implemented on a fixed wing UAV for attitude estimation (pitch, roll and heading angle). An overview of the SIL setup environment between MATLAB/Simulink and the X-Plane flight simulator is given. Kalman filter design in Simulink utilizes a state-space model of the UAV dynamics, while complementary filter combines accelerometer output for low frequency attitude estimation with integrated gyro output for high frequency estimation. Simulation results are provided and discussed under both Gaussian and uniform noise, highlighting the convergence of the designed estimators. It is also shown that the estimator following the nonlinear complementary framework yields a better match to the dynamic evolution of the actual attitude angles of the vehicle over time.},
keywords={Kalman filters;Estimation;Software packages;Atmospheric modeling;Automotive components;Unmanned aerial vehicles;Aerodynamics},
doi={10.1109/ICUAS.2019.8797942},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{1510401,
author={Magee, D.P.},
booktitle={Proceedings. 42nd Design Automation Conference, 2005.},
title={Matlab extensions for the development, testing and verification of real-time DSP software},
year={2005},
volume={},
number={},
pages={603-606},
abstract={The purpose of this paper is to present the required tools for the development, testing and verification of DSP software in Matlab. The paper motivates a DSP Simulator concept that can be combined with the MATLAB executable interface to develop, evaluate and test DSP software within a single environment. Programming guidelines and optimization results are also provided to demonstrate the effectiveness of the intrinsics software development approach.},
keywords={MATLAB;Software testing;Digital signal processing;Software tools;Application software;Software algorithms;Software performance;Software libraries;Programming;Computer languages},
doi={10.1145/1065579.1065736},
ISSN={0738-100X},
month={June},}
@ARTICLE{6581816,
author={},
journal={IEEE Std 1666-2011 (Revision of IEEE Std 1666-2005) - Redline},
title={IEEE Standard for Standard SystemC Language Reference Manual - Redline},
year={2012},
volume={},
number={},
pages={1-1163},
abstract={SystemC(R) is defined in this standard. SystemC is an ANSI standard C++ class library for system and hardware design for use by designers and architects who need to address complex systems that are a hybrid between hardware and software. This standard provides a precise and complete definition of the SystemC class library so that a SystemC implementation can be developed with reference to this standard alone. The primary audiences for this standard are the implementors of the SystemC class library, the implementors of tools supporting the class library, and the users of the class library.},
keywords={IEEE standards;Computer languages;Embedded systems;Software engineering;System-on-chip;Discrete-time systems;Hardware verification;Digital systems;Electronic design automation and methodology;C++;computer languages;digital systems;discrete event simulation;electronic design automation;electronic system level;electronic systems;embedded software;fixed-point;hardware description language;hardware design;hardware verification;IEEE 1666;SystemC;system modeling;system-on-chip;transaction level},
doi={},
ISSN={},
month={Jan},}
@INPROCEEDINGS{5952002,
author={Kwon, Jagun and Hailes, Stephen},
booktitle={2011 IEEE Ninth International Symposium on Parallel and Distributed Processing with Applications Workshops},
title={A Lightweight, Component-Based Approach to Engineering Reconfigurable Embedded Real-Time Control Software},
year={2011},
volume={},
number={},
pages={361-366},
abstract={The cost of poor or repeat engineering in complex control systems is extremely high, and flexibility in software design and implementation is one of the key factors in staying competitive in the market. Complexity can be managed most effectively if the underlying software systems support structured, standardised, high-level abstraction layers that encapsulate unnecessary details behind well-defined interfaces. Moreover, since the costs of software maintenance are often as high as that of initial development, the ease with which it is possible flexibly to reconfigure, re-engineer, and replace software components in operational systems is also critical. In this paper, we present a lightweight, component-based approach to engineering embedded real-time control software, which is realized in the form of a middleware system named MIREA. The middleware supports dynamic reconfiguration of components written in C/C++, and addresses variability management in relation to non-functional properties, such as quality-of-service (QoS) and real-time scheduling. Users are allowed to componentize existing libraries easily, such as the standard NIST 4D/Real-time Control Systems (RCS) library, which has been successfully used in many U.S government-driven intelligent control projects, and to reuse them as dynamically reconfigurable components. A realistic illustration is provided showing how control systems are structured and reconfigured using our approach. In fact, we discuss our approach to control using a fusion of NIST RCS as a means of architecting a real time control system and MIREA as a means of realising that architecture. Our progress to date suggests that MIREA is indeed well suited as a middleware facilitating the construction of efficient, lightweight, and scalable real-time embedded control systems.},
keywords={Middleware;Batteries;Real time systems;Software;Control systems;Runtime;Monitoring},
doi={10.1109/ISPAW.2011.69},
ISSN={},
month={May},}
@INPROCEEDINGS{9970849,
author={Solouki, Mohammadreza Amel and Sini, Jacopo and Violante, Massimo},
booktitle={2022 29th IEEE International Conference on Electronics, Circuits and Systems (ICECS)},
title={Effectiveness of Control Flow Checking Algorithms Using a Model-Based Software Design Approach: An Empirical Study},
year={2022},
volume={},
number={},
pages={1-4},
abstract={Many software-implemented control flow error detection techniques have been proposed over the years. However, applying these approaches can be difficult because their respective literature gives little guidance on the practical implementation in high-level programming languages, and they have to be implemented in low-level code, e.g., assembly. Moreover, the current trend in the automotive industry is to adopt the so-called Model-Based Software Design, where an executable algorithm model is automatically translated into C or C++ source code. This paper presents experimental data, compliant with the ISO26262 automotive functional safety standard, on the capabilities of Control Flow Checking (CFC) algorithms, implemented in the model and then automatically generated. The assessment was performed using a novel fault injection environment targeting a RISC-V (RV32I) microcontroller.},
keywords={Industries;Software design;Software packages;Microcontrollers;Source coding;Software algorithms;Benchmark testing;fault injection;functional safety;automotive applications;fault tolerance},
doi={10.1109/ICECS202256217.2022.9970849},
ISSN={},
month={Oct},}
@INPROCEEDINGS{4629256,
author={Zhan, Jianfeng and Wang, Lei and Tu, Bibo and Zhang, Zhihong and Wen, Yu and Chen, Yuansheng and Zhou, Wei and Meng, Dan and Sun, Ninghui},
booktitle={2007 IEEE International Conference on Cluster Computing},
title={A layered design methodology of cluster system stack},
year={2007},
volume={},
number={},
pages={404-409},
abstract={The application range of cluster has expanded beyond scientific computing, but the present cluster system software fails to provide a flexible architecture to promote code reuse and facilitate building cluster system software for different computing contexts, most of which are developed from scratch case by case, or integrated or packaged with “the best practice”. In this paper, we have proposed a layered design methodology to build cluster system stack with different layers concentrating on different functions, and developed common sets of core service as reusing framework for different computing context. Following this methodology, we have built Phoenix-a complete cluster system stack for both scientific and business computing, which is verified and deployed on Dawning 4000A super computer for scientific computing and other cluster systems for business computing. The qualitative evaluation and our practices show the design methodology of Phoenix has advantages over other methodologies.},
keywords={Design methodology;System software;Engines;Computer architecture;Software;Business;Monitoring},
doi={10.1109/CLUSTR.2007.4629256},
ISSN={2168-9253},
month={Sep.},}
@INPROCEEDINGS{5276558,
author={Othman, M.K. and Lapeer, R.J.},
booktitle={2006 International Conference on Computing & Informatics},
title={User interfaces design for CVE software},
year={2006},
volume={},
number={},
pages={1-6},
abstract={The project aims to study and design an alternative user interface for collaborative virtual environments (CVE's) software also known as networked virtual environments (NVE's). To reduce cost, most current and operative CVE's use the Internet and standard PC to create a visual virtual environment (VE), which can be shared by a large number of users. This project also involves an image processing technique (morphing technique using thin plate spline) for creating a facial expression for the CVE software and in volves OpenGL API for implementation. This project discusses communication aspects in the CVE system and suggests the different types of communication that are suitable for the project. It also suggests a suitable user interfaces for the software.},
keywords={User interfaces;Software design;Collaborative software;Virtual environment;Humans;Protocols;Computer networks;Image processing;Spline;Graphical user interfaces},
doi={10.1109/ICOCI.2006.5276558},
ISSN={2166-5729},
month={June},}
@INPROCEEDINGS{7340762,
author={Stetsenko, Inna V. and Dorosh, Vitaliy I. and Dyfuchyn, Anton},
booktitle={2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)},
title={Petri-object simulation: Software package and complexity},
year={2015},
volume={1},
number={},
pages={381-385},
abstract={This paper presents the Petri-object model formalization based on description of system dynamics with the stochastic timed Petri net. The model structure consists of Petri-objects with the use of object-oriented approach. The evaluation of computational complexity of model implementation based on mathematical description of Petri-object model is obtained. The theoretical evaluation of complexity is confirmed by experimental research. A significant reduction of Petri-object simulation complexity in comparison with stochastic Petri net is proved.},
keywords={Petri nets;Computational modeling;Mathematical model;Object oriented modeling;Stochastic processes;Computational complexity;computational complexity;descrete-event system;simulation modeling;stochastic Petri net;object-oriented approach;state equation},
doi={10.1109/IDAACS.2015.7340762},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{994374,
author={Ribbers, P.M.A. and Schoo, K.-C.},
booktitle={Proceedings of the 35th Annual Hawaii International Conference on System Sciences},
title={Designing complex software implementation programs},
year={2002},
volume={},
number={},
pages={3391-3401},
abstract={The central question of this paper is: How can design of Program Management contribute to the success of complex software implementations? Incomplete goal specifications, lack of communication, and underestimation of project complexity are signs of insufficient program and project management. To avoid these pitfalls, we will propose ways that have worked well in recent complex multi project ERP implementations ("programs"). Answering the above question raises the problem of adequately defining and measuring the level of complexity of an implementation program. We operationalize complexity through three dimensions: variety, variability, and integration. A conceptual model was developed, which identifies program management factors that are proposed to have an impact on implementation success. Fifteen cases were studied to find support for the proposed framework.},
keywords={Software design;Project management;Enterprise resource planning;Packaging;Information management;Electronic mail;Portfolios;Software standards;Industrial relations;Aerodynamics},
doi={10.1109/HICSS.2002.994374},
ISSN={},
month={Jan},}
@INPROCEEDINGS{342810,
author={Chung-Shyan Liu and Kuo-Hua Su},
booktitle={Proceedings Eighteenth Annual International Computer Software and Applications Conference (COMPSAC 94)},
title={An FSM-based program generator for communication protocol software},
year={1994},
volume={},
number={},
pages={181-187},
abstract={A program generator for communication protocol software is presented. This program generator takes an extended finite state machine as a domain model and generates a group of C++ classes needed for an implementation. In the program generator, an object is generated for each state of the FSM. In a given state, for each interface event that triggers a state transition from the state to another state or back to itself, a member function (or called method) is created for the state object. The actions associated with a state transition constitute bodies of the member function corresponding to the interface event that triggers the transition. The program generator now includes a state machine editor, a program editor, and a class library. Incremental implementation is also supported by the program generator.<>},
keywords={Automatic programming;Protocols;Automata;Software libraries;Productivity;Software design;Software performance;Software systems;Concurrent computing;Software tools},
doi={10.1109/CMPSAC.1994.342810},
ISSN={},
month={Nov},}
@ARTICLE{8476558,
author={Soto-Hidalgo, J. M. and Alonso, Jose M. and Acampora, Giovanni and Alcala-Fdez, J.},
journal={IEEE Access},
title={JFML: A Java Library to Design Fuzzy Logic Systems According to the IEEE Std 1855-2016},
year={2018},
volume={6},
number={},
pages={54952-54964},
abstract={Fuzzy logic systems are useful for solving problems in many application fields. However, these systems are usually stored in specific formats and researchers need to rewrite them to use in new problems. Recently, the IEEE Computational Intelligence Society has sponsored the publication of the IEEE Standard 1855-2016 to provide a unified and well-defined representation of fuzzy systems for problems of classification, regression, and control. The main aim of this standard is to facilitate the exchange of fuzzy systems across different programming systems in order to avoid the need to rewrite available pieces of code or to develop new software tools to replicate functionalities that are already provided by other software. In order to make the standard operative and useful for the research community, this paper presents JFML, an open source Java library that offers a complete implementation of the new IEEE standard and capability to import/export fuzzy systems in accordance with other standards and software. Moreover, the new library has associated a Website with complementary material, documentation, and examples in order to facilitate its use. In this paper, we present three case studies that illustrate the potential of JFML and the advantages of exchanging fuzzy systems among available software.},
keywords={Fuzzy logic;IEEE Standards;Libraries;Fuzzy systems;Software;Java;Fuzzy logic systems;IEEE std 1855-2016;fuzzy markup language;open source software;IEC61131-7},
doi={10.1109/ACCESS.2018.2872777},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{716647,
author={Heineman, G.T.},
booktitle={Proceedings. The Twenty-Second Annual International Computer Software and Applications Conference (Compsac '98) (Cat. No.98CB 36241)},
title={A model for designing adaptable software components},
year={1998},
volume={},
number={},
pages={121-127},
abstract={The widespread construction of software systems from pre-existing, independently developed software components will only occur when application builders can adapt software components to suit their needs. We propose that software components provide two interfaces-one for behavior and one for adapting that behavior as needed. The ADAPT framework presented in the paper supports both component designers in creating components that can easily be adapted, and application builders in adapting software components. The motivating example, using Java-Beans, shows how adaptation, not customization, is the key to component based software.},
keywords={Software design;Application software;Software systems;Java;Software engineering;Software libraries;Graphical user interfaces;Cost function;Programming;Calendars},
doi={10.1109/CMPSAC.1998.716647},
ISSN={0730-3157},
month={Aug},}
@INPROCEEDINGS{884749,
author={Pollard, J.K.},
booktitle={Proceedings 24th Annual International Computer Software and Applications Conference. COMPSAC2000},
title={Component-based architecture for simulation of transmission systems},
year={2000},
volume={},
number={},
pages={363-368},
abstract={Example transmission system simulations are used to illustrate criteria for quality architecture: component interoperability, reusability, reliability and maintainability. Top-level architectural issues such as system partition, encapsulation of components and a graphical user interface that is decoupled from the core software are considered. It is suggested that component communication should be: write a file, signal a "commit" and then read by the recipient. This protocol allows input and output data types and ranges to be checked. An error code on failure allows roll-back to a previously saved state, whereas a successful completion signal can be used as a sequential control. The desirable feature of very loosely coupled independent components implies insensitivity to construction technology. This allows the use of legacy and commercial software packages. In addition, components can be deployed on different types and scales of networks and can be fixed on computers and data transferred to them, or vice-versa.},
keywords={Object oriented modeling;Hardware;Graphical user interfaces;Computational modeling;Computer architecture;Maintenance;Encapsulation;Spread spectrum communication;Telephony;Data communication},
doi={10.1109/CMPSAC.2000.884749},
ISSN={0730-3157},
month={Oct},}
@INPROCEEDINGS{375454,
author={Keng Ng and Kramer, J. and Magee, J. and Dulay, N.},
booktitle={Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences},
title={The Software Architect's Assistant-a visual environment for distributed programming},
year={1995},
volume={2},
number={},
pages={254-263 vol.2},
abstract={This paper describes work on the application of visual techniques to the design and construction of parallel and distributed programs. In particular, it looks at how the software architectural view can be effectively utilised to provide a common framework for integrating the various software development activities, ranging from early, informal program design to the evolution of the running program. A prototype visual programming environment-the Software Architect's Assistant-has been built for the design and development of Regis distributed programs. It provides the user with automated, intelligent assistance throughout the software design process. Facilities provided include the display of integrated graphical and textual views, a flexible mechanism for recording design information and the automatic generation of program code and formatted reports from design diagrams. Software reuse is also supported through the use of component libraries. Support for graphical monitoring and management of running programs, currently provided by a complementary tool, will be integrated into the environment to provide a complete solution for visual distributed programming.<>},
keywords={Application software;Context;Distributed computing;Educational institutions;Software prototyping;Programming environments;Software design;Displays;Software libraries;Monitoring},
doi={10.1109/HICSS.1995.375454},
ISSN={},
month={Jan},}
@INPROCEEDINGS{5289176,
author={Wong, H.J. and Rendell, A.P.},
booktitle={2009 IEEE International Conference on Cluster Computing and Workshops},
title={Integrating software distributed shared memory and message passing programming},
year={2009},
volume={},
number={},
pages={1-10},
abstract={Software Distributed Shared Memory (SDSM) systems provide programmers with a shared memory programming environment across distributed memory architectures. In contrast to the message passing programming environment, the SDSM can resolve data dependencies within the application without the programmer having to explicitly specify communication. However, this service is provided at a cost to performance. Thus it makes sense to use message passing directly when data dependencies are easy to solve using message passing. For example, it is not complicated to specify data transfer for large contiguous regions of memory. This paper outlines how the Danui SDSM library has been extended to include support for message passing. Four different message passing transfers are identified depending on whether the data being sent/received resides in private or globally shared buffers. Transfers between globally shared buffers are further categorized as symmetrical or asymmetrical depending on whether they correspond to the same region of shared memory. The implication of each transfer type on the memory consistency of the global address space is discussed. Central to the Danui SDSM extension is the use of information provided and implied by message passing operations. The overhead of the implementation is analyzed.},
keywords={Message passing;Yarn;Programming profession;Programming environments;Libraries;Computer science;Memory architecture;Application software;Costs;Data communication},
doi={10.1109/CLUSTR.2009.5289176},
ISSN={2168-9253},
month={Aug},}
@INPROCEEDINGS{599249,
author={O'Halloran, C.},
booktitle={IEE Colloquium on Cots and Safety Critical Systems (Digest No. 1997/013)},
title={Controlling the risk of COTS via application programming interfaces},
year={1997},
volume={},
number={},
pages={6/1-6/2},
abstract={There are various approaches to building critical systems. One approach is the use of fault-tolerant software architectures. This approach can be difficult even when components have been developed under a customer's control. When the detailed behaviour of the component is unknown, which is often the case with a COTS (commercial off-the-shelf) component, then providing appropriate recovery actions becomes even more difficult. To be able to tolerate erroneous behaviours, application programming interfaces (APIs) must be identified because it is through these that a component expresses its behaviour. The more information about an API that is known, the more will be known about the possible behaviours of a component and how erroneous behaviour could be tolerated. An approach to accepting safety-critical systems consisting of COTS software is the use of static analysis techniques to determine desirable properties of components. Even when a software component is analysed, the properties of that component need to be composed together with the other components to determine the overall system properties. Again, the key is to determine the APIs and how components interact through them in order to establish compositional behaviours. A COTS component tends to have more functionality than required for a particular system because it is more general-purpose. This provides more ways for unexpected behaviours to arise and threaten the integrity of a system. By identifying unwanted APIs and policing them, the extra functionality can sometimes be limited and the vulnerability of the system to failure reduced.},
keywords={Software packages},
doi={10.1049/ic:19970096},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8725346,
author={Gusarova, A.A. and Shilkina, S.V.},
booktitle={2019 International Science and Technology Conference "EastConf"},
title={Modeling the Operation of the System in the CODESYS Software Environmentper},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Nowadays the world seeks to automate all branches of life. Automation plays a significant role in large-scale manufacturing, due to the large volume of production. Complex processes that have many controlled and testing parameters are difficult to implement by a team of workers. There is also a human factor that can disrupt the process. To solve this problem, programmable logical controllers (PLCs) were created that took on the role of a “brain” in a controlled system. The task of the controller is to evaluate all the factors of the system and to correct its operation to perform the given mode. So, all automation systems are built. Each process has its own peculiarities and mode. The PLC runs on the program loaded into it, which corresponds to the selected process. Correct writing of the program is one of the main tasks in the design of the system. The article discusses the programming environment of CoDeSys controllers, which makes it possible for any specialist, with the help of logical operations in a different view, to compile a program for any process. Writing the program is possible in any convenient format: in the language of relay contact circuits, in the graphical language of functional block charts, and also with the help of high-level diagrams describing the stages and conditions of the transitions in the contemporary computer programming language. In addition, the complex CoDeSys makes it possible for you to see the program in operation, using the visualization editor. Visualization is possible without connecting the PLC. In this article, an example of using the CoDeSys complex to develop a simulation program for the batching and blending process of a glass charge is considered. In the work, various ways of modeling the process are presented for a more illustrative demonstration of the system operation and debugging of the controller. When the flow chart of this process is constructed, a visualization of the process is carried out by means of a graphical display of the state of the equipment and subprocesses. The result of this work is the disclosure of the capabilities of the software complex CoDeSys for use by specialists in the field of automation of control systems for the management of technological processes and production in construction. The complex is associated with the development, commissioning, adjustment of the automated process control system. The application of this software complex in Russia has a tendency of steady growth. A program developed for a specific process in CoDeSys can be easily verified using graphical modeling and is available for adjustment directly in the process of operation, taking into account the process change. It is also advantageous that the CoDeSys complex with instruction for its use is freely available, which makes it possible to use freely this tool, adapt it to any technological process. The main thing is to understand what kind of tool it is and what opportunities it provides.},
keywords={Sensors;Visualization;Software;Process control;Mixers;Production;Tools;automation of production;process;automated control systems;programmable logic controllers;CoDeSys software package;Continuous Function Chart (CFC) programming language;computer simulation;graphical visualization of program},
doi={10.1109/EastConf.2019.8725346},
ISSN={},
month={March},}
@INPROCEEDINGS{5676829,
author={Cai, Li and Chen, Zhen},
booktitle={2010 International Conference on Computational Intelligence and Software Engineering},
title={Design and Implementation of OGRE-Based Game Scene Editor Software},
year={2010},
volume={},
number={},
pages={1-4},
abstract={With the rapid development of network game, network education game as a new education means has gradually received much concern. Developing the network education game needs the support of game engine, and the scene editor software is a foundation of the game engine and an essential tool. This paper has realized the scene editor based on OGRE, .NET framework and C++/ CLI technology. The Software has abundant functions and humanized user interface, and can conveniently, swiftly edit terrain, surface, water surface, game element in the game scenes, etc. At present, the scenes created by this editor have already been applied to the network education game called "Eastern Learning", and constructed a rich game learning environment for players, furthermore this software provides the theory foundation and application value for research and development of the educational game engine field.},
keywords={Games;Software;Education;Engines;Rendering (computer graphics);User interfaces;Three dimensional displays},
doi={10.1109/CISE.2010.5676829},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6199506,
author={Liping Xu and Eli, Samat and Haiyin Xu},
booktitle={Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering (TMEE)},
title={A method of focused crawling for software components},
year={2011},
volume={},
number={},
pages={1560-1563},
abstract={The number of vertical search engines has rapidly increased over the last years, making the importance of a focused crawler. This paper introduces design and implementation of a focused crawler for software components. Before computing the similarity of a page to the topic, analyze its URL whether it is necessary or not. This leads to significant savings in hardware and network resources, and help the crawler avoid irrelevant page's similarity computation.},
keywords={Crawlers;Software;Search engines;Web pages;Educational institutions;Vectors;Libraries;software component;focused crawler;similarity computation},
doi={10.1109/TMEE.2011.6199506},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8252207,
author={Ferrier, Malcolm},
booktitle={2017 Computing Conference},
title={Effective quantitative business software selection: Tools and techniques},
year={2017},
volume={},
number={},
pages={945-946},
abstract={This paper outlines a recommended methodology for selecting business software applications for any size of enterprise. Given the number of options available for business applications in the software market for a functional area (e.g. human resources, finance, operations), a structured technique for assessing features against the enterprise's custom requirements is clearly necessary. A weighted requirements assessment against the features of the software makes sense, but runs into difficulty when attempting to compare cost of ownership between applications. An algorithm is presented in this paper to compare the applications both in features and in total cost of ownership which will result in a single quantitative measure that can be compared across the business application options. An implementation of this methodology by the author can be found at http://espanalytics.com.},
keywords={Application software;Mathematical model;Tools;Finance;Software algorithms;business application software selection},
doi={10.1109/SAI.2017.8252207},
ISSN={},
month={July},}
@INPROCEEDINGS{5770605,
author={Romano, Daniele and Di Penta, Massimiliano and Antoniol, Giuliano},
booktitle={2011 Fourth IEEE International Conference on Software Testing, Verification and Validation},
title={An Approach for Search Based Testing of Null Pointer Exceptions},
year={2011},
volume={},
number={},
pages={160-169},
abstract={Uncaught exceptions, and in particular null pointer exceptions (NPEs), constitute a major cause of crashes for software systems. Although tools for the static identification of potential NPEs exist, there is need for proper approaches able to identify system execution scenarios causing NPEs. This paper proposes a search-based test data generation approach aimed at automatically identify NPEs. The approach consists of two steps: (i) an inter-procedural data and control flow analysis - relying on existing technology - that identifies paths between input parameters and potential NPEs, and (ii) a genetic algorithm that evolves a population of test data with the aim of covering such paths. The algorithm is able to deal with complex inputs containing arbitrary data structures. The approach has been evaluated on to test class clusters from six Java open source systems, where NPE bugs have been artificially introduced. Results show that the approach is, indeed, able to identify the NPE bugs, and it outperforms random testing. Also, we show how the approach is able to identify real NPE bugs some of which are posted in the bug-tracking system of the Apache libraries.},
keywords={Gallium;Testing;Libraries;Java;Instruments;Null value;Genetic algorithms;Null pointer exceptions;Search-based testing},
doi={10.1109/ICST.2011.49},
ISSN={2159-4848},
month={March},}
@ARTICLE{7514992,
author={Rovere, Santiago L. and North, Michael J. and Podestá, Guillermo P. and Bert, Federico E.},
journal={IEEE Access},
title={Practical Points for the Software Development of an Agent-Based Model of a Coupled Human-Natural System},
year={2016},
volume={4},
number={},
pages={4282-4298},
abstract={Modeling complex natural and human systems to support policy or management decision making is becoming increasingly common. The resulting models are often designed and implemented by researchers or domain experts with limited software engineering expertise. To help this important audience, we present our experience and share lessons learned from the design and implementation of an agent-based model of agricultural production systems in the Argentine Pampas, emphasizing the software engineering perspective. We discuss the model's design including the model classes; the activity diagram, and data flow; the package and folder layout; the use of design patterns; performance optimization; initialization approaches; the analysis of results; and model measurement, validation, and verification.},
keywords={Unified modeling language;Object oriented modeling;Agriculture;Software;Biological system modeling;Adaptation models;Software engineering;Complex adaptive systems;agent-based modeling;coupled human and natural systems;model design and implementation;software engineering},
doi={10.1109/ACCESS.2016.2592418},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{1357892,
author={Li, J. and Bjoernson, F.O. and Conradi, R. and Kampenes, V.B.},
booktitle={10th International Symposium on Software Metrics, 2004. Proceedings.},
title={An empirical study of variations in COTS-based software development processes in Norwegian IT industry},
year={2004},
volume={},
number={},
pages={72-83},
abstract={More and more software projects use commercial-off-the-shelf (COTS) components. Although previous studies have proposed specific COTS-based development processes, there are few empirical studies to investigate how to use and customize them to different project contexts. This paper describes an exploratory study of state-of-the-practice of COTS-based development processes. 16 software projects in Norwegian IT companies have been studied by structured interviews. The results are that COTS-specific activities can be successfully incorporated in most traditional development processes (such as waterfall or prototyping), given proper guidelines to reduce risks and provide specific assistance. We have identified four COTS-specific activities - the build vs. buy decision, COTS component selection, learning and understanding COTS components, and COTS component integration - and one new role, that of a knowledge keeper. We have also found a special COTS component selection activity for unfamiliar components, combining Internet searches with hands-on trials. The process guidelines are expressed as scenarios and lessons learned, and can be used to customize the actual development processes, e.g. in which lifecycle phase to put the new activities. Such customization crucially depends on project context, such as previous familiarity with possible COTS components and flexibility of requirements.},
keywords={Programming;Computer industry;Guidelines;Software maintenance;Information science;Laboratories;Software prototyping;Prototypes;Diversity reception;Internet},
doi={10.1109/METRIC.2004.1357892},
ISSN={1530-1435},
month={Sep.},}
@INPROCEEDINGS{7230851,
author={Mandziy, Bogdan and Seniv, Maxym and Mosondz, Natalia and Sambir, Andriy},
booktitle={The Experience of Designing and Application of CAD Systems in Microelectronics},
title={Programming visualization system of block diagram reliability for program complex ASNA-4},
year={2015},
volume={},
number={},
pages={258-262},
abstract={In this work the software for visualization of construction process of reliability block diagram of technical system and automated determination of its performance conditions dependent on states of system elements taking into account the multiplicity of elements redundancy, number and priority of restorations, number of repair teams is considered. The program focuses on interaction with the software package ASNA-4, which allows developers of respective systems at the design stage to model the behavior of these systems and to determine their reliability characteristics.},
keywords={Software reliability;Mathematical model;MATLAB;Visualization;Algorithm design and analysis;reliability block diagram;technical system;efficiency;software},
doi={10.1109/CADSM.2015.7230851},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9911106,
author={Krupenkins, Eduards and Zhang, Qichun},
booktitle={2022 27th International Conference on Automation and Computing (ICAC)},
title={Digital Circuit Simulator Development with CNN Integration},
year={2022},
volume={},
number={},
pages={1-6},
abstract={This paper investigates a machine learning integrated circuits simulator design and development. It aims to provide a prototyping framework that may assist digital integrated circuit engineers in designing digital circuits utilising machine learning support. Currently, there is no existing solution on the applications that integrated digital simulator with machine learning. Many digital simulators cannot be extended due to lack of API, and they would struggle to generate datasets in real-time for the simulation models. The developed platform focuses on designing the overall application and the implementation aspects of the machine learning integration. In particular, a sophisticated gate-level simulator was developed using C++ and LUA programming languages; the gate-level simulator contains various features to be effortlessly integrated with most python machine learning libraries via a communication channel. Also, convolutional neural network model is adopted, which directly communicate with the simulator by retrieving live datasets and controlling the simulator by prediction scores. An example has been given as a case study for demonstrating the developed prototype.},
keywords={Wires;Prototypes;Digital integrated circuits;Machine learning;Reinforcement learning;Logic gates;Solids;Digital integrated circuit simulator;Machine learning;Convolutional neural network;Software engineering;Computer-aided design},
doi={10.1109/ICAC55051.2022.9911106},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6032416,
author={Park, Pyungsun and Jung, Jaeil and Huh, Byounghweh},
booktitle={2011 IEEE 35th Annual Computer Software and Applications Conference},
title={Development of CAN-1394 Automotive Gateway System Using Designed Modular Software Stack},
year={2011},
volume={},
number={},
pages={674-679},
abstract={Recently, software diversity and reuse issues in automotive embedded software development have rapidly increased due to newly released technologies and its standardization. The modular design of software is essential to enhance software re-usability and portability. In this paper, we present a CAN-1394 Automotive gateway system implementation using modular designs of software stacks. We first study and summarize key specifications and their relationships in 1394 Automotive software stack development. Then, we present our modular implementation of software and hardware, which includes 1394 Automotive core stack components such as a communication driver and API library. In addition, we highlight essential functions of the implemented gateway for the 1394 Automotive backbone network and the CAN based in-vehicle network in detail.},
keywords={IEEE 1394 Standard;Protocols;Automotive engineering;Software;Vehicles;Logic gates;Streaming media;IEEE 1394;IDB-1394;1394 Automotive;Vehicle Interface;CAN-1394 Auto Gateway},
doi={10.1109/COMPSAC.2011.94},
ISSN={0730-3157},
month={July},}
@INPROCEEDINGS{6908411,
author={Nsame, Pascal and Bois, Guy and Savaria, Yvon},
booktitle={2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS)},
title={Adaptive real-time DSP acceleration for SoC applications},
year={2014},
volume={},
number={},
pages={298-301},
abstract={This paper investigates VLSI architectures for digital processing (DSP) functions amenable to low energy operation with scalable performance for H.265 high efficiency video coding (HEVC) applications. First, we describe and experimentally evaluate a novel adaptive computing fabric. Second, we propose an energy-efficient method to scale the performance of the fabric for large images or for meeting stringent real-time computation requirements. A series of tradeoffs for exploiting efficiently the application space for general purpose DSP acceleration are proposed. We experimentally show how the proposed computing fabric is reusable for Filters, FFT and DCT acceleration with a scalable throughput. We report on the design and implementation of the fabric on a Xilinx FPGA device and show how regulated-parallelism augmented with in-memory processing techniques impact performance and power efficiency. The FPGA prototype demonstrates a sustained throughput exceeding 10Gbps irrespective of the kernel and image size for H.265 HEVC applications.},
keywords={Digital signal processing;Discrete cosine transforms;Fabrics;Throughput;Acceleration;Program processors;Real-time systems;Architectural Tradeoffs;Design Methodology;Hardware/Software Co-Design;DSP function library;VLIW;ASIP;FPGA;ASIC;SoC;NoC},
doi={10.1109/MWSCAS.2014.6908411},
ISSN={1558-3899},
month={Aug},}
@INPROCEEDINGS{7943259,
author={Sugandhi, Ritesh and Srivastava, Pankaj and Srivastav, Prabhakar and Sanyasi, Amulaya and Awasthi, Lalit Mohan and Parmar, Vijaysinh and Makadia, Keyur and Patel, Ishan and Shah, Sandeep},
booktitle={2017 7th International Conference on Cloud Computing, Data Science & Engineering - Confluence},
title={Implementation of object oriented software engineering on LabVIEW graphical design framework for data acquisition in large volume plasma device},
year={2017},
volume={},
number={},
pages={798-803},
abstract={The data acquisition and control system (DACS) implementation for laboratory plasma experiments is a challenging task, develops gradually over time due to the: (a) rapidly evolving requirements driven by the new findings, (b) application of new ideas to the experiments, (c) interaction of the software with the specialized hardware and (d) time scales of measurement and controls. This motivates development of software based on flexible and modular architecture for the scientific computing. We have broadly classified it as: (a) base design dealing with specialized measurement hardware and (b) application design for system testing and experimentation. The role of object oriented software engineering (OOSE) is important so that developed software components could be effectively utilized by applications. The OOSE on LabVIEW graphical programming platform is a new and evolving paradigm. A demonstration of it, is achieved in Large Volume Plasma Device (LVPD) utilizing high speed PXIe bus based instrumentation using hybrid approach of OOSE and data flow programming. The LVPD is a pulsed plasma device involved in pursuing investigations ranging from excitation of wave packets of whistler time scales, relevant to space plasmas to understanding of plasma instability and transport due to electron temperature gradient (ETG) driven turbulence, relevant for fusion plasmas. The development of DACS effectively handles high acquisition cards on PXIe bus, data streaming, high channel count system design and synchronized behavior on the backplane bus. Application development include development of applications highlighting pulsed operation and data visualization including development of oscilloscope for raw and process data visualization. This paper will discuss the requirements, object oriented design, development, testing, results and lessons learned from this initiative.},
keywords={Hardware;Computer architecture;Nickel;Data acquisition;Plasmas;Software packages},
doi={10.1109/CONFLUENCE.2017.7943259},
ISSN={},
month={Jan},}
@INPROCEEDINGS{405465,
author={Olesak, P.J.},
booktitle={Proceedings of IEEE Frontiers in Education Conference - FIE '93},
title={Linking classroom learning with SPC software},
year={1993},
volume={},
number={},
pages={544-545},
abstract={It is suggested that laboratory sessions which stress construction and interpretation of control charts and other statistical tools can strengthen students' understanding of SPC (statistical process control) concepts. The statistical software package used by the author in her laboratory sessions reinforces the "calculations" side of the SPC along with construction and interpretation of control charts. Students learn of economical, statistical software packages currently available that simplify and enhance control charting as well as other statistical tools. Each laboratory session is designed to reinforce a corresponding lecture.<>},
keywords={Joining processes;Control charts;Automatic control;Costs;Histograms;Cause effect analysis;Software packages;Materials science and technology;Data analysis;Laboratories},
doi={10.1109/FIE.1993.405465},
ISSN={0190-5848},
month={Nov},}
@ARTICLE{4448478,
author={Adamczewski, J. and Essel, H. G. and Kurz, N. and Linev, S.},
journal={IEEE Transactions on Nuclear Science},
title={Data Acquisition Backbone Core DABC},
year={2008},
volume={55},
number={1},
pages={251-255},
abstract={For the new experiments at FAIR new concepts of data acquisition systems have to be developed like the distribution of self-triggered, time stamped data streams over high performance networks for event building. The Data Acquisition Backbone Core (DABC) is a software package designed for FAIR detector tests, readout components test, and data flow investigations. All kinds of data channels (front-end systems) are connected by program plug-ins into functional components of DABC like data input, combiner, scheduler, event builder, analysis and storage components. After detailed simulations real tests of event building over a switched network (InfiniBand clusters with up to 23 nodes) have been performed. With the DABC software more than 900 MByte/s input and output per node can be achieved meeting the most demanding requirements. The software is ready for the implementation of various test beds needed for the final design of data acquisition systems at FAIR.},
keywords={Data acquisition;Spine;Software testing;Buildings;Software packages;Software design;Detectors;Discrete event simulation;Performance evaluation;System testing;Data acquisition;event builder;InfiniBand;multiprocessor interconnection;software},
doi={10.1109/TNS.2007.913938},
ISSN={1558-1578},
month={Feb},}
@INPROCEEDINGS{9125370,
author={Torres-Rios, Emmanuel and Pérez-Rojas, Daniel and Antonio-Torres, David and Moreno-Moreno, Jesús and Carrillo-Martínez, Luis Antonio},
booktitle={2020 IEEE Global Engineering Education Conference (EDUCON)},
title={IoT Device Implementation for Evaluation of Electronics and Software Design Skills},
year={2020},
volume={},
number={},
pages={1651-1656},
abstract={The use of specific hardware and the Application Programing Interface (API) are incorporated into a methodology for the study of the Internet of Things (IoT) from the point of view of electronic, computing, communication and data base design. Selected courses in one semester of the curricula of the student career are grouped and create a task force is created to achieve a final project. Topics covered in this semester are: sensors and actuators, microcontrollers architecture, analog electronic design, and social entrepreneurship. The proposed final project implements the knowledge of each course and incorporates some specific elements of the IoT environment. The final project is always supervised by the professors of the semester and by a guest company that collaborates in the observations of details in the implementation of the final product during the design and development time. The guest company designates two or three specific engineers in their area of information technology or logistics to join the students for three specific weeks of the semester. The results observed in the application of this methodology shows a high impact in the understanding of the theory and improvement in the circuit design capabilities from the conceptual description to final product.},
keywords={Microcontrollers;Software algorithms;Prototypes;Companies;Hardware;Sensors;Internet of Things;IoT;electronic design;electronic device specification;engineering education;educational innovation;higher education},
doi={10.1109/EDUCON45650.2020.9125370},
ISSN={2165-9567},
month={April},}
@INPROCEEDINGS{777993,
author={Ncube, C. and Maiden, N.A.M.},
booktitle={Proceedings IEEE International Symposium on Requirements Engineering (Cat. No.PR00188)},
title={Guiding parallel requirements acquisition and COTS software selection},
year={1999},
volume={},
number={},
pages={133-140},
abstract={This paper proposes a new process to address the lack of guidance for acquiring requirements to enable evaluation of commercial off-the-shelf (COTS) software. The process is part goal-driven and part context-driven, in that it exploits models of the candidate COTS software as well as process goals to guide a requirements engineering team. The paper demonstrates the approach with selection of a commercial electronic mail system. It also describes a prototype software tool currently under development, and outlines future research directions to extend and evaluate the approach.},
keywords={Software tools;Software prototyping;System analysis and design;Guidelines;Decision making;Human computer interaction;Context modeling;Design engineering;Process design;Software systems},
doi={10.1109/ISRE.1999.777993},
ISSN={},
month={June},}
@INPROCEEDINGS{6266941,
author={Nowicki, Marek and Bała, Piotr},
booktitle={2012 International Conference on High Performance Computing & Simulation (HPCS)},
title={Parallel computations in Java with PCJ library},
year={2012},
volume={},
number={},
pages={381-387},
abstract={In this paper we present PCJ — a new library for parallel computations in Java inspired by the partitioned global address space approach. We present design details together with the examples of usage for basic operations such as a point-point communication, synchronization or broadcast. The PCJ library is easy to use and allows for a fast development of the parallel programs. It allows to develop distributed applications in easy way, hiding communication details which allows user to focus on the implementation of the algorithm rather than on network or threads programming. The objects and variables are local to the program threads however some variables can be marked shared which allows to access them from different nodes. For shared variables PCJ offers one-sided communication which allows for easy access to the data stored at the different nodes. The parallel programs developed with PCJ can be run on the distributed systems with different Java VM running on the nodes. In the paper we present evaluation of the performance of the PCJ communication on the state of art hardware. The results are compared with the native MPI implementation showing good performance and scalability of the PCJ.},
keywords={Java;Libraries;Message systems;Synchronization;Monitoring;Hardware;Instruction sets;parallelization tools;software engineering;performance},
doi={10.1109/HPCSim.2012.6266941},
ISSN={},
month={July},}
@ARTICLE{9349185,
author={Tian, Jing and Wang, Piaoyang and Liu, Zhe and Lin, Jun and Wang, Zhongfeng and Großschädl, Johann},
journal={IEEE Transactions on Computers},
title={Efficient Software Implementation of the SIKE Protocol Using a New Data Representation},
year={2022},
volume={71},
number={3},
pages={670-683},
abstract={Thanks to relatively small public and secret keys, the Supersingular Isogeny Key Encapsulation (SIKE) protocol made it into the third evaluation round of the post-quantum standardization project of the National Institute of Standards and Technology (NIST). Even though a large body of research has been devoted to the efficient implementation of SIKE, its latency is still undesirably long for many real-world applications. Most existing implementations of the SIKE protocol use the Montgomery representation for the underlying field arithmetic since the corresponding reduction algorithm is considered the fastest method for performing multiple-precision modular reduction. In this paper, we propose a new data representation for supersingular isogeny-based Elliptic-Curve Cryptography (ECC), of which SIKE is a sub-class. This new representation enables significantly faster implementations of modular reduction than the Montgomery reduction, and also other finite-field arithmetic operations used in ECC can benefit from our data representation. We implemented all arithmetic operations in C using the proposed representation such that they have constant execution time and integrated them to the latest version of the SIKE software library. Using four different parameters sets, we benchmarked our design and the optimized generic implementation on a 2.6 GHz Intel Xeon E5-2690 processor. Our results show that, for the prime of SIKEp751, the proposed reduction algorithm is approximately 2.61 times faster than the currently best implementation of Montgomery reduction, and our representation also enables significantly better timings for other finite-field operations. Due to these improvements, we were able to achieve a speed-up by a factor of about 1.65, 2.03, 1.61, and 1.48 for SIKEp751, SIKEp610, SIKEp503, and SIKEp434, respectively, compared to state-of-the-art generic implementations.},
keywords={Protocols;Cryptography;Elliptic curves;Elliptic curve cryptography;Software algorithms;Public key;NIST;Supersingular Isogeny Diffie-Hellman (SIDH) key exchange;Elliptic Curve Cryptography (ECC);modular reduction operation;montgomery representation;barrett representation;Post-Quantum Cryptography (PQC)},
doi={10.1109/TC.2021.3057331},
ISSN={1557-9956},
month={March},}
@INPROCEEDINGS{1466147,
author={KiSeun Kwon and YoungMin Yi and DoHyung Kim and SoonHoi Ha},
booktitle={Proceedings of the ASP-DAC 2005. Asia and South Pacific Design Automation Conference, 2005.},
title={Embedded software generation from system level specification for multi-tasking embedded systems},
year={2005},
volume={1},
number={},
pages={145-150 Vol. 1},
abstract={In this paper we present a new design flow in which embedded software code is generated from system level specification of multi-tasking embedded system, both for simulation and implementation. The generated software has a layered structure using virtual OS APIs and OS wrapper implementations to make it reconfigurable for multiple target platforms. Implementation of the OS wrapper is explained in details. With a Divx play example, we show some experimental results about the real-time performance comparison between two different platforms.},
keywords={Embedded software;Embedded system;Decoding;Distributed power generation;Debugging;Engines;Streaming media;Control systems;Educational institutions;Computer science},
doi={10.1109/ASPDAC.2005.1466147},
ISSN={2153-697X},
month={Jan},}
@INPROCEEDINGS{840886,
author={Moya, J.M. and Dominguez, S. and Moya, F. and Lopez, J.C.},
booktitle={Proceedings Design, Automation and Test in Europe Conference and Exhibition 2000 (Cat. No. PR00537)},
title={A flexible specification framework for hardware-software codesign},
year={2000},
volume={},
number={},
pages={753-},
abstract={Presents a new specification technique for complex hardware-sofware systems, based on standard high-level programming languages, such as C, C++, Java, Scheme, or Ada, without extensions or semantic changes. Unlike previous approaches, the designer may choose the model of computation and the specification language that best suits her needs, while still being able to formally verify the correctness of the specification. The details of the available hardware and software resources, and the implementation of the different models of computation are encapsulated in libraries to maximize reuse in system specifications.},
keywords={Computational modeling;Java;Software libraries;Specification languages;Hardware;Application software;Formal verification;Computer architecture;Computer interfaces;Petri nets},
doi={10.1109/DATE.2000.840886},
ISSN={},
month={March},}