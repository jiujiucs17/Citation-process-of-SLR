@INPROCEEDINGS{5076643,
author={Shen, Liwei and Peng, Xin and Zhao, Wenyun},
booktitle={2009 Australian Software Engineering Conference},
title={A Comprehensive Feature-Oriented Traceability Model for Software Product Line Development},
year={2009},
volume={},
number={},
pages={210-219},
abstract={Feature-oriented traceability is essential for efficient Software Product Line (SPL) development, including product derivation and SPL evolution. Widely-used feature based method has been proved to be effective in domain analysis and modeling. However, it cannot support the traceability naturally due to the big gap between the problem space and the solution space. In this paper, we propose a comprehensive feature-oriented traceability model for SPL development, which provides mechanisms for various features and implementation types throughout the four levels of goal model, feature model, feature implementation model and program implementations. In it, the feature implementation model is introduced as the intermediate level between features and implementation artefacts. The feature interactions are captured in the finer role level, and they help to clarify the complex mapping between features and program implementations. The traceability meta-model for SPL development is introduced and an example on the library management domain is demonstrated.},
keywords={Software engineering;Scattering;Australia;Computer science;Software libraries;Asset management;Software development management;Engineering management;Data structures;Collaborative work},
doi={10.1109/ASWEC.2009.27},
ISSN={2377-5408},
month={April},}
@INPROCEEDINGS{528216,
author={Deutsch, J.K. and Gary, M.R.},
booktitle={Proceedings of IEEE 14th Symposium on Mass Storage Systems},
title={Physical volume library deadlock avoidance in a striped media environment},
year={1995},
volume={},
number={},
pages={54-64},
abstract={Most modern high performance storage systems store data in large repositories of removable media volumes. Management of the removable volumes is performed by a software module known as a physical volume library (PVL). To meet performance and scalability requirements, a PVL can be asked to mount multiple removable media volumes for use by a single client for parallel data transfer. Mounting sets of volumes creates an environment in which it is possible for multiple client requests to deadlock while attempting to gain access to storage resources. Scenarios leading to deadlock in a PVL include multiple client requests that contend for the same cartridge(s), and client requests that vie for a limited set of drive resources. These deadlock scenarios are further complicated by the potential for volumes to be mounted out-of-order (for example, by automatic cartridge loaders or human operators). This paper begins by introducing those PVL requirements which create the possibility of deadlock resolution and how they might be applied in a PVL. This leads to a design for a PVL that addresses deadlock scenarios. Following the design presentation is a discussion of possible design enhancements. We end with a case study of an actual implementation of the PVL design in the high performance storage system (HPSS).},
keywords={Libraries;System recovery;Humans;Memory;Variable structure systems;Government;Laboratories;Scalability;Out of order;Bandwidth},
doi={10.1109/MASS.1995.528216},
ISSN={1051-9173},
month={Sep.},}
@INPROCEEDINGS{1231395,
author={Inverardi, P. and Tivoli, M. and Bucchiarone, A.},
booktitle={WET ICE 2003. Proceedings. Twelfth IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises, 2003.},
title={Automatic synthesis of coordinators for COTS groupware applications: an example},
year={2003},
volume={},
number={},
pages={123-128},
abstract={The coordination of concurrent activities in collaborative environments is a very important and difficult task. Many approaches for the construction of large-scale flexible group-ware applications there exist in the literature. They provide valid support to modeling, analysis and to a whitebox developing of coordination protocols for computer supported cooperative applications. Little attention has been dedicated so far to group-ware applications built by assembling third-party components. In this paper by means of an exploratory example, we apply a software architecture based approach to the group-ware systems development. The software architecture imposed on the coordinating part of the system, allows for detection and recovery of possible and unpredictable concurrent activities conflicts. Moreover, the approach allows the enforcing of coordination policies on the composed system by automatically synthesizing the policy-satisfying assembly code.},
keywords={Application software;Collaborative work;Assembly systems;Connectors;Software architecture;Large-scale systems;Protocols;Collaboration;Computer applications;Concurrent computing},
doi={10.1109/ENABL.2003.1231395},
ISSN={1080-1383},
month={June},}
@INPROCEEDINGS{823407,
author={Zoraja, I. and Bode, A. and Sunderam, V.},
booktitle={Proceedings 8th Euromicro Workshop on Parallel and Distributed Processing},
title={A framework for process migration in software DSM environments},
year={2000},
volume={},
number={},
pages={158-165},
abstract={Proves that process migration can successfully be implemented for software distributed shared memory (DSM) environments. We have developed a migration framework that is able to transparently migrate DSM processes, thereby preserving the consistency of running applications. The migration framework is integrated into the CORAL (Cooperative Online monitoRing Actions Layer) system, an online monitoring system that connects parallel tools to a running application. A special emphasis has been put on techniques and mechanisms for the migration of shared resources and communication channels as well as internal monitoring data structures. Currently, the migration framework migrates parallel processes based on the TreadMarks library. The Condor library has been utilized for the state transfer of a single process. In a computing environment consisting of eight nodes running TreadMarks applications, the migration framework brings a 10% overhead to Condor and grows almost linearly with added nodes. Although our first implementation supports TreadMarks applications, both the monitoring system and the migration framework are designed to be reusable and easily adaptable to other software DSM systems.},
keywords={Monitoring;Load management;Application software;Computer science;Processor scheduling;Programming profession;Message passing;Concurrent computing;Military computing;Information management},
doi={10.1109/EMPDP.2000.823407},
ISSN={},
month={Jan},}
@INPROCEEDINGS{557902,
author={Messer, A. and Wilkinson, T.},
booktitle={Proceedings of the Fifth International Workshop on Object-Orientation in Operation Systems},
title={Components for operating system design},
year={1996},
volume={},
number={},
pages={128-132},
abstract={Components are being increasingly used in the construction of complex application software. Operating systems suffer from similar software complexities, causing a move to architectures such as micro-kernels. The authors propose a low-overhead technique for providing components that allow the level of coupling between components to be varied at run-time. In doing so, they indicate their use in a component-orientated operating system to allow its components to be 'hot-plugged' during execution.},
keywords={Operating systems;Runtime;Computer architecture;Application software;Kernel;Libraries;Software maintenance;Protection;Costs;LAN interconnection},
doi={10.1109/IWOOOS.1996.557902},
ISSN={1063-5351},
month={Oct},}
@INPROCEEDINGS{932551,
author={Freund, E. and Ludemann-Ravit, B. and Stern, O. and Koch, T.},
booktitle={Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)},
title={Creating the architecture of a translator framework for robot programming languages},
year={2001},
volume={1},
number={},
pages={187-192 vol.1},
abstract={Presents an approach to facilitate the development and maintenance of translators for industrial robot programming languages. Such translators are widely used in robot simulation and offline programming systems to support programming in the respective native robot language. Our method is based upon a software architecture, that is provided as a complete translator framework. For the developer of a new translator, it offers convenient strategies to concentrate on robot specific language elements during the design and implementation process: fill-in templates, libraries for common functionality, design patterns etc., all tied up with a general translation scheme. In contrast to other compiler construction tools, the developers need not care about the complex details of a whole translator. As a matter of principle, the architecture offers a complete default translator (except for the grammar). Robot specific elements can be held in separate units-outside of the actual translator-to facilitate maintenance and feature extension. The most probable changes in the translator product life cycle are restricted to the adaptation of these units. Several translators built upon this framework are in actual use in the commercial robot simulation system COSIMIR(R) to support native language robot programming, as well as in the widely used robot programming system COSIROP to verify the syntax of robot programs.},
keywords={Robot programming;Service robots;Robot control;Electrical equipment industry;Manufacturing;Production;Analytical models;Computer languages;Process design;Software libraries},
doi={10.1109/ROBOT.2001.932551},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{581526,
author={Ji-Hoon Jeong and Moon-Kyun Oh and Han-Kyoung Kim},
booktitle={1997 IEEE International Performance, Computing and Communications Conference},
title={The design and implementation of call/connection control software in ATM switching system for multimedia services},
year={1997},
volume={},
number={},
pages={259-265},
abstract={The call/connection control functions, capable of diverse call/connection, are one of the most important capability in ATM switching system for multimedia services. We describe the design and implementation technology of call/connection control based on the scenario socket, process instance identifier (PID) succession, call/connection processing system library, and the data configuration method for multimedia services. By using these in the ATM switching system development, we can provide urgently demanded B-ISDN services and adopt new diverse services easily.},
keywords={Control systems;Asynchronous transfer mode;Switching systems;B-ISDN;Protocols;Multimedia systems;Communication system control;Telecommunication control;Bandwidth;Topology},
doi={10.1109/PCCC.1997.581526},
ISSN={},
month={Feb},}
@INPROCEEDINGS{493444,
author={Larsen, L. and Harrold, M.J.},
booktitle={Proceedings of IEEE 18th International Conference on Software Engineering},
title={Slicing object-oriented software},
year={1996},
volume={},
number={},
pages={495-505},
abstract={Describes the construction of system dependence graphs for object-oriented software on which efficient slicing algorithms can be applied. We construct these system dependence graphs for individual classes, groups of interacting classes and complete object-oriented programs. For an incomplete system consisting of a single class or a number of interacting classes, we construct a procedure dependence graph that simulates all possible calls to public methods in the class. For a complete system, we construct a procedure dependence graph from the main program in the system. Using these system dependence graphs, we show how to compute slices for individual classes, groups of interacting classes and complete programs. One advantage of our approach is that the system dependence graphs can be constructed incrementally because representations of classes can be reused. Another advantage of our approach is that slices can be computed for incomplete object-oriented programs such as classes or class libraries. We present our results for C++, but our techniques can be applied to other statically typed object-oriented languages such as Ada-95.},
keywords={Testing;Computer science;Software algorithms;Computational modeling;Object oriented modeling;Libraries;Data analysis;Algorithm design and analysis;Flow graphs;Data flow computing},
doi={10.1109/ICSE.1996.493444},
ISSN={0270-5257},
month={March},}
@INPROCEEDINGS{9632034,
author={Chesnokov, Andrei and Mikhailov, Vitalii and Dolmatov, Ivan},
booktitle={2021 3rd International Conference on Control Systems, Mathematical Modeling, Automation and Energy Efficiency (SUMMA)},
title={Numerical Algorithm for Finding Optimal Parameters of Pre-stressed Roof Structure},
year={2021},
volume={},
number={},
pages={523-527},
abstract={Numerical technique for finding optimal parameters of the roof structure is proposed. The structure consists of pre-stressed bearer and backstay chords made of high-strength steel cables. The roof has reduced overall height. It is the appropriate solution for long-span buildings. The coordinate descent method is used to perform structural optimization. This approach allows gaining precise results which are to be used for further nonlinear structural analysis by specialized software packages. The present study contributes to automated structural simulation of cable and membrane building constructions.},
keywords={Software packages;Buildings;Software algorithms;Control systems;Mathematical models;Energy efficiency;Numerical models;coordinate descent method;automated structural simulation;cable roof;numerical technique},
doi={10.1109/SUMMA53307.2021.9632034},
ISSN={},
month={Nov},}
@INPROCEEDINGS{5069262,
author={Ali, Mohd Amry Johan Mohd and Adnan, Ramli and Tahir, Nooritawati Md and Rahman, Mohd Hezri Fazalul and Yahya, Zahrullaili and Samad, Abd. Manan},
booktitle={2009 5th International Colloquium on Signal Processing & Its Applications},
title={A feasibility study of automated Digital Elevation Model (DEM) construction using Arc Micro Language (AML)},
year={2009},
volume={},
number={},
pages={413-417},
abstract={This study is about automated of digital elevation model (DEM) construction using arc macro language (AML). Generating digital elevation model (DEM) from geographic information system (GIS) module is quite complicated as well as in ARC/INFO workstation. It required data conversion and some other process that give user adversity which need to study the steps in sequence and orderly. To overcome the problem, we have to develop an automated technique in geographic information system (GIS) for generating DEM with simple steps. All procedures were developed with ARC/INFO workstation, GIS software and fully automated in Arc macro language (AML).},
keywords={Digital elevation models;Geographic Information Systems;Workstations;Computer languages;Digital signal processing;Civil engineering;Educational institutions;Software measurement;Length measurement;Packaging;Arc Macro Language (AML);Digital Elevation Model (DEM);Geographic Information System (GIS)},
doi={10.1109/CSPA.2009.5069262},
ISSN={},
month={March},}
@INPROCEEDINGS{7999865,
author={Lin, Puru Burce and Ko, Cheng-Ta and Ho, Wei-Tse and Kuo, Chi-Hai and Chen, Kuan-Wen and Chen, Yu-Hua and Tseng, Tzyy-Jang},
booktitle={2017 IEEE 67th Electronic Components and Technology Conference (ECTC)},
title={A Comprehensive Study on Stress and Warpage by Design, Simulation and Fabrication of RDL-First Panel Level Fan-Out Technology for Advanced Package},
year={2017},
volume={},
number={},
pages={1413-1418},
abstract={Rapid development of semiconductor technology and multi-function demands of end products has driven IC foundry industry toward 7nm node process, and even next generation of 5nm. The I/O pitch of chip is reduced accordingly but the build-up layer of IC carrier is still too large to fit interconnects. In order to overcome the gap of I/O pitch between IC chip and carrier, the interposer technology has been considered as a solution to resolve the issue. However, the cost of silicon interposer is too high, and the glass interposer lacks the associated infrastructure and is difficult to be handled, which makes a technology drawback for market applications. Alternatively, fan-out wafer/panel level package technology is getting more attractions for advanced package recently because of its features of low profile, small form factor, and high bandwidth with fine line re-distribution layer (RDL) routability. There are lots of literatures addressing about the residual stress and warpage mostly on wafer level fan-out technology, especially for chip-first technology scheme. However, comprehensive study on the panel level fan-out is not mature yet. This paper investigates fundamental factors that impact the residual stress and warpage level of panel level fan-out package, such as metal layer counts, thickness of dielectric and metal layer, coefficient of thermal expansion (CTE) and Young's modulus of dielectric and molding compound, molding gap and molding process temperature, etc. In this study, a RDL-first (chip-last) fan-out panel level structure of three metal layers on releasing film molded with epoxy compound was established as a simulation model by means of finite element analysis software. The simulation results provide a guideline of design rules for fabricating multi-layer RDL panel level fan-out package and making the minimum residual stress while chip assembly. Fabrication of three-layer dielectric panel level fan-out, where 370mmx470mm panel size is applied, is also demonstrated to compare with the simulation results.},
keywords={Compounds;Metals;Residual stresses;Dielectrics;Glass;Strain;Fabrication;RDL-first;panel level;fan-out;epoxy compound},
doi={10.1109/ECTC.2017.106},
ISSN={2377-5726},
month={May},}
@INPROCEEDINGS{4483212,
author={Yang, Hong Yul and Tempero, Ewan and Melton, Hayden},
booktitle={19th Australian Conference on Software Engineering (aswec 2008)},
title={An Empirical Study into Use of Dependency Injection in Java},
year={2008},
volume={},
number={},
pages={239-247},
abstract={Over the years many guidelines have been offered as to how to achieve good quality designs. We would like to be able to determine to what degree these guidelines actually help. To do that, we need to be able to determine when the guidelines have been followed. This is often difficult as the guidelines are often presented as heuristics or otherwise not completely specified. Nevertheless, we believe it is important to gather quantitative data on the effectiveness of design guidelines wherever possible. In this paper, we examine the use of "dependency injection", which is a design principle that is claimed to increase software design quality attributes such as extensibility, modifiability, testability, and reusability. We develop operational definitions for it and analysis techniques for detecting its use. We demonstrate these techniques by applying them to 34 open source Java applications.},
keywords={Java;Guidelines;Electronics packaging;Software testing;Application software;System testing;Software quality;Software engineering;Computer science;Software design;dependency injection;empirical study;java;software corpus},
doi={10.1109/ASWEC.2008.4483212},
ISSN={2377-5408},
month={March},}
@ARTICLE{6825920,
author={Valcárcel, Daniel F. and Alves, Diogo and Neto, André and Reux, Cédric and Carvalho, Bernardo B. and Felton, Robert and Lomas, Peter J. and Sousa, Jorge and Zabeo, Luca},
journal={IEEE Transactions on Nuclear Science},
title={Parallel Task Management Library for MARTe},
year={2014},
volume={61},
number={3},
pages={1222-1227},
abstract={The Multithreaded Application Real-Time executor (MARTe) is a real-time framework with increasing popularity and support in the thermonuclear fusion community. It allows modular code to run in a multi-threaded environment leveraging on the current multi-core processor (CPU) technology. One application that relies on the MARTe framework is the Joint European Torus (JET) tokamak WAll Load Limiter System (WALLS). It calculates and monitors the temperature on metal tiles and plasma facing components (PFCs) that can melt or flake if their temperature gets too high when exposed to power loads. One of the main time consuming tasks in WALLS is the calculation of thermal diffusion models in real-time. These models tend to be described by very large state-space models thus making them perfect candidates for parallelisation. MARTe's traditional approach for task parallelisation is to split the problem into several Real-Time Threads, each responsible for a self-contained sequential execution of an input-to-output chain. This is usually possible, but it might not always be practical for algorithmic or technical reasons. Also, it might not be easily scalable with an increase in the number of available CPU cores. The WorkLibrary introduces a “GPU-like approach” of splitting work among the available cores of modern CPUs that is (i) straightforward to use in an application, (ii) scalable with the availability of cores and all of this (iii) without rewriting or recompiling the source code. The first part of this article explains the motivation behind the library, its architecture and implementation. The second part presents a real application for WALLS, a parallel version of a large state-space model describing the 2D thermal diffusion on a JET tile.},
keywords={Real-time systems;Libraries;Parallel processing;Instruction sets;Load modeling;Central Processing Unit;Parallel processing;real time computer applications;real time software systems},
doi={10.1109/TNS.2014.2321194},
ISSN={1558-1578},
month={June},}
@INPROCEEDINGS{5303208,
author={Feng, Jingchun and Zhang, Fujie and Li, Ming},
booktitle={2009 International Conference on Management and Service Science},
title={Research on Work Breakdown Structure of IT Project},
year={2009},
volume={},
number={},
pages={1-5},
abstract={Work breakdown structure of IT project is one basic part of IT project management. IT project valuation and price, IT project objective control, IT project procurement and IT project contract management are all connected with IT work breakdown structure. This paper studies IT work breakdown structure and the meaning of each level including IT project, monomial works, unit works, subsection works and subentry works by analyzing the purpose of IT work breakdown structure. Based on the research above, this paper makes a detailed research on the breakdown of monomial works including communication engineering, software development, system integration and Website construction, thus putting forward IT work breakdown structure and breakdown structure of the four monomial works mentioned above.},
keywords={Electric breakdown;Project management;Packaging;Contracts;Scheduling;Cost accounting;Procurement;Systems engineering and theory;Programming;Information technology},
doi={10.1109/ICMSS.2009.5303208},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{4725707,
author={Barbier, Franck and Cariou, Eric},
booktitle={2008 34th Euromicro Conference Software Engineering and Advanced Applications},
title={Component Design based on Model Executability},
year={2008},
volume={},
number={},
pages={68-75},
abstract={Model-driven development (MDD) corresponds to the building of models and their transformation into intermediate models and code. Modeling components and compositions is a natural consequence of MDD. We show in this paper the advantages of using an executable modeling language associated with a Java library which pre-implements the execution semantics of this language. The proposed executable language is based on UML state machine diagrams. The semantic variation points linked to these diagrams lead us to manage equivalent variations in the Java implementation of components. The paper offers a comprehensive component design method based on a tailor-made UML profile whose role is the control of the semantic variation points in models.},
keywords={Java;Unified modeling language;Object oriented modeling;Runtime;Engines;Libraries;Design methodology;Documentation;Software engineering;Application software;Software component;MDA;executability},
doi={10.1109/SEAA.2008.16},
ISSN={2376-9505},
month={Sep.},}
@INPROCEEDINGS{9129981,
author={Covaciu, Florin and Pisla, Adrian and Vaida, Calin and Gherman, Bogdan and Pisla, Doina},
booktitle={2020 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)},
title={Development of a Virtual Reality Simulator for a Lower Limb Rehabilitation Robot},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The paper describes the design of a virtual reality simulator destined to a robotic system designed for patient's lower limb medical recovery. The VR simulator is created in Unity 5 environment. In this environment was imported the mechanical design of the robotic structure, together with a virtual human model (an avatar) that latter was coupled with the robotic structure. The robotic mechanical structure is designed in the Siemens NX environment, a professional mechatronics design software and the human virtual model was created using the MakeHuman program, an open source 3D computer graphics middleware. In the first step for creating the virtual reality simulator, an enclosure was defined where the robotic structure used to recover the lower limb has been introduced. In the second stage, the human virtual model was loaded into Unity 5 environment and “attached” to the robotic mechanical system. In the last stage was defined a Robotic system User Interface (RUI) for the robotic system control. The RUI was created using C Sharp (C#) programming language that exists within the Visual Studio software package.},
keywords={Solid modeling;Visualization;Three-dimensional displays;Software packages;Computational modeling;User interfaces;Rehabilitation robotics;rehabilitation robot design;virtual reality;robotic system user interface;lower limb recovery simulation},
doi={10.1109/AQTR49680.2020.9129981},
ISSN={},
month={May},}
@INPROCEEDINGS{522008,
author={Morley, J.A.},
booktitle={Proceedings of the IEEE 1995 National Aerospace and Electronics Conference. NAECON 1995},
title={Personal computer database development and the end user},
year={1995},
volume={2},
number={},
pages={664-671 vol.2},
abstract={Advances in personal computer hardware and software technology have placed enormous computing power into the hands of even the most casual users. More advanced users are beginning to take advantage of sophisticated PC-based database management system products to develop their own databases. Many of these users do not understand the importance of designing sound data structures into their database applications. This paper addresses the problem by outlining a database construction methodology that can be employed by nontechnical users. The methodology focuses on easy-to-follow steps and eliminates references to technical terminology that may confuse the user-developer. The philosophy is that users can apply these techniques to build better databases without understanding terms such as obligatory and non-obligatory membership class, insertion, deletion and update anomalies; first, second and third normal forms, and referential integrity.},
keywords={Microcomputers;Hardware;Application software;Database systems;Packaging;Data processing;Information systems;Drives;Data structures;Terminology},
doi={10.1109/NAECON.1995.522008},
ISSN={0547-3578},
month={May},}
@INPROCEEDINGS{666238,
author={Voigt Knudsen, P. and Madsen, J.},
booktitle={Proceedings of the Sixth International Workshop on Hardware/Software Codesign. (CODES/CASHE'98)},
title={Communication estimation for hardware/software codesign},
year={1998},
volume={},
number={},
pages={55-59},
abstract={This paper presents a general high level estimation model of communication throughput for the implementation of a given communication protocol. The model, which is part of a larger model that includes component price, software driver object code size and hardware driver area, is intended to be general enough to be able to capture the characteristics of a wide range of communication protocols and yet to be sufficiently detailed as to allow the designer or design tool to efficiently explore tradeoffs between throughput, bus widths, burst/non-burst transfers and data packing strategies. Thus it provides a basis for decision making with respect to communication protocols/components and communication driver design in the initial design space exploration phase of a co-synthesis process where a large number of possibilities must be examined and where fast estimators are therefore necessary. The fill model allows for additional (money) cost, software code size and hardware area tradeoffs to be examined.},
keywords={Hardware;Protocols;Space exploration;Delay;Information technology;Decision making;Software libraries;Communication channels;Coprocessors;Degradation},
doi={10.1109/HSC.1998.666238},
ISSN={1092-6100},
month={March},}
@INPROCEEDINGS{5347106,
author={Khalgui, Mohamed and Hanisch, Hans-Michael and Gharbi, Atef},
booktitle={2009 IEEE Conference on Emerging Technologies & Factory Automation},
title={Model-checking for the functional safety of Control Component-based heterogeneous embedded systems},
year={2009},
volume={},
number={},
pages={1-10},
abstract={This paper1 deals with the model checking of Safe Heterogeneous Embedded Control Systems following different component-based technologies or implemented according to different Architecture Description Languages (ADL) used today in industry. The purpose is to reduce their time to market by exploiting various execution environments and different rich libraries. A ¿Control Component¿ is defined in our research work as an event-triggered software unit composed of an interface for any external interactions and an implementation allowing control actions of physical processes. A control system is assumed to be a composition of components with precedence constraints to control the plant according to well-defined execution orders. We define an agent-based architecture where the agent controls the environment evolution and applies automatic reconfigurations when hardware errors occur at run-time to guarantee a functional safety of the whole system. We model the architecture according to the formalism Net Condition/Event Systems (abbr. NCES), and apply the model checker SESA to check functional properties described according to the well-known Computation Tree Logic (abbr. CTL). Our purpose is to check that whenever an error occurs at run-time, the agent behaves as described in user requirements by activating Control Components and deactivating others to guarantee a functional safety of the whole system. A Benchmark Production System is used in this research work to explain our contribution.},
keywords={Safety;Embedded system;Automatic control;Control systems;Computer architecture;Error correction;Runtime;Control system synthesis;Architecture description languages;Electrical equipment industry;Software Component;Functional Safety;Agent-based Architecture;Automatic Reconfiguration;Model Checking},
doi={10.1109/ETFA.2009.5347106},
ISSN={1946-0759},
month={Sep.},}
@INPROCEEDINGS{6970181,
author={Stathopoulou, Ioanna-Ourania and Stathopoulos, Panagiotis and Georgiadis, Haris and Houssos, Nikos and Banos, Vangelis and Sachini, Evi},
booktitle={IEEE/ACM Joint Conference on Digital Libraries},
title={An Open Cultural Digital Content Infrastructure},
year={2014},
volume={},
number={},
pages={285-288},
abstract={We present an Open Cultural Digital Content Infrastructure, a platform providing a coherent suite of loosely-coupled services that aim to promote metadata quality in repositories and facilitate metadata data and digital content reuse. The key functions of the infrastructure are the aggregation of metadata and digital files and the automatic validation of metadata records and digital material for compliance with desired quality specifications. The system that has recently moved to production, is currently being employed to ensure the quality standards of the output of more than 70 projects that support Greek cultural heritage organisations and are funded by the European Union structural funds. These projects are expected to produce more than 1.5 million digitized and born-digital items accompanied with detailed metadata. The validation is based on a set of quality and interoperability specifications that have been developed for the purpose. The infrastructure has been developed using an open source technology stack and tools and in particular reuses a number of components of the publicly available Europeana aggregator and portal software platform.},
keywords={Europe;Cultural differences;Documentation;Interoperability;Computer architecture;Standards;Data models;Metadata aggregation;Metadata quality;Metadata validation;Digital content aggregration;Digital content aggregration validation;Cultural Heritage Infrastructures;OAI-PMH;Interoperability guidelines;Metadata harvesting},
doi={10.1109/JCDL.2014.6970181},
ISSN={},
month={Sep.},}
@ARTICLE{286076,
author={},
journal={IEEE Std 1224.1-1993},
title={IEEE Standard for Information Technology--X.400-Based Electronic Messaging--Application Program Interface (API) [Language Independent]},
year={1993},
volume={},
number={},
pages={1-147},
abstract={Application program interfaces (APIs) to X.400-based electronic messaging services are defined in terms that are independent of any particular programming language. A general-purpose API that makes the functionality of a message transfer system (MTS) accessible to a message store (MS) or user agent (UA), or the functionality of a simple MS accessible to a UA, is provided. An X.400 gateway API divides a message transfer agent (MTA) into two software components, a messaging system gateway and an X.400 gateway service. This standard, and the language bindings derived from it, are intended to be used in conjunction with IEEE Std 1224-1993, which provides a general-purpose API for the creation, examination, modification, and deletion of OSI information objects.},
keywords={IEEE Standards;Open systems;Computer languages;Logic gates;Electronic messaging;Consumer electronics;X.400;Open systems interconnection;Open systems;Object management;OSI;Language independent;Electronic messaging;Application portability;API},
doi={10.1109/IEEESTD.1993.119658},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5364947,
author={Evangelista, Pedro and Maia, Paulo and Rocha, Miguel},
booktitle={2009 Ninth International Conference on Intelligent Systems Design and Applications},
title={Implementing Metaheuristic Optimization Algorithms with JECoLi},
year={2009},
volume={},
number={},
pages={505-510},
abstract={This work proposes JECoLi-a novel Java-based library for the implementation of metaheuristic optimization algorithms with a focus on Genetic and Evolutionary Computation based methods. The library was developed based on the principles of flexibility, usability, adaptability, modularity, extensibility, transparency, scalability, robustness and computational efficiency. The project is open-source, so JECoLi is made available under the GPL license, together with extensive documentation and examples, all included in a community Wiki-based web site (http://darwin.di.uminho.pt/jecoli). JECoLi has been/is being used in several research projects that helped to shape its evolution, ranging application fields from Bioinformatics, to Data Mining and Computer Network optimization.},
keywords={Libraries;Java;Optimization methods;Genetics;Evolutionary computation;Usability;Scalability;Robustness;Computational efficiency;Open source software;Evolutionary Computation;Metaheuristics;Open-source software;Java},
doi={10.1109/ISDA.2009.161},
ISSN={2164-7151},
month={Nov},}
@ARTICLE{5512507,
author={Kuhn, Rick and Johnson, Chris},
journal={IT Professional},
title={Vulnerability Trends: Measuring Progress},
year={2010},
volume={12},
number={4},
pages={51-53},
abstract={We analyzed data from the National Vulnerability Database (NVD). Designed and operated by the National Institute of Standards and Technology (NIST) with support from the Department of Homeland Security, the NVD provides fine-grained search capabilities of all publicly reported software vulnerabilities since 1997-a total of 41,810 vulnerabilities for more than 20,000 products. Frequently, a single vulnerability can affect a large number of products-for example, when the fault occurs in a library function.},
keywords={Software measurement;Data analysis;Software libraries;Dictionaries;Guidelines;Arm;Fires;Weapons;Data security;Availability;Information technology;security &;privacy;software vulnerabilities},
doi={10.1109/MITP.2010.116},
ISSN={1941-045X},
month={July},}
@INPROCEEDINGS{1036910,
author={Kizhner, S. and Petrick, D.J. and Flatley, T.P. and Hestnes, P. and Jentoft-Nilsen, M. and Blank, K.},
booktitle={Proceedings, IEEE Aerospace Conference},
title={Pre-hardware optimization of spacecraft image processing software algorithms and hardware implementation},
year={2002},
volume={4},
number={},
pages={4-4},
abstract={Spacecraft telemetry rates and product complexity have steadily increased over the last decade presenting a problem for real-time processing by ground facilities. This paper proposes a solution to a related problem for the Geostationary Operational Environmental Spacecraft (GOES-8) image data processing and color picture generation (GOES-8 application). The proposed solution is based on a PC platform and synergy of optimized software algorithms and reconfigurable computing hardware (RC) technologies, such as FPGA and DSP. The solution involved porting the GOES-8 application from its Silicon Graphics Inc Workstation/UNIX platform, making minor platform specific changes to the GOES-8 application so that it runs on the PC, benchmarking the various code segments, and implementing the most computing intensive functions in hardware. After pre-hardware optimization steps in the PC environment, the necessity for RC hardware implementation for bottleneck code became more evident. The problem was solved beginning with the methodology described by T. Flatley (AIST-0132-0000, 1999), M. Figueiredo et al (IEEE Comp. Mag., pp. 115-118, 1999), and S. Kizhner (Proc. ION GPS'2000), and implementing a novel methodology for this application. The PC-RC interface bandwidth problem for the class of applications with moderate input-output data rates but large intermediate multi source data streams has been addressed and mitigated. This opens a new class of satellite image processing applications for bottleneck problem solution using RC technologies. The issue of a science algorithm level of abstraction necessary for RC hardware implementation is also described. Selected software functions already implemented in hardware were investigated for applicability in order to create a library of RC functions for ongoing work. A complete class of spacecraft image processing applications development using reconfigurable computing technology to meet real-time requirements, including methodology, performance results and comparison with the existing system, is described in this paper.},
keywords={Space vehicles;Image processing;Software algorithms;Hardware;Application software;Space technology;Telemetry;Data processing;Color;Field programmable gate arrays},
doi={10.1109/AERO.2002.1036910},
ISSN={},
month={March},}
@INPROCEEDINGS{1592362,
author={Rendon, O.M.C. and Pabon, F.O.M. and Vargas, M.J.G. and Guaca, J.A.H.},
booktitle={Third Latin American Web Congress (LA-WEB'2005)},
title={Architectures for Web services access from mobile devices},
year={2005},
volume={},
number={},
pages={5 pp.-},
abstract={The success of Web services, an open Internet standards based technology, opens the door to the construction of business applications in the distributed computing world. As Web services are based on open standards, it lets the integration of different kinds of software components, including the wireless and mobile applications. However, the Post PC World, dominated by mobile devices, is not completely ready to Web Service accesss, due to memory and processing constraints. Specific architectures for an easy and clear Web Services integration are required. This article introduces the main aspects related with Web services access from mobile devices. Two proposals are presented for high and low end mobile devices, using Java 2 Platform, Micro Edition (J2ME) Web services API (WSA) and short messaging service (SMS) respectively, which define a specific architecture for each case.},
keywords={Service oriented architecture;Web services;Computer architecture;Application software;Web and internet services;Distributed computing;Software standards;Memory management;Proposals;Java},
doi={10.1109/LAWEB.2005.9},
ISSN={},
month={Oct},}
@INPROCEEDINGS{4606668,
author={Caballé, Santi},
booktitle={2008 International Conference on Complex, Intelligent and Software Intensive Systems},
title={Combining Generic Programming and Service-Oriented Architectures for the Effective and Timely Development of Complex e-Learning Systems},
year={2008},
volume={},
number={},
pages={94-100},
abstract={Over the last years, e-Learning needs have been evolving accordingly with more and more demanding pedagogical and technological requirements. On-line learning environments no longer depend on homogeneous groups, static content and resources, and single pedagogies, but high customization and flexibility are a must in this context. As a result, current educational organizations’ needs involve extending and moving to highly customized learning and teaching forms in timely fashion, each incorporating its own pedagogical approach, each targeting a specific learning goal, and each incorporating its specific resources. Moreover, organizations’ demands include a cost-effective integration of legacy and separated learning systems, from different institutions, departments and courses, which are implemented in different languages, supported by heterogeneous platforms and distributed everywhere, to name some of them. Therefore, e-Learning applications need to be developed in a way that  overcome these demanding requirements as well as provide educational organizations with fast,  flexible and effective solutions for the enhancement and improvement of the learning performance and outcomes. To this end, in this paper, an innovative engineering software technique is introduced that combines the Generic Programming paradigm and Service-Oriented Architectures in the form of Web-services for the effective and timely construction of flexible, scalable, interoperable and robust applications as key aspects to address the current demanding and changing requirements in software development in general and specifically in the e-Learning domain. This results in a generic, reusable, extensible platform called Collaborative Learning Purpose Library for the systematic development of collaborative learning applications that help meet these demanding  requirements.},
keywords={Software;Collaborative work;Service oriented architecture;Programming;Collaboration;Organizations;Computer architecture},
doi={10.1109/CISIS.2008.99},
ISSN={},
month={March},}
@ARTICLE{7997602,
author={Ghorbanian, Vahid and Salimi, Armin and Lowther, David Alister},
journal={IEEE Transactions on Industrial Electronics},
title={A Computer-Aided Design Process for Optimizing the Size of Inverter-Fed Permanent Magnet Motors},
year={2018},
volume={65},
number={2},
pages={1819-1827},
abstract={A process for designing an inverter-fed motor while taking into account the performance of the inverter is proposed. To draw a comparison, the classical approach to machine sizing is discussed and its shortcomings in achieving a more optimal solution to the motor-drive system design problem are pointed out. The results prove that designing the motor as an independent system may give less optimal solutions compared to the case where an integrated system is considered. Therefore, the machines and the inverters should be designed simultaneously. An inverter-fed interior permanent magnet motor is investigated, and the corresponding design guidelines are presented. These guidelines are based on the knowledge extracted from an inclusively modeled, sampled, and simulated design space. The reliability of the design, the inverter efficiency, and the priorities of the transient, rated and flux weakening operations are assigned as the selection criteria. Moreover, various user-package interfaces are proposed to show how the designer should be guided towards a more realistic design choice. Finally, four different design cases are presented and compared to the output of the classical machine sizing process. The proposed approach serves as a proposal for the next generation of processes implemented with the aid of a high-performance cloud-computing service.},
keywords={Permanent magnet motors;Inverters;Magnetic flux;Stator windings;Loading;Torque;Demagnetization;design process;electrical machines;finite element analysis (FEA);high-performance computing;inverter;optimization;user-software interaction},
doi={10.1109/TIE.2017.2733460},
ISSN={1557-9948},
month={Feb},}
@INPROCEEDINGS{4617273,
author={Sun, Lei and Nakajima, Tatsuo},
booktitle={2008 14th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications},
title={A Lightweight Kernel Objects Monitoring Infrastructure for Embedded Systems},
year={2008},
volume={},
number={},
pages={55-60},
abstract={In this paper, a lightweight system level monitoring infrastructure known as kernel objects monitoring infrastructure (KOMI) is presented for commercial-off-the-shelf (COTS) embedded systems. The kernel objects consist of certain critical kernel data structures and entry points of system calls, which are protected as first-class objects inside the system. KOMI provides specific runtime protections to different kernel objects: kernel data structures are protected by the periodic detection and recovery, the interception of arguments is used to protect vulnerable system calls. Both protection methods can provide not only consistency regulations but also recovery actions for the system. During its runtime deployment, once any system inconsistency has been detected, predefined recovery actions will be invoked. Since KOMI requires few modifications to kernel source code, it is easy to integrate into existing embedded systems. The evaluation experiment results indicate our prototype system can correctly detect the inconsistent kernel data structures caused by security attacks and also prevent kernel from exploits due to vulnerable system calls with acceptable penalty to the system performance. Moreover, KOMI is fully software-based without introducing any specific hardware and requires no modifications to system call APIs, therefore legacy applications can be also easily reused.},
keywords={Kernel;Monitoring;Data structures;Linux;Embedded system;Runtime;Security;security;monitor;recovery;reliability},
doi={10.1109/RTCSA.2008.16},
ISSN={2325-1301},
month={Aug},}
@INPROCEEDINGS{1316682,
author={Wagner, F. and Wagner, T. and Wolstenholme, P.},
booktitle={Proceedings. 11th IEEE International Conference and Workshop on the Engineering of Computer-Based Systems, 2004.},
title={Closing the gap between software modelling and code},
year={2004},
volume={},
number={},
pages={52-59},
abstract={If a software implementation is to be generated fully automatically from a model, then the model must be detailed and totally complete. For the definition of software implementing system behaviour, through finite state machines, we propose a well-proven method for the creation of such models and an associated XML expression of them.},
keywords={Unified modeling language;Software systems;Software standards;Programming;Application software;Automata;Computer architecture;Embedded software;Embedded system;Software libraries},
doi={10.1109/ECBS.2004.1316682},
ISSN={},
month={May},}
@INPROCEEDINGS{689474,
author={Kropp, N.P. and Koopman, P.J. and Siewiorek, D.P.},
booktitle={Digest of Papers. Twenty-Eighth Annual International Symposium on Fault-Tolerant Computing (Cat. No.98CB36224)},
title={Automated robustness testing of off-the-shelf software components},
year={1998},
volume={},
number={},
pages={230-239},
abstract={Mission-critical system designers may have to use a commercial off-the-shelf (COTS) approach to reduce costs and shorten development time, even though COTS software components may not specifically be designed for robust operation. Automated testing can assess component robustness without sacrificing the advantages of a COTS approach. This paper describes the Ballista methodology for scalable, portable, automated robustness testing of component interfaces. An object-oriented approach based on parameter data types rather than component functionality essentially eliminates the need for function-specific test scaffolding. A full-scale implementation that automatically tests the robustness of 233 operating system software components has been ported to ten POSIX systems. Between 42% and 63% of components tested had robustness problems, with a normalized failure rate ranging from 10% to 23% of tests conducted. Robustness testing could be used by developers to measure and improve robustness, or by consumers to compare the robustness of competing COTS component libraries.},
keywords={Robustness;Automatic testing;Software testing;Vehicle crash testing;Mission critical systems;Costs;Computer crashes;Application software;Design engineering;Systems engineering and theory},
doi={10.1109/FTCS.1998.689474},
ISSN={0731-3071},
month={June},}
@INPROCEEDINGS{7407087,
author={Hsieh, Fu-Shiung},
booktitle={2015 Conference on Technologies and Applications of Artificial Intelligence (TAAI)},
title={Location-aware workflow scheduling in supply chains based on multi-agent systems},
year={2015},
volume={},
number={},
pages={441-448},
abstract={In construction industry, companies form a supply chain to respond to business opportunities. The complex workflows, dependency between partners and their location pose a big challenge in construction project management. How to schedule activities to meet the construction project requirements under resource constraints is an important issue. To create a feasible schedule for a construction project, companies in a typical construction supply chain need to negotiate with each other. Development of an effective software system to support negotiation and collaboration between the partners in a construction supply chain is urgent. Execution of workflows in a construction project usually depends on location. Although workflow management problems have been extensively studied for decades, location information of workflows is rarely taken into account in existing literature. In this paper, we will study the development of a location-aware workflow scheduling system for construction supply chains. We will propose a flexible scheduling system to optimize the construction project schedule based on collaboration of entities/partners in a construction supply chain. We propose a methodology that includes modeling of location-aware workflows in construction projects based on formal workflow models and develop a technique to transform workflow models to formulate and solve a project scheduling problem. We propose architecture to implement a location-aware multi-agent scheduling system based on JADE and Google API. The proposed methodology is verified by an example.},
keywords={Computational modeling;Distributed computing;Computer architecture;Optimization;supply chain;scheduling;workflow;location aware;multi-agent},
doi={10.1109/TAAI.2015.7407087},
ISSN={2376-6824},
month={Nov},}
@ARTICLE{9891727,
author={de Souza, Koffi V. C. K. and Bouslimani, Yassine and Ghribi, Mohsen},
journal={IEEE Journal on Miniaturization for Air and Space Systems},
title={Flight Software Development for a CubeSat Application},
year={2022},
volume={3},
number={4},
pages={184-196},
abstract={This article presents a development of a CubeSat mission software running on an STM32-based on-board computer (OBC). This was conducted under the Canadian CubeSat Project, initiated by the Canadian Space Agency in 2018 to support the development of 15 CubeSats across Canada. The proposed mission software has a multilayered architecture and is divided into five layers from a low layer dedicated to the peripherals to the top layer dedicated to the Mission Applications. The CubeSat protocol (CSP) is used at the communication layer for easing connectivity between subsystems and to communicate with the ground segment. The mission software running on the OBC is built to meet many requirements defined for this satellite, such as version control, classifications, margins, etc. The CubeSat will be able to accomplish two scientific missions related to the study of space weather once the satellite is put into orbit from the International Space Station. An overview of the software running on the OBC is presented, written in C Language, and includes the implementation of the CSP. FreeRTOS used as an operating system for the OBC is also presented. A Command Line Interface was designed for testing purposes to ensure software efficiency and some results are discussed in this article. The flight software consists of three main tasks and subtasks. Of the 1024 kB of flash memory, only 240 kB was used which represents less than 20% of the total memory. The CPU load is 34% for normal, manual, and maintenance modes and 16% for failure modes.},
keywords={Software;CubeSat;Small satellites;Satellite broadcasting;Hardware;Space vehicles;Operating systems;Nanotechnology;Software packages;CAN bus communications;CubeSat;CubeSat protocol (CSP);FlatSat;flight software;nanosatellite},
doi={10.1109/JMASS.2022.3206713},
ISSN={2576-3164},
month={Dec},}
@INPROCEEDINGS{4783884,
author={Chou, Ya-Yuen and Lin, Chih-Jen and Yu, Chao-Kai and Chiu, Hsien-Sen},
booktitle={2008 3rd International Microsystems, Packaging, Assembly & Circuits Technology Conference},
title={CAE Analysis for Molding Design of Microchip Encapsulation},
year={2008},
volume={},
number={},
pages={352-355},
abstract={Semiconductor industry is one of the most important industries in Taiwan for more than one decade. The development of microchip product is complicated due to the complexity of material properties while processing. During fabrication, various problems such as wire sweep and paddle shift causing defects will happen. Traditionally, people would get rid of those problems by means of "trial-and-error". However, it is not so easy and effective. Recently, using CAE technology in the development of microchip encapsulation process is becoming more and more popular. CAE technology provides a more scientific way to help people solving the problems and enhance the development. In this paper, the true 3D CAE software, Moldex3D, is adopted to evaluate the design of microchip encapsulation. As an integrated technology to connect pre-process, filling and curing analyses, structure analysis and post-process, it gives a comprehensive solution for microchip encapsulation. The results of wire sweep and paddle shift analyses can provide good guideline for the microchip encapsulation development. By using this integrated CAE technology, the physical phenomenon for different molding design of microchip encapsulation can be easily obtained and therefore the most desired design will be found painlessly.},
keywords={Computer aided engineering;Encapsulation;Wire;Filling;Curing;Resins;Material properties;Fabrication;Guidelines;Equations},
doi={10.1109/IMPACT.2008.4783884},
ISSN={2150-5942},
month={Oct},}
@INPROCEEDINGS{8533525,
author={DECHELOTTE, Jonathan and TESSIER, Russell and DALLET, Dominique and CRENNE, Jeremie},
booktitle={2018 28th International Conference on Field Programmable Logic and Applications (FPL)},
title={Lynq: A Lightweight Software Layer for Rapid SoC FPGA Prototyping},
year={2018},
volume={},
number={},
pages={372-3723},
abstract={Modern FPGAs include a diverse collection of heterogeneous processing elements including microprocessors. However, in many cases, specialized knowledge is required to integrate processing elements, IP hardware cores, memory interfaces and interconnects together. Xilinx recently released PYNQ, an open-source framework to enable interactive testing, rapid design iteration, and fast prototyping on SoC FPGAs. In this paper we present Lynq, Lua for Lynq, a lightweight software layer for rapid SoC FPGA prototyping on Xilinx Zynq devices. We evaluate the performance and energy efficiency of the new software and assess hardware integration efficiency versus competing approaches. It is shown that we outperform Python implementations with PYNQ even when a JITed version of Python is available. Run-time speedups between 3.2× and 4.9× are shown with an energy improvement of 2.5× to 4.8× versus PYNQ. System bootup is achieved in less than 10 ms which fits time-critical application requirements.},
keywords={Python;Field programmable gate arrays;Hardware;Libraries;Kernel;Computer architecture;SoC FPGA;Rapid Prototyping;Zynq;JIT;Lua;PYNQ;Lynq},
doi={10.1109/FPL.2018.00070},
ISSN={1946-1488},
month={Aug},}
@INPROCEEDINGS{10009317,
author={Merdan, Ali and Aslan, Heba and Abdelbaki, Nashwa},
booktitle={2022 20th International Conference on Language Engineering (ESOLEC)},
title={Design and Implementation of a Dockerized, Cross Platform, Multi-Purpose Cryptography as a Service Framework Featuring Scalability, Extendibility and Ease of Integration},
year={2022},
volume={20},
number={},
pages={152-157},
abstract={Following cybersecurity standards nowadays is becoming one of the highest priorities to the digital specialists. Due to the global direction to apply digital transformation, data security is a concern. It becomes crucial to ensure data confidentiality, integrity, and availability whether while transmitting, at rest or even while processing it. The difficulty being faced by organizations, is the challenge of applying the needed security measures. Also, implementing, and maintaining the cryptographic algorithms that ensure the wellness of the data encryption. Having a crypto library or a server that can fit multiple use-cases is either too costly to implement, or expensive to buy (including licensing options, per user/server/year…etc.). The goal of our work is to identify the data protection challenges, by implementing a solution that could match a theoretical hypothesis of having cryptography as a service framework. The term “as a service” has been promoted lately due to its capabilities to provide a ready-made solution by the vendors to satisfy their customer base. In this paper, we are proposing a framework that works cross-platform with ease. It is a scalable, extendible solution with multiple hosting options, from an on-premises hosting to cloud hosting. The proposed framework is implemented and evaluated. The results show that the proposed framework can efficiently process enormous amounts of data. In addition, it could be easily accessed by standard HTTPS requests using JSON format. Also, proving the used deployment technique, we were able to evaluate it on-premises and on cloud with the same allocated resources, getting matching results.},
keywords={Scalability;Digital transformation;Standards organizations;Data protection;Organizations;Licenses;Libraries;Computer Security;Cryptography;Encryption;Software as a Service;Cloud Computing;Software Development},
doi={10.1109/ESOLEC54569.2022.10009317},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9936167,
author={Yingju, Zhao},
booktitle={2022 International Conference on Edge Computing and Applications (ICECAA)},
title={The Decentralized Structure of the Digital Cultural Network Affects the Research on Education Informatization},
year={2022},
volume={},
number={},
pages={359-362},
abstract={Under the trend of "decentralization", the authoritarian environment of online ideological and political education has been broken, and the actual effect of education is difficult to achieve; the generation and dissemination of educational content is facing the crisis of "mainstream decentralization"; the identity of the subject and object of education has changed, seeking dialogue and interaction. Logical Analysis The method explores the direction of the informatization reform of higher vocational physical education classrooms mainly in three aspects: teaching mode, teaching method, and evaluation method. The ideological workers in colleges and universities are in an embarrassing situation. It is pointed out that the obstacles to the informatization of physical education classrooms in higher vocational colleges mainly include the construction of software and hardware facilities.},
keywords={Technological innovation;Education;Market research;Software;Libraries;Hardware;Internet;Decentralized Structure;Digital Cultural Network;Education Informatization},
doi={10.1109/ICECAA55415.2022.9936167},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6743786,
author={Dore, C. and Murphy, M.},
booktitle={2013 Digital Heritage International Congress (DigitalHeritage)},
title={Semi-automatic techniques for as-built BIM façade modeling of historic buildings},
year={2013},
volume={1},
number={},
pages={473-480},
abstract={This paper presents two new developments for asbuilt BIM modeling of historical buildings. The first is a new library of interactive parametric objects designed for modeling classical architectural elements from survey data. These library objects are dynamic and have parameters that can alter the shape and size of objects for multiple uses and not just once off static modeling. The parametric architectural objects have been designed from historic manuscripts and architectural pattern books. These parametric objects were built using an embedded programming language within the ArchiCAD BIM software called Geometric Description Language (GDL). The second development which is described in more detail in this paper is a parametric building façade which has been developed as a template for fast and efficient modeling of endless configurations of building façades. The design of this parametric façade incorporates concepts from procedural modeling which is an automated approach to generating 3D geometries based on rules and algorithms. With this developed parametric façade, the structure of a façade can be automatically generated by altering parameters for the number of stories, number or horizontal tiles and door position. When automatically generating a façade, the initial position and size of elements are estimated using classical architectural proportions. After the façade is automatically generated users can then interactively edit the position, size and other parameters of façade elements to accurately map objects to survey data. Parametric library objects such as windows, ashlar block wall detail and other architectural elements are incorporated into the parametric façade. The parametric façade template has also been implemented with the Geometric Description Language for ArchiCAD BIM software. This enables the tools developed to utilize the full benefits of BIM software which includes automated construction or conservation documents, semantic object orientated objects based on IFC semantic classes, automatic lists of objects and material and the ability to add and link additional information to the model. Initial tests have shown that the parametric façade is more efficient than existing manual BIM methods for creating façade models from survey data. The façade template also provides an easier solution for generating façade models when compared to existing methods. Non-specialist users with little experience in 3D modeling can easily generate and modify the façade template by altering parameters graphically or from a dialogue box.},
keywords={Shape;Buildings;Libraries;Software;Grammar;Three-dimensional displays;Data models;As-Built BIM;Laser Scanning;Photogrammetry;Historic Building Information Modeling;Parametric Modeling;Procedural Modeling;Architectural Modeling;Cultural Heritage},
doi={10.1109/DigitalHeritage.2013.6743786},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9911314,
author={Benetti, Elisa and Zucchelli, Andrea and Mazzini, Gianluca},
booktitle={2022 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)},
title={Design and Implementation of a Software Vulnerabilities and Application Research Tool},
year={2022},
volume={},
number={},
pages={1-5},
abstract={In a distributed environment that includes a large number of virtual machines managed by a single entity, maintaining an up-to-date inventory of the same is essential for several reasons. First of all, cybersecurity is an element of increasing importance that must necessarily be taken into consideration: in the event of a vulnerability, knowing quickly which virtual machines are affected in order to proceed with the fix minimizes problem resolution times and therefore the probability of attacks. Furthermore, knowing instantly which virtual machines contain certain versions of packages helps in identifying the best host on which to develop new projects according to specific needs. This paper proposes a possible solution already in use in a company that manages a considerable amount of servers and projects of decidedly heterogeneous types developed on them.},
keywords={Companies;Virtual machining;Software;Computer networks;Telecommunications;Servers;Computer security},
doi={10.23919/SoftCOM55329.2022.9911314},
ISSN={1847-358X},
month={Sep.},}
@INPROCEEDINGS{7889776,
author={Chen, Xi and Jiao, Jian},
booktitle={2017 Annual Reliability and Maintainability Symposium (RAMS)},
title={A fault propagation modeling method based on a finite state machine},
year={2017},
volume={},
number={},
pages={1-7},
abstract={With the development of technology and the expansion of application in different areas, the function and structure of engineering systems becomes more and more complex, which brings increasingly strict requirements for system reliability and safety. System failure is one of the primary reasons for accidents, thus it is of primary importance to investigate the fault propagation process and to establish the fault propagation model, which provides a basis for reducing accident risk. However, there are complex interactive relationships existing among the components as well as between the external environment and the system, so it is difficult to get a satisfactory result through a traditional safety analysis method. The model based safety analysis (MBSA) is able to solve the problem of poor expression ability and the low description precision of traditional analysis methods, so as to improve the efficiency and objectivity of safety analysis. The existing MBSA method, however, still has deficiencies in fault and/or failure modeling, lacking an abundant fault model library. Based on the study of fault propagation process and the research of traditional modeling methods, this paper decomposes the system into subsystems through the analysis of local fault effects based on Failure Modes and Effects Analysis (FMEA), proposing fault propagation modes according to the interaction between components. Subsequently, combined with Finite State Machine (FSM) theory, this paper describes the interactive behaviors between the components, constructing the transition process of fault propagation through the extraction of the state, input, output and state function of the component, abstracting out the system interactive model. This aims at enriching the MBSA fault model library while describing the fault propagation process within the entire system in a more detailed way. Finally, a case study is provided using Stateflow, software based on FSM theory, to verify the effectiveness and feasibility of this approach.},
keywords={Automata;Safety;Analytical models;Mathematical model;Accidents;Libraries;Software packages;fault propagation;model;finite state machine;stateflow;simulation},
doi={10.1109/RAM.2017.7889776},
ISSN={},
month={Jan},}
@INPROCEEDINGS{5705008,
author={Gohari, Mojtaba and Mortaza, Niyousha},
booktitle={2010 17th Iranian Conference of Biomedical Engineering (ICBME)},
title={Designing and fabrication of a Postural Stabilometer: A static platform},
year={2010},
volume={},
number={},
pages={1-4},
abstract={In this paper, designing and fabrication of a static Postural Stabilometer is described. The hardware and software implementation of the instrument is briefly reported. Sensors, hardware circuit, filter and A/D converter is presented in hardware section. Forces estimation, center of pressure (COP) position and sway index is stated in software section. Finally, the overall instrument is tested on several healthy subjects and their reports are presented in detail.},
keywords={Modulation;Diseases;Electronics packaging;Particle measurements;Atmospheric measurements;Software;Hardware;component;postural stabilometer;hardware;software},
doi={10.1109/ICBME.2010.5705008},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9385238,
author={Sokolovskyy, Yaroslav and Nechepurenko, Andriy and Herasymchuk, Olha and Mokrytska, Olha and Samotii, Tetiana},
booktitle={2021 IEEE 16th International Conference on the Experience of Designing and Application of CAD Systems (CADSM)},
title={Software and Algorithmic Aspects of Automating Finite-element Discretization},
year={2021},
volume={},
number={},
pages={28-33},
abstract={A software package has been developed for automating finite-element discretization of two-dimensional and three-dimensional areas in the C # programming language in the Microsoft Visual Studio environment (.NET Framework). Within the framework of the object-oriented approach, the information model of the system is presented in the form of designed graphical UML diagrams of use cases, classes and relationships between them. The created graphical user interface allows you to set the discretization parameters for two-dimensional and three-dimensional areas and control changes in the geometric dimensions of the discretes for the purpose of grid condensation in the specified areas of the region. The developed classes reflect the essence of object-oriented implementation of iterative methods of triangulation based on the Delaunay criterion. This makes it possible to integrate the developed software into existing CAE / CAD / CAM systems in order to expand their functionality.},
keywords={Visualization;Solid modeling;Unified modeling language;Software algorithms;Software systems;Finite element analysis;Iterative methods;triangulation;Delaunay criterion;iterative method;finite element method;object-oriented design},
doi={10.1109/CADSM52681.2021.9385238},
ISSN={2572-7591},
month={Feb},}
@ARTICLE{9208715,
author={Gao, Honghao and Qin, Xi and Barroso, Ramón J. Durán and Hussain, Walayat and Xu, Yueshen and Yin, Yuyu},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
title={Collaborative Learning-Based Industrial IoT API Recommendation for Software-Defined Devices: The Implicit Knowledge Discovery Perspective},
year={2022},
volume={6},
number={1},
pages={66-76},
abstract={The industrial Internet of things (IIoT), a new computing mode in Industry 4.0, is deployed to connect IoT devices and use communication technology to respond to control commands and handle industrial data. IIoT is typically employed to improve the efficiency of computing and sensing and can be used in many scenarios, such as intelligent manufacturing and video surveillance. To build an IIoT system, we need a collection of software to manage and monitor each system component when there are large-scale devices. Application programming interface (API) is an effective way to invoke public services provided by different platforms. Developers can invoke different APIs to operate IoT devices without knowing the implementation process. We can design a workflow to configure how and when to invoke target APIs. Thus, APIs are a powerful tool for rapidly developing industrial systems. However, the increasing number of APIs exacerbates the problem of finding suitable APIs. Current related recommendation methods have defects. For example, most existing methods focus on the relation between users and APIs but neglect the valuable relations among the users or APIs themselves. To address these problems, this article studies implicit knowledge in IIoT by using collaborative learning techniques. Considering the increased dimensions and dynamics of IoT devices, we explore the possible relationships between users and between APIs. We enhance the matrix factorization (MF) model with the mined implicit knowledge that are implicit relationships on both sides. We build an ensemble model by using all implicit knowledge. We conduct experiments on a collected real-world dataset and simulate industrial system scenarios. The experimental results verify the effectiveness and superiority of the proposed models.},
keywords={Computational modeling;Mashups;Prediction algorithms;Internet of Things;Collaboration;Collaborative work;API recommendation;collaborative learning;implicit relationship mining;industrial internet of things;matrix factorization},
doi={10.1109/TETCI.2020.3023155},
ISSN={2471-285X},
month={Feb},}
@INPROCEEDINGS{8436656,
author={Kodama, Satoshi and Nakagawa, Rei},
booktitle={2018 Tenth International Conference on Ubiquitous and Future Networks (ICUFN)},
title={Integration of Multiple IP Domains in Low-Cost and Security-Oriented Small Networks},
year={2018},
volume={},
number={},
pages={110-113},
abstract={This paper has two main aims. The first is to reduce hardware management-related issues when working with complex networks, such as a lack of flexibility and scalability with regard to global configuration changes. The second is to create a communication library that provides programmable network function virtualization, helping to achieve the first aim. Specifically, we target low-cost, security-oriented networks that use broadband routers as L3 switches. When such networks have multiple IP domains between the external gateway and internal networks, domains that are lower in the hierarchy become more secure, but at the cost of flexibility. Our proposed system architecture aims to increase communication flexibility in such networks without requiring complex encapsulation and achieves this goal via a practical method that does not change the packet size. Finally, we conduct tests using an experimental implementation of the system, demonstrating its scalability.},
keywords={Scalability;Systems architecture;Logic gates;Libraries;Network function virtualization;System software;IP networks;Software Defined Network;Private Network;Network Management System},
doi={10.1109/ICUFN.2018.8436656},
ISSN={2165-8536},
month={July},}
@ARTICLE{6259853,
author={Sánchez-Solano, Santiago and Brox, María and del Toro, Ernesto and Brox, Piedad and Baturone, Iluminada},
journal={IEEE Transactions on Industrial Informatics},
title={Model-Based Design Methodology for Rapid Development of Fuzzy Controllers on FPGAs},
year={2013},
volume={9},
number={3},
pages={1361-1370},
abstract={The complexity reached by current applications of industrial control systems has motivated the development of new computational paradigms, as well as the employment of hybrid implementation techniques that combine hardware and software components to fulfill system requirements. On the other hand, continuous improvements in field-programmable devices today make possible the implementation of complex control systems on reconfigurable hardware, although they are limited by the lack of specific design tools and methodologies to facilitate the development of new products. This paper describes a model-based design approach for the synthesis of embedded fuzzy controllers on field-programmable gate arrays (FPGAs). Its main contributions are the proposal of a novel implementation technique, which allows accelerating the exploration of the design space of fuzzy inference modules, and the use of a design flow that eases their integration into complex control systems and the joint development of hardware and software components. This design flow is supported by specific tools for fuzzy systems development and standard FPGA synthesis and implementation tools, which use the modeling and simulation facilities provided by the Matlab environment. The development of a complex control system for parking an autonomous vehicle demonstrates the capabilities of the proposed procedure to dramatically speed up the stages of description, synthesis, and functional verification of embedded fuzzy controllers for industrial applications.},
keywords={Field programmable gate arrays;Mathematical model;Hardware;Fuzzy systems;MATLAB;Libraries;Fuzzy controllers;hardware/software codesign;industrial control systems;model-based design},
doi={10.1109/TII.2012.2211608},
ISSN={1941-0050},
month={Aug},}
@INPROCEEDINGS{6669909,
author={Jamro, Marcin and Trybus, Bartosz},
booktitle={2013 18th International Conference on Methods & Models in Automation & Robotics (MMAR)},
title={An approach to SysML modeling of IEC 61131-3 control software},
year={2013},
volume={},
number={},
pages={217-222},
abstract={Designing, developing, and maintaining control software is often a complex and difficult task, especially in larger projects. The paper presents a concept of applying the Model-Driven Development approach with SysML modeling to the IEC 61131-3 development process. Four types of diagrams are used to model different aspects of the system: Requirements Diagram, Package Diagram, Block Definition Diagram, and State Machine Diagram. The models represent POUs and their requirements, resources, and tasks. Some POUs can be modeled as state machines as well. The SysML diagrams can be used to generate code templates for the implementation in IEC 61131-3 languages, such as ST or FBD. The paper also describes an extension to the CPDev engineering environment, which integrates the proposed SysML modeling with programming and execution of IEC 61131-3 software. The example of an engine and pump control system is presented to show various stages of the proposed approach.},
keywords={IEC standards;Unified modeling language;Software;Object oriented modeling;Engines;Control systems;Data structures},
doi={10.1109/MMAR.2013.6669909},
ISSN={},
month={Aug},}
@ARTICLE{469458,
author={Aagaard, M. and Leeser, M.},
journal={IEEE Transactions on Software Engineering},
title={Verifying a logic-synthesis algorithm and implementation: a case study in software verification},
year={1995},
volume={21},
number={10},
pages={822-833},
abstract={We describe the verification of a logic synthesis tool with the Nuprl proof development system. The logic synthesis tool, Pbs, implements the weak division algorithm. Pbs consists of approximately 1000 lines of code implemented in a functional subset of Standard ML. It is a proven and usable implementation and is an integral part of the Bedroc high level synthesis system. The program was verified by embedding the subset of Standard ML in Nuprl and then verifying the correctness of the implementation of Pbs in the Nuprl logic. The proof required approximately 500 theorems. In the process of verifying Pbs we developed a consistent approach for using a proof development system to reason about functional programs. The approach hides implementation details and uses higher order theorems to structure proofs and aid in abstract reasoning. Our approach is quite general, should be applicable to any higher order proof system, and can aid in the future verification of large software implementations.<>},
keywords={Software algorithms;Computer aided software engineering;Logic;Hardware;Equations;Circuit synthesis;Software tools;Code standards;High level synthesis;Software libraries},
doi={10.1109/32.469458},
ISSN={1939-3520},
month={Oct},}
@INPROCEEDINGS{1245125,
author={Gorodetsky, V. and Karsaeyv, O. and Samoilov, V.},
booktitle={IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change (IEEE Cat. No.03CH37502)},
title={Software tool for agent-based distributed data mining},
year={2003},
volume={},
number={},
pages={710-715},
abstract={We describe multi-agent technology and software tool for the joint engineering, implementation, deployment and possibly use of applied multi-agent distributed data mining and distributed decision making systems. The core problem of distributed data mining and decision making technology does not concerns particular data mining techniques, because the respective library of classes can be extended when necessary. Instead of this, its core problem is development of an infrastructure and protocols supporting coherent collaborative work of distributed software components (agents) responsible for data mining and decision making. We focus on architecture of multiagent distributed data mining and decision making system, on its design technology, software tool and on the protocols of software tool agents' interaction, mainly, in distributed data mining and decision making processes. The presented software tool is implemented and validated on the basis of several case studies from data fusion scope.},
keywords={Software tools;Data mining;Decision making;Protocols;Data engineering;Distributed decision making;Software libraries;Collaborative work;Collaborative software;Computer architecture},
doi={10.1109/KIMAS.2003.1245125},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9590859,
author={Scarpitta, Carmine and Ventre, Pier Luigi and Lombardo, Francesco and Salsano, Stefano and Blefari-Melazzi, Nicola},
booktitle={2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)},
title={EveryWAn- An Open Source SD-WAN solution},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Software Defined Wide Area Network (SD-WAN) was originally proposed as an alternative solution to redesign the architecture of the WAN. Like its technology precursor Software Defined Networking, SD-WAN was aiming at simplifying the management and operation of the networks (with a particular focus on WAN scenarios) by decoupling the networking hardware from its control programs and using software and open APIs to abstract the infrastructure and manage the connectivity and the services. The SD-WAN architecture leverages SDN principles to securely build interconnections between users and the applications hosted in the clouds or in remote branches, by leveraging any combination of transport services With this paper we shed some light on the SD-WAN scenario and describe an open-source implementation which can be taken as reference. We call this architecture EveryWAn.It has been designed with SDN and NFV principles in mind, and leverages Cloud best practices to deliver to the WAN customers and the MSP the same benefits and the agility of the Cloud service providers. Moreover, we strongly believe in the openness of the SDN/NFV paradigms which can ease the development of new services and can foster the innovation in the SD-WAN deployments.},
keywords={Wide area networks;Technological innovation;Mechatronics;Computer architecture;Hardware;Service-oriented architecture;Software defined networking;SDN Software Defined Networking;WAN Wide Area Networks;SD-WAN Software Defined WAN},
doi={10.1109/ICECCME52200.2021.9590859},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8060361,
author={Zuo, Wei and Pouchet, Louis-Noel and Ayupov, Andrey and Kim, Taemin and Chung-Wei Lin and Shiraishi, Shinichi and Chen, Deming},
booktitle={2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC)},
title={Accurate high-level modeling and automated hardware/software co-design for effective SoC design space exploration},
year={2017},
volume={},
number={},
pages={1-6},
abstract={A desirable feature of a development tool for SoC design is that, given the important applications in the domain to be targeted by the SoC, a powerful hardware-software partitioning engine is available to determine which function(s) shall be mapped to hardware. However, to provide high-quality partitioning, this engine must be able to consider a rich design space of possible alternate hardware and software implementations for each program region candidate for hardware acceleration, in turn making the task of finding the optimal mapping very difficult given the number of design points to consider and the need for accurate modeling of latency, power and area. In this work we propose a novel framework to enable hardware acceleration of performance-critical parts of an application, by addressing the problem of hardware/software partitioning under power and area constraints to minimize the overall program latency. Our flow is based on the LLVM compiler, and focuses on building a scalable compile-time partitioning algorithm while considering large sets of alternative hardware and software implementations for a particular region. To this end we develop a hybrid approach based on mixing semi-random selection of hardware design points and an Integer Linear Programming formulation of the mapping decision, along with iterative refinements of the solution. Experimental results demonstrate the capability of our approach to consider complex designs and yet output near-optimal partitioning decision. Our package is named RIP (Randomized ILP-based Partitioning), and is open source to benefit the research community.},
keywords={Hardware;Software;Acceleration;Buildings;Tools;Space exploration;Measurement},
doi={10.1145/3061639.3062195},
ISSN={},
month={June},}
@INPROCEEDINGS{4639367,
author={Fluri, Beat and Giger, Emanuel and Gall, Harald C.},
booktitle={2008 23rd IEEE/ACM International Conference on Automated Software Engineering},
title={Discovering Patterns of Change Types},
year={2008},
volume={},
number={},
pages={463-466},
abstract={The reasons why software is changed are manyfold; new features are added, bugs have to be fixed, or the consistency of coding rules has to be re-established. Since there are many types of of source code changes we want to explore whether they appear frequently together in time and whether they describe specific development activities. We describe a semi-automated approach to discover patterns of such change types using agglomerative hierarchical clustering. We extracted source code changes of one commercial and two open-source software systems and applied the clustering. We found that change type patterns do describe development activities and affect the control flow, the exception flow, or change the API.},
keywords={Software;History;Data mining;Software systems;Encoding;Java;Guidelines},
doi={10.1109/ASE.2008.74},
ISSN={1938-4300},
month={Sep.},}
@INPROCEEDINGS{8743200,
author={Jain, Saksham and Baek, Iljoo and Wang, Shige and Rajkumar, Ragunathan},
booktitle={2019 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)},
title={Fractional GPUs: Software-Based Compute and Memory Bandwidth Reservation for GPUs},
year={2019},
volume={},
number={},
pages={29-41},
abstract={GPUs are increasingly being used in real-time systems, such as autonomous vehicles, due to the vast performance benefits that they offer. As more and more applications use GPUs, more than one application may need to run on the same GPU in parallel. However, real-time systems also require predictable performance from each individual applications which GPUs do not fully support in a multi-tasking environment. Nvidia recently added a new feature in their latest GPU architecture that allows limited resource provisioning. This feature is provided in the form of a closed-source kernel module called the Multi-Process Service (MPS). However, MPS only provides the capability to partition the compute resources of GPU and does not provide any mechanism to avoid inter-application conflicts within the shared memory hierarchy. In our experiments, we find that compute resource partitioning alone is not sufficient for performance isolation. In the worst case, due to interference from co-running GPU tasks, read/write transactions can observe a slowdown of more than 10x. In this paper, we present Fractional GPUs (FGPUs), a software-only mechanism to partition both compute and memory resources of a GPU to allow parallel execution of GPU workloads with performance isolation. As many details of GPU memory hierarchy are not publicly available, we first reverse-engineer the information through various micro-benchmarks. We find that the GPU memory hierarchy is different from that of the CPU, making it well-suited for page coloring. Based on our findings, we were able to partition both the L2 cache and DRAM for multiple Nvidia GPUs. Furthermore, we show that a better strategy exists for partitioning compute resources than the one used by MPS. An FGPU combines both this strategy and memory coloring to provide superior isolation. We compare our FGPU implementation with Nvidia MPS. Compared to MPS, FGPU reduces the average variation in application runtime, in a multi-tenancy environment, from 135% to 9%. To allow multiple applications to use FGPUs seamlessly, we ported Caffe, a popular framework used for machine learning, to use our FGPU API.},
keywords={Graphics processing units;Kernel;Random access memory;Computer architecture;Instruction sets;Hardware;Real-time systems;GPGPU;CUDA;partitioning;page coloring;memory hierarchy;cache structure;Program Co-Run},
doi={10.1109/RTAS.2019.00011},
ISSN={2642-7346},
month={April},}
@INPROCEEDINGS{777429,
author={Hyunok Oh and Soonhoi Ha},
booktitle={Proceedings of the Seventh International Workshop on Hardware/Software Codesign (CODES'99) (IEEE Cat. No.99TH8450)},
title={A hardware-software cosynthesis technique based on heterogeneous multiprocessor scheduling},
year={1999},
volume={},
number={},
pages={183-187},
abstract={In this paper, we propose a fast and simple heuristic for the cosynthesis problem targeting the system-on-chip (SOC) design. The proposed algorithm covers from implementation selection and resource sharing problem in SOC design to PE selection problems in distributed heterogeneous embedded (DHE) system design. The proposed solution also considers multiple design objectives. Through benchmark experimentation, it is proven that the proposed solution produces solutions of equivalent quality to the previously published results in the DHE design. Its execution speed is several orders of magnitude smaller for large examples. We envision that the proposed approach will be one of significant cosynthesis researches in the SOC design. In the DHE design, the proposed approach could be used as an initial solution to a probabilistic algorithm guaranteeing to obtain a better solution.},
keywords={Processor scheduling;Hardware;Engines;System-on-a-chip;Embedded system;Algorithm design and analysis;Space technology;Design methodology;Space exploration;Libraries},
doi={10.1109/HSC.1999.777429},
ISSN={1092-6100},
month={March},}
@INPROCEEDINGS{7784562,
author={Murvay, Pal-Stefan and Matei, Alexandru and Solomon, Cristina and Groza, Bogdan},
booktitle={2016 11th International Conference on Availability, Reliability and Security (ARES)},
title={Development of an AUTOSAR Compliant Cryptographic Library on State-of-the-Art Automotive Grade Controllers},
year={2016},
volume={},
number={},
pages={117-126},
abstract={In the light of the recently reported attacks on intra-vehicle networks, it has become clear that cryptography is vital for assuring the security of in-vehicle communications. The current preoccupation of industry professionals in this direction is proved by the inclusion of a comprehensive cryptographic extension in the recent-most version of the AUTOSAR (AUTomotive Open System ARchitecture) stan-dard. In this work we try to give an answer on how prepared are current state-of-the-art automotive controllers for implementing cryptographic primitives and what is the exact cost of software implementations. We take into account automotive grade controllers that range from some of the most constrained platforms, e.g., from 8051 based tire sensors with 8-bit cores, up to 32-bit Infineon TriCore architectures, as well as devices that lay in between these two. We provide experimental results on several symmetric cryptographic primitives, i.e., block ciphers and hash functions, mainly focusing on the lightest constructions proposed in the literature, e.g., Speck, Katan, Blake, as well as on past or current standards, e.g., AES, SHA2 or SHA3. As expected, the results are sparse, some of the platforms being well prepared, capable to easily handle software implementation or carrying dedicated hardware, while for others no dedicated hardware exists while software implementation of current cryptographic standards cannot be handled, especially with the overhead incurred by the cohesion to the AUTOSAR standard.},
keywords={Cryptography;Random access memory;Automotive engineering;Standards;Microcontrollers;Computer architecture;AUTOSAR;automotive;cryptographic primitives;library},
doi={10.1109/ARES.2016.60},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8530948,
author={Arun Kumar, K A},
booktitle={2018 International CET Conference on Control, Communication, and Computing (IC4)},
title={ARM-FPGA Implementation of a Partially Reconfigurable OFDM-MIMO Phy-Link},
year={2018},
volume={},
number={},
pages={288-292},
abstract={MIMO-OFDM systems are known for high data rate and lower bit error rate (BER) in wireless communication system. These systems helps to yield high data rate and spectral efficiency over multipath and fading channels. OFDM systems use varying modulation schemes and IFFT points based on data rate requirements and number of carriers. Similarly the MIMO system uses an MxM antenna array with M ranging from 2 to M. Based on the channel conditions and environment a particular combination can perform better with maximum throughput and minimum BER. This paper explores a software defined reconfigurable hardware for the realization of MIMO-OFDM systems and a physical layer link implemented in Xilinx FPGA with partial reconfiguration. The phy link involves a QPSK and a QAM modem with 2x2 and 4x4 antenna array. Using Partial reconfiguration technique the user can switch between these two schemes in minimum time without configuring the entire FPGA which will take 2 to 3 minutes based on the application. The same hardware can be used for designing multiple combination of modulation, number of carries and antenna array with partial reconfiguration which helps to maintain same hardware and switching between the schemes.},
keywords={Field programmable gate arrays;MIMO communication;OFDM;Hardware;Software packages;Antenna arrays;Switches;MIMO;OFDM;BER;Partial reconfiguration;Software defined radio;DUC;and DDC},
doi={10.1109/CETIC4.2018.8530948},
ISSN={},
month={July},}
@INPROCEEDINGS{624696,
author={Gall, H. and Jazayeri, R. and Klosch, R. and Trausmuth, G.},
booktitle={Proceedings Twenty-First Annual International Computer Software and Applications Conference (COMPSAC'97)},
title={The architectural style of component programming},
year={1997},
volume={},
number={},
pages={18-25},
abstract={Component programming is a multiparadigm approach to software construction based on highly generic components. Because component programming is concerned with source-code components, it is assumed by many to be a low-level approach to software development that affects only the development of source code libraries. On the contrary, this paper shows that the concepts of component programming go beyond library and source code issues and define a new conceptual attempt to software development with generic components. We show that component programming is an architectural style that supports the building of classes of software architectures in a specific domain. Component programming can be applied in the early stages of software development when architectural issues are to be determined. All the benefits of using an architectural style, therefore, can also be gained by using component programming: it guides the engineer in the problem decomposition towards the design and implementation of a system. The paper presents the architectural style of component programming and the insights we gained about component programming as we tried to define it as an architectural style.},
keywords={Software libraries;Software design;Software architecture;Object oriented modeling;Programming;Buildings;Computer languages;Design engineering;Software standards;Process design},
doi={10.1109/CMPSAC.1997.624696},
ISSN={0730-3157},
month={Aug},}
@ARTICLE{159342,
author={},
journal={IEEE Std 610.12-1990},
title={IEEE Standard Glossary of Software Engineering Terminology},
year={1990},
volume={},
number={},
pages={1-84},
abstract={This IEEE Standards product is part of the family on Software Engineering. This standard identifies terms currently in use in the field of Software Engineering. Standard definitions for those terms are established.},
keywords={Terminology;Software engineering;Standards;glossary;terminology;dictionary;Software engineering;Definitions},
doi={10.1109/IEEESTD.1990.101064},
ISSN={},
month={Dec},}
@ARTICLE{6827966,
author={Zavattoni, Eric and Perez, Luis J. Dominguez and Mitsunari, Shigeo and Sanchez-Ramırez, Ana H. and Teruya, Tadanori and Rodríguez-Henríquez, Francisco},
journal={IEEE Transactions on Computers},
title={Software Implementation of an Attribute-Based Encryption Scheme},
year={2015},
volume={64},
number={5},
pages={1429-1441},
abstract={A ciphertext-policy attribute-based encryption protocol uses bilinear pairings to provide control access mechanisms, where the set of user's attributes is specified by means of a linear secret sharing scheme. In this paper we present the design of a software cryptographic library that achieves record timings for the computation of a 126-bit security level attribute-based encryption scheme. We developed all the required auxiliary building blocks and compared the computational weight that each of them adds to the overall performance of this protocol. In particular, our single pairing and multi-pairing implementations achieve state-of-the-art time performance at the 126-bit security level.},
keywords={Protocols;Elliptic curves;Encryption;Software;Hospitals;Attribute-based-encryption;pairing-based protocols;bilinear pairings;scalar multiplication},
doi={10.1109/TC.2014.2329681},
ISSN={1557-9956},
month={May},}
@INPROCEEDINGS{6140799,
author={Budianto, E. and Alvissalim, M.S. and Hafidh, A. and Wibowo, A. and Jatmiko, W. and Hardian, B. and Mursanto, P. and Muis, A.},
booktitle={2011 International Conference on Advanced Computer Science and Information Systems},
title={Telecommunication networks coverage area expansion in disaster area using autonomous mobile robots: Hardware and software implementation},
year={2011},
volume={},
number={},
pages={113-118},
abstract={Communication network expansion technology using autonomous robot covers three research fields which includes network expansion, network routing, and localization. On this research, we implement an efficient robot formation and network expansion algorithm on a simulator based on Open Dynamics Engine (ODE) library. We extended the robot formation algorithm to handle multiple sources implementation to keep communication linkage between communication towers. We also developed a network routing algorithm and implement the robot formation algorithm on real autonomous robots hardware. The result of simulation shows that our proposed communication network expansion technology is visible to be implemented. Therefore, we designed an autonomous robot meeting the requirement set in the simulation.},
keywords={Routing protocols;Heuristic algorithms;Routing;Mobile robots;Robot kinematics;Communication networks},
doi={10.1109/MHS.2011.6102209},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7155808,
author={Shekanayaki, K. and Chakure, Afrin and Jain, Anita},
booktitle={2015 International Conference on Computing Communication Control and Automation},
title={A Survey of Journey of Cloud and Its Future},
year={2015},
volume={},
number={},
pages={60-64},
abstract={Cloud computing in the past few years has grown from a promising business idea to one of the fastest growing field of the IT industry. Still the IT organization is concern about critical issues (like security, data loss) existing with the implementation of cloud computing, related to security in particular. Consequently issues arise due to client switching to cloud computing. This paper briefs about the role of cloud in IT business enterprise, its woes and its projected solutions. It proposes the use of "Honey-Comb Infrastructure" for flexible, secure and reliable storage supported by parallel computing.},
keywords={Cloud computing;Security;Computational modeling;Computer architecture;Software as a service;Business;Servers;Cloud Computing;DC (Data-centers);Virtualization;TC (Telecommunications Closet);SOA (Service-Oriented Architecture);API (Application Programming Interface);CSP (Cloud Service Provider);SAAS (Software as a Service);PAAS (Platform as a Service);and},
doi={10.1109/ICCUBEA.2015.20},
ISSN={},
month={Feb},}
@INPROCEEDINGS{524804,
author={Cavender, M.E. and Xiaodong Zhang},
booktitle={Proceedings Nineteenth Annual International Computer Software and Applications Conference (COMPSAC'95)},
title={Software support for asynchronous computing across networks},
year={1995},
volume={},
number={},
pages={376-382},
abstract={The paper describes the design and implementation of asynchronous communication library routines for distributed computing across networks of workstations. The new system is based on modifications of the existing PVM message-passing environment. An intensive and comparative study of synchronous, asynchronous and non-blocking communication protocols is addressed in terms of their design, implementation and applications. Experimental performance comparisons of an application program using the three communication protocols on a network of workstations, are also presented. The experimental results show the power of the asynchronous communication library and the effective enhancements of the PVM message-passing environment.},
keywords={Computer networks;Protocols;Asynchronous communication;High performance computing;Software performance;Software libraries;Workstations;Concurrent computing;Debugging;Distributed computing},
doi={10.1109/CMPSAC.1995.524804},
ISSN={0730-3157},
month={Aug},}
@INPROCEEDINGS{5691780,
author={Hongliang Liu and Ronggao Liu},
booktitle={The 2nd International Conference on Information Science and Engineering},
title={Design and construction of GIS-based China Major Natural Disaster Integrated Assessment System},
year={2010},
volume={},
number={},
pages={3607-3610},
abstract={China is one of the counties in the world that suffers the most natural disasters. Geographic Information System (GIS) plays a significant part in different stages of disaster prevention and reduction. However, current systems existing for disaster reduction in various sectors mainly serve for single kind of disaster and usually have their own special data formats for input and analysis that result in low efficiency, digital divide and incompatible among them. Consequently, to build an integrated platform to facilitate disaster reduction and standardize disaster management in national scale is urgent and necessary. This paper describes the design and construction of such a system combing natural disaster models with capacity provided by GIS in a uniform and flexible decision support environment. Especially it presents a mean leveraging ArcGIS technology to build a software system loosely coupled between common GIS component and model bank containing expert knowledge.},
keywords={Object oriented modeling;Geographic Information Systems;Data models;Analytical models;Couplings;Libraries;Computer architecture;GIS;disaster;assessment;risk;models},
doi={10.1109/ICISE.2010.5691780},
ISSN={2160-1291},
month={Dec},}
@INPROCEEDINGS{7422276,
author={Jaafar, Younes and Bouzoubaa, Karim},
booktitle={2015 First International Conference on Arabic Computational Linguistics (ACLing)},
title={Arabic Natural Language Processing from Software Engineering to Complex Pipeline},
year={2015},
volume={},
number={},
pages={29-36},
abstract={Arabic Natural Language Processing (ANLP) has known an important development during the last decade. Nowadays, Several ANLP tools are developed such as morphological analyzers, syntactic parsers, etc. These tools are characterized by their diversity in terms of development languages used, inputs/outputs manipulated, internal and external representations of results, etc. This is mainly due to the lack of models and standards that govern their implementations. This diversity does not favor interoperability between these tools or their reuse in new advanced projects. In this article, we propose APIs and models for three types of tools namely: stemmers, morphological analyzers and syntactic parsers, using SAFAR platform. Our proposal is a step for standardizing all aspects shared by tools of the same type. We review also the issue of interoperability between these tools. Finally, we discuss pipeline processes.},
keywords={Pipelines;Syntactics;Interoperability;Computer architecture;Morphology;Software engineering;ANLP;Software engineering;interoperability;pipelines},
doi={10.1109/ACLing.2015.11},
ISSN={},
month={April},}
@INPROCEEDINGS{7116881,
author={Ibrahim, Khaled Z. and Williams, Samuel W. and Epifanovsky, Evgeny and Krylov, Anna I.},
booktitle={2014 21st International Conference on High Performance Computing (HiPC)},
title={Analysis and tuning of libtensor framework on multicore architectures},
year={2014},
volume={},
number={},
pages={1-10},
abstract={Libtensor is a framework designed to implement the tensor contractions arising form the coupled cluster and equations of motion computational quantum chemistry equations. It has been optimized for symmetry and sparsity to be memory efficient. This allows it to run efficiently on the ubiquitous and cost-effective SMP architectures. Unfortunately, movement of memory controllers on chip has endowed these SMP systems with strong NUMA properties. Moreover, the many core trend in processor architecture demands that the implementation be extremely thread-scalable on node. To date, Libtensor has been generally agnostic of these effects. To that end, in this paper, we explore a number of optimization techniques including a thread-friendly and NUMA-aware memory allocator and garbage collector, tuning the tensor tiling factor, and tuning the scheduling quanta. In the end, our optimizations can improve the performance of contractions implemented in Libtensor by up to 2× on representative Ivy Bridge, Nehalem, and Opteron SMPs.},
keywords={Tensile stress;Instruction sets;Memory management;Chemistry;Libraries;Runtime;Tuning;tensor algebra;parallel programming;quantum chemistry software},
doi={10.1109/HiPC.2014.7116881},
ISSN={1094-7256},
month={Dec},}
@INPROCEEDINGS{8022759,
author={Fujisawa, Kohei and Nunome, Atsushi and Shibayama, Kiyoshi and Hirata, Hiroaki},
booktitle={2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)},
title={A software implementation of speculative memory},
year={2017},
volume={},
number={},
pages={437-443},
abstract={Many techniques for parallelizing a sequentially coded program have been developed and put to practical use, but there are many cases in which program codes cannot be parallelized because it is impossible to assure that their parallel execution does not violate the data dependencies in the program. To parallelize such programs, we have previously proposed speculative memory (SM). With SM, programmers can specify the parallel and speculative execution of threads explicitly in their programs. The SM system manages the memory data that are speculatively read or written by the threads running in parallel. When the system detects inconsistent memory accesses, it recovers the computational state of the program and restarts the execution. If such inconsistencies are not encountered often, we can expect the total execution time of the program to be shorter. In this paper we present a software implementation of SM (SSM). We have developed an SM library by using POSIX threads. In spite of large overheads that are essentially unavoidable in a software implementation, our SSM system can shorten the execution time of a program that compilers cannot parallelize automatically.},
keywords={Instruction sets;Libraries;Hazards;Message systems;Binary search trees;thread-level speculation (TLS);speculative multithreading (SpMT);parallel architecture;multithreaded programming},
doi={10.1109/SNPD.2017.8022759},
ISSN={},
month={June},}
@INPROCEEDINGS{1028221,
author={Dimkoviae, I. and Milovanoviae, D. and Bojkoviae, Z.},
booktitle={2002 14th International Conference on Digital Signal Processing Proceedings. DSP 2002 (Cat. No.02TH8628)},
title={Fast software implementation of MPEG advanced audio encoder},
year={2002},
volume={2},
number={},
pages={839-843 vol.2},
abstract={An optimized software implementation of a high quality MPEG AAC-LC (low complexity) audio encoder is presented in this paper. The standard reference encoder is improved by utilizing several algorithmic optimizations (fast psycho-acoustic model, new tonality estimation, new time domain block switching, optimized quantizer and Huffman coder) and very careful code optimizations for PC CPU architectures with SIMD (single-instruction-multiple-data) instruction set. The psychoacoustic model used the MDCT filterbank for energy estimation and peak detection as a measure of tonality. Block size decision is based on local perceptual entropies as well as LPC analysis of the time signal. Algorithmic optimizations in the quantizer include loop control module modification and optimized Huffman search. Code optimization is based on parallel processing by replacing vector algebra and math junctions with their optimized equivalents with Intel/sup /spl reg// Signal Processing Library (SPL). The implemented codec outperforms consumer MP3 encoders at 30% less bitrate at the same time achieving encoding times several times faster than real-time.},
keywords={Signal processing algorithms;Psychoacoustic models;Software quality;Code standards;Psychology;Filter bank;Energy measurement;Entropy;Linear predictive coding;Signal analysis},
doi={10.1109/ICDSP.2002.1028221},
ISSN={},
month={July},}
@INPROCEEDINGS{9270314,
author={Suñé, Agustín E. Martinez},
booktitle={2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)},
title={Formalization and analysis of quantitative attributes of distributed systems},
year={2020},
volume={},
number={},
pages={210-213},
abstract={While there is not much discussion on the importance of formally describing and analyzing quantitative requirements in the process of software construction; in the paradigm of API-based software systems, it could be vital. Quantitative attributes can be thought of as attributes determining the Quality of Service - QoS provided by a software component published as a service. In this sense, they play a determinant role in classifying software artifacts according to specific needs stated as requirements. In this work, we present a research program consisting of the development of formal languages and tools to characterize and analyze the Quality of Service attributes of software components in the context of distributed systems. More specifically, our main motivational scenario lays on the execution of a service-oriented architecture.},
keywords={Quality of service;Contracts;Software;Tools;Formal languages;Minimization;Software product lines;service oriented computing;distributed systems;quality of service;formal verification;non functional requirements;quantitative attributes;qos ranking;service level agreement},
doi={},
ISSN={2574-1926},
month={Oct},}
@INPROCEEDINGS{7777254,
author={Pop, S. and Bande, V. and Baciu, I. H.},
booktitle={2016 IEEE 22nd International Symposium for Design and Technology in Electronic Packaging (SIITME)},
title={Wireless diagnosis and monitoring system of sensor network from civil structures},
year={2016},
volume={},
number={},
pages={102-105},
abstract={This paper is focused on the development of a wireless device used in diagnosis and monitoring of sensors networks from civil structures like hydro-energetic buildings. Those constructions are monitored with sensors and measurement systems spread over the entire construction's body. The measurement systems are connected through a RS485 network. The entire structure forms a data acquisition system that is usually controlled by a software application that runs on a computer. A daily management activity in hydro-energetic buildings consists in an automatic and a manual data collection. At the physical layer, in real life, the measurement devices and RS485 networks can be affected by a set of malfunctions that are dangerous signal integrity for the safety of a human operator. For that reason a manual measurement device based on wireless technology is useful. The issues of signals integrity of RS485 lines are detected with an electronic device that is connected to the lines. In additional, using communication protocol the data from each sensor can be collected. The panel interface of the human operator is a software application that runs on a smart mobile device that uses Bluetooth communication [2]. In the last years the mobile software applications has been greatly increased in industry [1]. By using a software application and a wireless mobile device a diagnosis and monitoring system is developed which is more safety and has a vast development space [3].},
keywords={Monitoring;Software;Testing;Buildings;Wireless sensor networks;Wireless communication;Bluetooth;wireless;Bluetooth;diagnosis;monitoring},
doi={10.1109/SIITME.2016.7777254},
ISSN={},
month={Oct},}
@ARTICLE{5306930,
author={Brugali, Davide and Scandurra, Patrizia},
journal={IEEE Robotics & Automation Magazine},
title={Component-based robotic engineering (Part I) [Tutorial]},
year={2009},
volume={16},
number={4},
pages={84-96},
abstract={This article is the first of a two-part series intended as an introduction to component-based software engineering (CBSE) in robotics. In this tutorial, we regard a component as a piece of software that implements robotic functionality (e.g., path planning). The focus of this article is on design principles and implementation guidelines that enable the development of reusable and maintainable software-building blocks, which can be assembled to build robotic applications.},
keywords={Tutorials;Application software;Libraries;Software systems;Software engineering;Path planning;Algorithms;Software maintenance;Robotic assembly;Software engineering;reuse;architecture;component},
doi={10.1109/MRA.2009.934837},
ISSN={1558-223X},
month={December},}
@ARTICLE{5273808,
author={Aguayo Gonzalez, Carlos R. and Dietrich, Carl B. and Sayed, Shereef and Volos, Haris I. and Gaeddert, Joseph D. and Robert, P. Max and Reed, Jeffrey H. and Kragh, Frank E.},
journal={IEEE Communications Magazine},
title={Open-source SCA-based core framework and rapid development tools enable software-defined radio education and research},
year={2009},
volume={47},
number={10},
pages={48-55},
abstract={This article describes the Open Source SCA Implementation::Embedded project, an open source software development kit designed for rapid prototyping of software defined radios consistent with the Software Communications Architecture. The SCA is a product of the American military's SDR acquisition program and has played a large role in SDR development in the military and in the wireless industry. OSSIE was designed for use in wireless communications curricula and research efforts, so it is easy to learn and illustrative of software engineering, programming, and communications engineering concepts important in industrial practice today. OSSIE includes a core framework (i.e., common services enumerated in the SCA). It also includes graphical user interface-oriented tools that are easily learned and free to download and use. The tools auto-generate SCA-specific component source code and supporting files, leaving the developer to provide signal processing functionality. In addition, visualization tools for debugging and a growing library of SDR software components are available. Discussed herein are examples of SDRs designed using OSSIE, including embedded applications. OSSIE enables easy transition from concepts to practice in SDR design for communications engineers who may not have a strong software background.},
keywords={Open source software;Defense industry;Design engineering;Educational products;Educational programs;Software design;Software prototyping;Software radio;Computer architecture;Wireless communication},
doi={10.1109/MCOM.2009.5273808},
ISSN={1558-1896},
month={October},}
@INPROCEEDINGS{6830911,
author={Brugali, Davide and Fonseca, Andrea Fernandes da and Luzzana, Andrea and Maccarana, Yamuna},
booktitle={2014 IEEE 8th International Symposium on Service Oriented System Engineering},
title={Developing Service Oriented Robot Control System},
year={2014},
volume={},
number={},
pages={237-242},
abstract={The work presented in this paper is motivated by the aim of simplifying the integration of robotic and information systems technology. This would allow for example to extend the capabilities of autonomous robots with the possibility to access Web resources and services. For this purpose, this paper presents the Task Component Architecture, a framework for the implementation of Service ComponentArchitecture (SCA) components that execute autonomouslytheir service and that can be seamlessly integrated with robotic software control systems.},
keywords={Java;Observers;Libraries;Peer-to-peer computing;Robot kinematics;Robot sensing systems;Robot programming;Software Components},
doi={10.1109/SOSE.2014.28},
ISSN={},
month={April},}
@INPROCEEDINGS{6917463,
author={Chen, Meng and Li, Zhi and Zhang, Guanglie},
booktitle={The 4th Annual IEEE International Conference on Cyber Technology in Automation, Control and Intelligent},
title={A cooperative software-hardware approach for wireless body area network implementation},
year={2014},
volume={},
number={},
pages={214-218},
abstract={This paper proposes a cooperative softwarehardware framework to implement the complexity of application development for wireless body area networks (WBAN). The framework consists of a software WBAN simulator, WBAN hardware platform and code generator for sensor nodes. The proposed framework is convenient for design and verification of WBAN communication protocols and applications efficiently. In this paper, we discuss the cooperative software-hardware platform architecture, which packages the detailed hardware design. So the hardware of the sensor nodes is transparent to users. The paper also presents an application example with an adaptive MAC protocol to illustrate how to implement the proposed cooperative framework.},
keywords={Hardware;Wireless sensor networks;Wireless communication;Operating systems;Generators;Media Access Protocol;WBAN;Wearbale;Computing;Cooperative Simulation Platform},
doi={10.1109/CYBER.2014.6917463},
ISSN={},
month={June},}
@INPROCEEDINGS{10031712,
author={Wang, LuoChao and Lee, Raymond S. T.},
booktitle={2022 20th International Conference on Information Technology Based Higher Education and Training (ITHET)},
title={The Design and Implementation of Quantum Finance Software Development Kit (QFSDK) for AI Education},
year={2022},
volume={},
number={},
pages={1-7},
abstract={For the past several decades, with the rapid development of internet technologies and online transaction platforms, financial institutions and investors are facing huge challenges from the global economic environment that financial markets are becoming more unpredictable and volatile than before, especially in the stock markets, commodity markets and cryptocurrency markets. Interest and awareness of Artificial Intelligence and Quantum Finance are growing so fast that both academia and higher education are struggling to keep up with the accelerating demand of financial markets. Quantum finance is a newly developed interdisciplinary program with the integration of quantum theory, computational finance, and even computer science, which requires students to have comprehensive knowledge reserves. Meanwhile, it is extremely complicated for students to use a programming language to realize quantum finance calculations from scratch. To facilitate curricula teaching, and hands-on usage of quantum finance and AI, a Quantum Finance Software Development Kit (QFSDK) is proposed based on the author’s previous research on Quantum Finance Theory and other AI research findings. The QFSDK was prepared in python programming language as the first step in introducing students to the concepts and applications of quantum finance. The QFSDK bridges the theoretical and practical chasm for learners by developing a quantum finance calculator library. It serves as an open-source template that encourages heavy contextual modification, and it supports any online platforms in the python programming language.},
keywords={Quantum computing;Education;Finance;Quantum mechanics;Weather forecasting;Software;Libraries;quantum finance;chaotic neural network;deep learning;QFSDK;python;AI education},
doi={10.1109/ITHET56107.2022.10031712},
ISSN={2380-1603},
month={Nov},}
@INPROCEEDINGS{6704496,
author={Shih-Wei Liao},
booktitle={The 11th IEEE Symposium on Embedded Systems for Real-time Multimedia},
title={High-level compute APIs and performance portability on Android},
year={2013},
volume={},
number={},
pages={1-1},
abstract={The versatility of heterogeneous platform had prompted it to become the mainstream of computer architecture design, especially for mobile computing. It is necessary to classify the strength and weakness among different programming models in heterogeneous system development to guide programmers to select suitable tools while implementing various software layers. In addition to the models, we will also offer two other angles: Hardware and runtime. The hardware side details heterogeneous compute devices. For the runtime angle, utilizing all available compute devices is a differentiator. Achieving device fusion and performance portability at run time have been active research areas recently. In this talk, we select two types of representative programming models, Google RenderScript and OpenCL, for comparison in order to fully illustrate their technical correlation and the implications to the platform architecture and system construction. We focus on the following aspects: language capability, performance, code complexity and multi-versioning, static runtime distribution and dynamic load balancing. RenderScript benefits application developers in terms of flexibility and hands-on programming convenience while OpenCL excels at wide adoption among hardware vendors and low-level runtime construction to maximize the system performance.},
keywords={Runtime;Educational institutions;Programming;Computational modeling;Hardware;Computer architecture;Google},
doi={10.1109/ESTIMedia.2013.6704496},
ISSN={2325-1301},
month={Oct},}
@ARTICLE{9193978,
author={Kuthe, Pascal and Müller, Markus and Schröter, Michael},
journal={IEEE Journal of the Electron Devices Society},
title={VerilogAE: An Open Source Verilog-A Compiler for Compact Model Parameter Extraction},
year={2020},
volume={8},
number={},
pages={1416-1423},
abstract={This article introduces a new open-source Verilog-A compiler, VerilogAE, purpose-built to ease compact model parameter extraction. VerilogAE retrieves all model equations, their dependencies, and relevant model parameters that are defined in a Verilog-A source. This information is made available to users by compiling the Verilog-A source file into a shared library. Herein, the features and design principles of the software and its interface are explained. Then, it is demonstrated how this eases the implementation of parameter extraction methods and steps.},
keywords={Mathematical model;Hardware design languages;Parameter extraction;Semiconductor process modeling;Integrated circuit modeling;Libraries;Electron devices;Semiconductor device modeling;open source software;parameter extraction;circuit simulation},
doi={10.1109/JEDS.2020.3023165},
ISSN={2168-6734},
month={},}
@ARTICLE{8911260,
author={Gao, Lan and Xu, Yunlong and Wang, Rui and Luan, Zhongzhi and Yu, Zhibin and Qian, Depei},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Thread-Level Locking for SIMT Architectures},
year={2020},
volume={31},
number={5},
pages={1121-1136},
abstract={As more emerging applications are moving to GPUs, thread-level synchronization has become a requirement. However, GPUs only provide warp-level and thread-block-level rather than thread-level synchronization. Moreover, it is highly possible to cause live-locks by using CPU synchronization mechanisms to implement thread-level synchronization for GPUs. In this article, we first propose a software-based thread-level synchronization mechanism called lock stealing for GPUs to avoid live-locks. We then describe how to implement our lock stealing algorithm in mutual exclusive locks and readers-writer locks with high performance. Finally, by putting it all together, we develop a thread-level locking library (TLLL) for commercial GPUs. To evaluate TLLL and show its general applicability, we use it to implement six widely used programs. We compare TLLL against the state-of-the-art ad-hoc GPU synchronization, GPU software transactional memory (STM), and CPU hardware transactional memory (HTM), respectively. The results show that, compared with the ad-hoc GPU synchronization for Delaunay mesh refinement (DMR), TLLL improves the performance by 22 percent on average on a GTX970 GPU, and shows up to 11 percent of performance improvement on a Volta V100 GPU. Moreover, it significantly reduces the required memory size. Such low memory consumption enables DMR to successfully run on the GTX970 GPU with the 10-million mesh size, and the V100 GPU with the 40-million mesh size, with which the ad-hoc synchronization can not run successfully. In addition, TLLL outperforms the GPU STM by 65 percent, and the CPU HTM (running on a Xeon E5-2620 v4 CPU with 16 hardware threads) by 43 percent on average.},
keywords={Graphics processing units;Synchronization;Message systems;System recovery;Instruction sets;Hardware;Computer architecture;Deadlocks;parallelism and concurrency;runtime environments;SIMD processors;synchronization},
doi={10.1109/TPDS.2019.2955705},
ISSN={1558-2183},
month={May},}
@INPROCEEDINGS{7294057,
author={Racchetti, Lorenzo and Tacconi, Lorenzo and Fantuzzi, Cesare},
booktitle={2015 IEEE International Conference on Automation Science and Engineering (CASE)},
title={Generating automatically the documentation from PLC code by D4T3 to improve the usability and life cycle management of software in automation},
year={2015},
volume={},
number={},
pages={168-173},
abstract={D4T3 (i.e. Doxygen for TwinCAT3) was developed to generate automatically the documentation from a set of documented and/or undocumented PLC source files. D4T3 documentation was designed to support traditional PLC-world features (e.g. inputs, programs, tasks, etc.) and more recent Object Oriented features of IEC61131-3 (e.g. interfaces, inheritance, etc.). Moreover, this documentation was designed to be generated as an on-line manual (i.e. HTML) and/or as an off-line reference manual (e.g. LATEX, CHM, etc.). The usability, maintainability and understanding of documented PLC software was found significantly improved when the software was provided with its D4T3 documentation. Additionally, D4T3 reduced the time spent on documentation and managed the differences among versions. Thus, the automated documentation generator can be used to simplify/overcome the usability and life-cycle-management challenges in automation. It can also lead PLC vendors to design a common tool to generate the PLC software documentation supporting system engineers and software engineers in automation.},
keywords={Documentation;Generators;Guidelines;Automation;Usability;Layout},
doi={10.1109/CoASE.2015.7294057},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{1368337,
author={Reves, X. and Marojevic, V. and Gelonch, A. and Ferrus, R.},
booktitle={2004 IEEE 15th International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE Cat. No.04TH8754)},
title={The cost of an abstraction layer on FPGA devices for software radio applications},
year={2004},
volume={3},
number={},
pages={1942-1946 Vol.3},
abstract={Software radio applications require a framework to develop and deploy applications, especially those related to radio infrastructure. It is interesting that a given application may be executed on any software radio. But, since hardware platforms used in this context will have multiple architectures and devices, a software layer to make applications independent from hardware is mandatory. Ad-hoc software for a given hardware platform may produce the best software performance. Conversely, when software is not targeted to any concrete platform the lost of performance may be excessive and the overhead introduced by any platform-dependent library could become intolerable. In this paper the resource utilization of a software radio application using a simple hardware abstraction layer is studied and compared to an ad-hoc implementation to make an assessment of the introduced overhead. The particularity of the hardware abstraction layer is that it runs on a platform which only processors are FPGA devices.},
keywords={Costs;Field programmable gate arrays;Software radio;Application software;Hardware;Software performance;Computer architecture;Concrete;Software libraries;Resource management},
doi={10.1109/PIMRC.2004.1368337},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{4148720,
author={Kootsey, J. Mailen},
booktitle={First Asia International Conference on Modelling & Simulation (AMS'07)},
title={Interactive Simulation in Web Pages: A System for Rapid Development},
year={2007},
volume={},
number={},
pages={556-561},
abstract={This paper describes a software system for rapid, coding-free development of interactive simulations in Web pages. The core of the system is a library of reusable objects based on the NumberLinX (NLX) architecture: GUI objects for user-controlled inputs, output displays, and controls, along with calculation objects and a manager linking all the objects. The development system included an NLX library, an application program for entering the model description, and integration of the NLX objects into a commercial Web design program for page construction},
keywords={Web pages;HTML;Object oriented modeling;Equations;Computer architecture;Computational modeling;Displays;Joining processes;Web design;Web page design},
doi={10.1109/AMS.2007.57},
ISSN={},
month={March},}
@INPROCEEDINGS{5337198,
author={Washizaki, Hironori and Fernandez, Eduardo B. and Maruyama, Katsuhisa and Kubo, Atsuto and Yoshioka, Nobukazu},
booktitle={2009 20th International Workshop on Database and Expert Systems Application},
title={Improving the Classification of Security Patterns},
year={2009},
volume={},
number={},
pages={165-170},
abstract={There are a large number of security patterns encapsulating reusable solutions to recurrent security problems. However, catalogs of security patterns are not enough because the designer does not know when and where to apply them, especially in a large complex system. There is a need to conduct more precise classifications of security patterns. We analyze here ways to represent security patterns using specialized models for their precise classification. We define two new types of models, one that describes how a security pattern relates to several classification dimensions (Dimension Graph), and another that describes how security patterns relate to each other (Pattern Graphs). We show these ideas with examples from security patterns.},
keywords={National security;Pattern analysis;Catalogs;Guidelines;Product design;Databases;Expert systems;Data security;Informatics;Packaging;Security;Security Patterns;Software Patterns;Classification;Modeling;UML;Metamodel},
doi={10.1109/DEXA.2009.79},
ISSN={2378-3915},
month={Aug},}
@INPROCEEDINGS{4618431,
author={Bullock, James and Frisk, Henrik A. and Coccioli, Lamberto},
booktitle={MELECON 2008 - The 14th IEEE Mediterranean Electrotechnical Conference},
title={Sustainability of ‘live electronic’ music in the Integra project},
year={2008},
volume={},
number={},
pages={182-187},
abstract={In this paper we describe a new XML file format and a database schema designed for the storage of performance data and meta-data relating to live electronic music. We briefly describe the architecture of the Integra environment, and give examples of the hierarchical modelling of Integra classes. The separation of module definition, module instance data and module implementation data is presented as one of the key components of the Integra system. The libIntegra library is proposed as a means for supporting the file formats in target applications.},
keywords={Music;Databases;Libraries;Oscillators;Software;XML;Documentation;Documentation;Multimedia databases;Multimedia systems;Music;Programming environments;Software portability},
doi={10.1109/MELCON.2008.4618431},
ISSN={2158-8481},
month={May},}
@INPROCEEDINGS{4022093,
author={Medina, Ma. Auxilio and Chavez-Aragon, Alberto and Chavez, R. Omar},
booktitle={2006 Fourth Latin American Web Congress},
title={Construction, Implementation and Maintenance of Ontologies of Records},
year={2006},
volume={},
number={},
pages={67-73},
abstract={This paper describes structures which represent the organization of documents extracted from open archives initiative compliant data providers. We have called them "ontologies of records". They group similar documents by means of data mining techniques and document clustering algorithms. Ontology markup languages are used to implement them. We show an ontology of records constructed in a semi-automatic way and propose a maintenance process based on collaborative rewriting and revision. Ontologies of records have a well defined meaning, they enable human and software agents to work in cooperation to exploit data providers. The paper is a small contribution to the construction of lightweight ontologies to be used for different purposes in the semantic Web},
keywords={Ontologies;Itemsets;Clustering algorithms;Data mining;Software libraries;Search engines;Markup languages;Humans;Software agents;Access protocols},
doi={10.1109/LA-WEB.2006.9},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8741505,
author={Mensah, Francis and Acakpovi, Amevi and Osumanu, Futa and Sowah, Robert and Fifatin, Francois-Xawier Nicolas and Nounangnonhou, Télesphore Cossi},
booktitle={2019 International Conference on Computing, Computational Modelling and Applications (ICCMA)},
title={Modelling an Efficient Gap Filler for DTT Network Using ADS Software},
year={2019},
volume={},
number={},
pages={34-345},
abstract={This paper proposes the modelling and simulation of a special gap filler intended to cover grey areas in the DTT network of Accra. This has become necessary due to the numerous areas of low signal coverage in the Accra DTT and the incapability of previous methods to efficiently address the problem. The ADS simulation consists of arrangements of components from the DBV-T library which consists of filters, amplifiers and a power source. This setup mimics a gap filler system with a better noise reduction implementation, several frequency values are being used for the simulation process. A significant increase in the output signal as in comparison to the input means the shaded areas will be properly covered. The results derived from the simulation of the ADS setup highly improved upon the output signal values, when compared to the ITU standard. Three (3) out of five (5) simulation results show values beyond the minimum signal level requirement. Also using MATLAB, the RF propagation toolbox which has the map tool feature was able to implement the gap fillers into the Accra area and gave a visual representation of the signal strength. Modelling a gap filler system which has better noise cancellation and which propagates better with a dipole antenna was achieved in this paper. The outcome of the paper shows that the gap filler modelling increase signals in grey areas.},
keywords={Baseband;Broadcasting;Power harmonic filters;TV;Radio transmitters;Radio frequency;ITU;Digital Terrestrial Television;Gap filler;Grey areas;MATLAB;Advanced Design System (ADS)},
doi={10.1109/ICCMA.2019.00013},
ISSN={},
month={March},}
@ARTICLE{1468669,
author={Gomez, J.M. and Gutierrez, X.F. and Canal, J.A.},
journal={IEEE Latin America Transactions},
title={Implementing Direct and Sequential Access to Data Collections using Aspects},
year={2005},
volume={3},
number={1},
pages={104-111},
abstract={Data collection libraries play an important role in component-based software development. The collections contained in those libraries (JCF, STL, LEDA, etc.) implement a mathematical model that defines one or more access methods to the elements (access by key, access to the element stored last, etc.). In addition, most of these libraries allow a different, more efficient type of access, which can be direct access (e.g., by means of the position where the element is stored, that is obtained when it is inserted) or sequential access (usually by means of the iterator concept). This type of efficient access presents several risks with respect to criteria such as precision and suitability that are not solved appropriately in the current existing libraries. In this work, we present two design patterns that provide a generic solution to the problem together with their implementation using aspects. The patterns introduce new data types and new operations that provide the libraries with full uniformity and a high extensibility degree. The use ofaspects allows dissociating these types of access and the functionality of the collection, making aspects responsible of the position persistence management, modification monitoring during iterations, etc. The proposal is implemented using AspectJ.},
keywords={Libraries;Programming;Software design;Software engineering;Java;aspect oriented software development;design patterns;component Based Software Engineering},
doi={10.1109/TLA.2005.1468669},
ISSN={1548-0992},
month={March},}
@ARTICLE{5634109,
author={Saranli, Uluç and Avci, Akın and Öztürk, M. Cihan},
journal={IEEE Transactions on Instrumentation and Measurement},
title={A Modular Real-Time Fieldbus Architecture for Mobile Robotic Platforms},
year={2011},
volume={60},
number={3},
pages={916-927},
abstract={The design and construction of complex and reconfigurable embedded systems such as small autonomous mobile robots is a challenging task that involves the selection, interfacing, and programming of a large number of sensors and actuators. Facilitating this tedious process requires modularity and extensibility both in hardware and software components. In this paper, we introduce the universal robot bus (URB), a real-time fieldbus architecture that facilitates rapid integration of heterogeneous sensor and actuator nodes to a central processing unit (CPU) while providing a software abstraction that eliminates complications arising from the lack of hardware homogeneity. Motivated by our primary application area of mobile robotics, URB is designed to be very lightweight and efficient, with real-time support for Recommended Standard (RS) 232 or universal serial bus connections to a central computer and inter-integrated circuit (I2C), controller area network, or RS485 bus connections to embedded nodes. It supports automatic synchronization of data acquisition across multiple nodes, provides high data bandwidth at low deterministic latencies, and includes flexible libraries for modular software development both for local nodes and the CPU. This paper describes the design of the URB architecture, provides a careful experimental characterization of its performance, and demonstrates its utility in the context of its deployment in a legged robot platform.},
keywords={Protocols;Real time systems;Downlink;Computer architecture;Robot sensing systems;Instruments;Distributed control;embedded systems;fieldbus;instrumentation architecture;mobile robots;real-time data acquisition;universal robot bus (URB)},
doi={10.1109/TIM.2010.2078351},
ISSN={1557-9662},
month={March},}
@INPROCEEDINGS{4090184,
author={Vishnu, Abhinav and Gupta, Prachi and Mamidala, Amith R. and Panda, Dhabaleswar K.},
booktitle={SC '06: Proceedings of the 2006 ACM/IEEE Conference on Supercomputing},
title={A Software Based Approach for Providing Network Fault Tolerance in Clusters with uDAPL interface: MPI Level Design and Performance Evaluation},
year={2006},
volume={},
number={},
pages={10-10},
abstract={In the arena of cluster computing, MPI has emerged as the de facto standard for writing parallel applications. At the same time, introduction of high speed RDMA-enabled interconnects like InfiniBand, Myrinet, Quadrics, RDMA-enabled Ethernet has escalated the trends in cluster computing. Network APIs like uDAPL (user direct access provider library) are being proposed to provide a network-independent interface to different RDMA-enabled interconnects. Clusters with combination(s) of these interconnects are being deployed to leverage their unique features, and network failover in wake of transmission errors. In this paper, we design a network fault tolerant MPI using uDAPL interface, making this design portable for existing and upcoming interconnects. Our design provides failover to available paths, asynchronous recovery of the previous failed paths and recovery from network partitions without application restart. In addition, the design is able to handle network heterogeneity, making it suitable for the current state of the art clusters. We implement our design and evaluate it with micro-benchmarks and applications. Our performance evaluation shows that the proposed design provides significant performance benefits to both homogeneous and heterogeneous clusters. Using a heterogeneous combinations of IBA and Ammasso-GigE, we are able to improve the performance by 10-15% for different NAS parallel benchmarks on 8 times 1 configuration. For simple micro-benchmarks on a homogeneous configuration, we are able to achieve an improvement of 15-20% in throughput. In addition, experiments with simple MPI micro-benchmarks and NAS applications reveal that network fault tolerance modules incur negligible overhead and provide optimal performance in wake of network partitions},
keywords={Software performance;Fault tolerance;Computer networks;Concurrent computing;Filters;Computer interfaces;Writing;Ethernet networks;Libraries;Throughput},
doi={10.1109/SC.2006.5},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9259353,
author={Pan, Heng and Li, Zhenyu and Zhang, Penghao and Salamatian, Kave and Xie, Gaogang},
booktitle={2020 IEEE 28th International Conference on Network Protocols (ICNP)},
title={Misconfiguration Checking for SDN: Data Structure, Theory and Algorithms},
year={2020},
volume={},
number={},
pages={1-11},
abstract={Software-Defined Networking (SDN) facilitates net-work innovations with programmability. However, programming the network is error-prone no matter using low-level APIs or high-level programming languages. That said, SDN policies deployed in networks may contain misconfigurations. Prior studies focus on either traditional access control policies or network-wide states, and thus are unable to effectively detect potential misconfigurations in SDN policies with bitmask patterns and complex action behaviorsTo address this gap, this paper first presents a new data structure, minimal interval set, to represent the match patterns of rulesets. This representation serves the basis for composition algebra construction and fast misconfiguration checking. We then propose the principles and algorithms for fast and accurate con-figuration verification. We finally implement a misconfiguration checking tool in Covisor with optimisations to further reduce the overhead. Experiments with synthetic and random rulesets show its fitness for purpose.},
keywords={Pattern matching;IP networks;Algebra;Tools;Programming;Data structures;Monitoring},
doi={10.1109/ICNP49622.2020.9259353},
ISSN={2643-3303},
month={Oct},}
@INPROCEEDINGS{5276549,
author={Zamli, Kamal Z. and Hassan, Mohd Daud Alang and Isa, Nor Ashidi Mat and Azizan, Siti Norbaya},
booktitle={2006 International Conference on Computing & Informatics},
title={An automated software fault injection tool for robustness assessment of java COTs},
year={2006},
volume={},
number={},
pages={1-6},
abstract={In line with market demands and the need for technological innovations, designing and implementing software and hardware components for computing systems is growing in complexity. In order to cope with such complexity whilst meeting market needs, engineers often rely on design integration with commercial-of-the-shelf-components (COTs). In the case where lives and fortunes are at stake, there is a need to ensure dependability of COTs in terms of their robustness before they can be adopted in such an environment. However, it is not often possible to thoroughly test COTs for robustness because their design as well as source codes are usually unavailable. In order to address some of the above issues, we have developed an automated software fault injection tool, ca lled SFIT, based on the use of computational reflection and Java technology. This paper describes our experiences with SFIT performing robustness testing of Java COTs, called Jada, a Linda tuple space implementation.},
keywords={Software tools;Robustness;Java;Testing;Space technology;Technological innovation;Software design;Hardware;Design engineering;Reflection},
doi={10.1109/ICOCI.2006.5276549},
ISSN={2166-5729},
month={June},}
@INPROCEEDINGS{9268358,
author={Yeoh, C. E. and Kim, D. B. and Won, Y. B. and Lee, S. R. and Yi, H.},
booktitle={2020 20th International Conference on Control, Automation and Systems (ICCAS)},
title={Constructing ROS Package for Legged Robot in Gazebo Simulation from Scratch},
year={2020},
volume={},
number={},
pages={94-99},
abstract={Robot Operating System, (ROS) is one of the open-source, meta-operating system, which is now widely used as the robotic software platform and can be applicable for anyone who wanted to build their robot from scratch. For the credit of the beneficial of ROS, the work of this paper describes all the process and structure of the package construction for the legged robot simulation in Gazebo. There are five mains folders consisted in the package, which are configuration file (config), launch file (launch), meshes folder (meshes), script folder (script), Universal robot definition format folder (urdf), and worlds folder (worlds). In this research, Pseudo-inverse Jacobian was implemented to obtain the optimal angular joint for every step walking during the simulation. Result of the walking robot simulation are shown to have the least error range around 0.0365 m to 0.0867 m differ from the actual target position.},
keywords={Robots;Legged locomotion;Jacobian matrices;Mathematical model;Kinematics;Collision avoidance;Operating systems;Robot operating system (ROS);Legged robot;Pseudo-inverse Jacobian;Gazebo simulation},
doi={10.23919/ICCAS50221.2020.9268358},
ISSN={2642-3901},
month={Oct},}
@INPROCEEDINGS{5404041,
author={Greiner, Alain and Faure, Etienne and Pouillon, Nicolas and Genius, Daniela},
booktitle={2009 Forum on Specification & Design Languages (FDL)},
title={A generic hardware / software communication middleware for streaming applications on shared memory multi processor systems-on-chip},
year={2009},
volume={},
number={},
pages={1-4},
abstract={Streaming applications, such as packet switching or video and multimedia processing, require high through-put, that can be obtained by exploiting the application coarse grain parallelism, and mapping the parallel multitasks application on a multiprocessor system on chip (MPSoC). The seamless migration of a task from software to hardware implementation requires an unified communication intrastructure. We present in this paper the multi-writer multi-reader (MWMR) communication middleware and the associated protocol, initially designed for telecom and packet processing applications. Our middleware provides both a software API (for software tasks), and a generic, programmable hardware controller with a DMA capability (that can be used with dedicated hardware coprocessors). We demonstrate on a multitask application (motion JPEG decoder) that this generic communication infrastructure can be used in video or multimedia applications, and it implements the KPN (Kahn process network) semantics more efficiently than previous implementations.},
keywords={Hardware;Communication system software;Middleware;Application software;Streaming media;Packet switching;Video sharing;Multimedia systems;Multiprocessing systems;System-on-a-chip},
doi={},
ISSN={1636-9874},
month={Sep.},}
@INPROCEEDINGS{7724480,
author={Kumar, Sushil and Nag, Rajiv},
booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)},
title={An approach for multimedia software size estimation},
year={2016},
volume={},
number={},
pages={1321-1326},
abstract={Although, the Function Point Analysis has offered an idea to estimate the size of software in both planned and existing one [1], use of multimedia technology has provided a different direction for delivering instruction. The interested users in the era of Graphics User Interfaces, are being attracted, gets benefited and have new learning capabilities and this is reason the two-way multimedia training is a process, rather than being termed as a technology. Multimedia software Developer should use suitable methods for designing the package which will not only enhance its capabilities but will also be user friendly. Mixed media projects can be utilized to present data in combined form in a number of ways to energize routes hypermedia strategies with guideline. Great presentations can be made when they depend on psychological targets that create attention on the learning of themes at distinctive levels of appreciation. All media segments, for example, design, sound and video and so forth it adds to learning. While developing multimedia programs, developer should focus mainly on three point; firstly grabbing the user's attention; secondly it should ease the user to find and organize all necessary information and finally to integrate all information into the user's knowledge data bank. All elements like text, graphics icon and audio visual elements need to be utilized at the maximum to create visual appeal and organized in structured program, and thus for the purpose of systematic organization it is convenient to divide the screen into functional areas by the Developers. Class and sequence diagrams were utilized solely for the generation of FP counts [2]. A similar technique for creating automated counts using COSMIC FFP methods likewise depended on UML graphs [3]. But, neither of these strategies measures will be used for the estimation mixed media software the developers.},
keywords={Handheld computers;Decision support systems;Conferences;MFPA — Multimedia Function Point Analysis;MUFP — Multimedia Unadjusted Function Points;MCAF — Multimedia Complexity Adjustment Factor;MLI — Level of Impact for Multimedia;MGSC — General System Characteristic for Multimedia;MVAF — Value Adjustment Factor for Multimedia},
doi={},
ISSN={},
month={March},}
@INPROCEEDINGS{5613097,
author={Kalinnik, Natalia and Korch, Matthias and Rauber, Thomas},
booktitle={2010 IEEE International Conference On Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS)},
title={Applicability of dynamic selection of implementation variants of sequential iterated Runge-Kutta methods},
year={2010},
volume={},
number={},
pages={1-8},
abstract={Iterated Runge-Kutta (IRK) methods are a class of solution methods for initial value problems (IVPs) of ordinary differential equations (ODEs). The main advantage of IRK methods is that the stages within each corrector step are independent. This provides an additional degree of parallelism as well as an additional degree of freedom in the organization of the computational structure. The performance of implementations of IRK methods strongly depends on the characteristics of the IVP and the target architecture. Therefore, it is important that an IRK solver can adapt to these characteristics, such as the coupling structure of the ODE system and parameters of the cache hierarchy. In this paper, we focus on autotuning techniques for the sequential execution of IRK methods. We present a self-adapting IRK solver, which exploits the time-stepping nature of the solution procedure to select the best implementation from a candidate pool at run-time. Runtime experiments show that this technique can successfully be applied to differently structured IVPs on different architectures.},
keywords={Approximation methods;Computer architecture;Pipeline processing;Signal processing algorithms;Equations;Libraries;Program processors;self-adapting numerical software;autotuning;ordinary differential equations;iterated Runge-Kutta methods},
doi={10.1109/CLUSTERWKSP.2010.5613097},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6494467,
author={Srinivasan, S. and Raja, K. and Muthuselvan, S.},
booktitle={2012 International Conference on Emerging Trends in Electrical Engineering and Energy Management (ICETEEEM)},
title={Futuristic assimilation of cloud computing platforms and its services},
year={2012},
volume={},
number={},
pages={178-180},
abstract={Cloud computing is one of today's most exciting technologies due to its ability to reduce costs associated with computing while increasing flexibility and scalability for computer processes. Cloud computing is Internet-based computing, whereby shared resources, software and information, are provided to computers and devices on-demand, like the electricity grid. It aims to construct a perfect system with powerful computing capability through a large number of relatively low-cost computing entities, and using the advanced business models. The construction of on-premises application platform into cloud environment with limited foundations, infrastructure and application services. The Integration of cloud platform architecture and on-premises platform together is an enormous reform on building a huge environment on today's cloud computing environment SOA is a set of services and advocate the principles of component reuse and well defined relationship between a service provider and service consumer. This article introduces the background, services and service model of cloud computing and overlapping of SOA and cloud computing.},
keywords={Cloud platforms;SOA;Integration;API},
doi={10.1109/ICETEEEM.2012.6494467},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7577368,
author={Sharif, Malik Umar and Shahid, Rabia and Gaj, Kris and Rogawski, Marcin},
booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)},
title={Hardware-software codesign of RSA for optimal performance vs. flexibility trade-off},
year={2016},
volume={},
number={},
pages={1-4},
abstract={Public-key cryptosystems such as RSA have been widely used to secure digital data in many commercial systems. Modular arithmetic on large operands used during modular exponentiation makes RSA computationally challenging. Traditionally, software implementations of these algorithms provided the highest flexibility but lacked performance. On the contrary, custom hardware accelerators provided the highest performance but lacked flexibility and adaptability to changing algorithms, parameters, and key sizes. In this paper, we present a hardware/software codesign of RSA cryptosystem that improves performance, while retaining flexibility. We adopted Xilinx Zynq-7000 SoC platform, which integrates a dual-core ARM Cortex-A9 processing system along with Xilinx programmable logic. The software part of our implementation is based on RELIC library (Efficient Library for Cryptography). The performance vs. flexibility trade-off is investigated, and the speed-up of our codesign implementation vs. the purely software implementation of RSA on the same platform is reported. Our results show a speedup of up to 57 times when compared with the software implementation for 2048-bit operand size. We also propose a generic model for HW/SW codesign focused on flexibility with comparable performance to existing HW/SW implementations.},
keywords={Cryptography;Hardware;Software;Partitioning algorithms;Software algorithms;Coprocessors},
doi={10.1109/FPL.2016.7577368},
ISSN={1946-1488},
month={Aug},}
@INPROCEEDINGS{4796498,
author={Abdi, Samar and Schirner, Gunar and Viskic, Ines and Hansu Cho and Yonghyun Hwang and Lochi Yu and Gajski, Daniel},
booktitle={2009 Asia and South Pacific Design Automation Conference},
title={Hardware-dependent Software synthesis for many-core embedded systems},
year={2009},
volume={},
number={},
pages={304-310},
abstract={This paper presents synthesis of hardware dependent software (HdS) for multicore and many-core designs using embedded system environment (ESE). ESE is a tool set, developed at UC Irvine, for transaction level design of multicore embedded systems. HdS synthesis is a key component of ESE back-end design flow. We follow a design process that starts with an application model consisting of C processes communicating via abstract message passing channels. The application model is mapped to a platform net-list of SW and HW cores, buses and buffers. A high speed transaction level model (TLM) is generated to validate abstract communication between processes mapped to different cores. The TLM is further refined into a pin-cycle accurate model (PCAM) for board implementation. The PCAM includes C code for all the HdS layers including routing, packeting, synchronization and bus transfer. The generated HdS methods provide a library of application level services to the C processes on individual SW cores. Therefore, the application developer does not need to write low level HdS for board implementation. Synthesis results for an multi-core MP3 decoder design, using ESE, show that the HdS is generated in order of seconds, compared to hours of manual coding. The quality of synthesized code is comparable to manually written code in terms of performance and code size.},
keywords={Embedded software;Embedded system;Multicore processing;Hardware;Process design;Application software;Message passing;Routing;Libraries;Digital audio players},
doi={10.1109/ASPDAC.2009.4796498},
ISSN={2153-697X},
month={Jan},}
@INPROCEEDINGS{6835584,
author={Zhu, Daxin and Wang, Xiaodong},
booktitle={2013 International Conference on Computer Sciences and Applications},
title={The Computer Implementations of an Efficient Iterative Algorithm Based on the Inverse Newton Interpolation},
year={2013},
volume={},
number={},
pages={219-222},
abstract={In this work, we develop a simple yet practical algorithm for solving nonlinear optimization problems by finding a root of a real function f'(x)=0 with a good local convergence. The algorithm uses an inverse interpolation method that can be easily implemented in software packages for achieving desired convergence orders. For the general n-point formula, the order of convergence rate of the presented algorithm is τn, the unique positive root of the equation xn - x(n-1)-...-x-1=0.},
keywords={Convergence;Interpolation;Algorithm design and analysis;Iterative methods;Nonlinear equations;Software algorithms;interpolation;convergence;software;algorithms},
doi={10.1109/CSA.2013.58},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9935197,
author={Duan, Xuefeng and Li, Jian and Pei, Xin and Ergesh, Toktonur and Wen, Zhigang and Chen, Maozheng},
booktitle={2022 IEEE 9th International Symposium on Microwave, Antenna, Propagation and EMC Technologies for Wireless Communications (MAPE)},
title={Implementation of CASPAR Firmware Interface on PYNQ-Z2},
year={2022},
volume={},
number={},
pages={53-57},
abstract={We proposed a new efficient and flexible FPGA design method for the PYNQ-Z2 platform. The CASPER firmware interface is developed based on the PYNQ-Z2, and the FPGA firmware programs are designed using the CASPER toolflow. We used the PYNQ system to create a TCP service for communication with the CASPER library to enable remote real-time interaction, configuration, program loading and data reading from the hardware platform. The performance of the implemented CASPER platform is verified by designing firmware programs for GPIO, software registers, FIR digital filters and related experiments. The implemented approach provides rich development resources for FPGA development, shortens development cycle, improves development efficiency, and greatly simplifies the FPGA firmware design flow through platform-independent hardware and software.},
keywords={Microwave antennas;Finite impulse response filters;Signal processing algorithms;Low-pass filters;Hardware;Software;Registers;PYNQ-Z2;GPIO;Software register;FIR Filter},
doi={10.1109/MAPE53743.2022.9935197},
ISSN={},
month={Aug},}
@INPROCEEDINGS{6663001,
author={Jurnečka, Peter and Hanáček, Petr and Kačic, Matej},
booktitle={2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)},
title={Concept of parallel code refactoring system for safety standards compliance},
year={2013},
volume={02},
number={},
pages={630-634},
abstract={The importance of safety standards of software systems is increasing as the use of software grows because of its convenience and flexibility. Software safety standards are very important in aircraft, military, automotive or medical devices. We are developing parallel code generating and refactoring system for safety standards compliance, which increases reliability of existing codes by refactoring of existing parallel source code, introducing parallel design patterns into this code. This paper describes the current status of these software safety standards, points out the common requirements of all these standards, specially the requirement for reliability. Reliability can be easily achieved using design patterns with verified reliable source code modules. In our research, we propose system for implementation of concurrency and synchronization design patterns into existing code. We have created parallel source code search API, which is planned to be used in our parallel code refactoring system for safety standards compliance. This API enables us to define appropriate places in source codes for introduction of parallel design patterns into existing parallel source codes. In next design iteration, the proposed system will provide suggestions of refactoring operations of found source codes, based on static code analysis and formal description of parallel design patterns.},
keywords={Standards;Safety;Synchronization;Reliability;Instruction sets;Suspensions;software safety;parallel design patterns;code searching},
doi={10.1109/IDAACS.2013.6663001},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{1564663,
author={Xiaoling Xu and Jieying Tang},
booktitle={2005 6th International Conference on Electronic Packaging Technology},
title={Analysis of Response of the Micro-Machined Poly-Silicon Cantilever Subjected to Vibration Environment},
year={2005},
volume={},
number={},
pages={1-5},
abstract={With the decrease in the dimension the microstucture, the effect of the interaction between the surfaces of the neighboring structures on the dynamic characteristics cannot be ignored. We present a comparison of the dynamic responses of the beam with and without considering the adhesive forces by simulating the dynamic behavior of the beam with a commercial software ANSYS. With the effect of the adhesive forces, the dynamic characteristics of the beam deviate from that of the beam without considering the adhesive forces. The reliability and the precision of the MEMS products using cantilevers are diminished.},
keywords={Micromechanical devices;Instruments;Vibrations;Structural beams;Microstructure;Force measurement;Equations;Reliability theory;Guidelines;Atomic measurements},
doi={10.1109/ICEPT.2005.1564663},
ISSN={},
month={Aug},}
@INPROCEEDINGS{6471572,
author={Ahmed, Shaon and Iqbal, S.M. Navid and Sakib, Nazmus and Islam, Md. Rafiqul},
booktitle={2012 7th International Conference on Electrical and Computer Engineering},
title={Design and implementation of data string transceiver using GNU radio},
year={2012},
volume={},
number={},
pages={401-404},
abstract={The increase of wireless applications and the rise of number of gadgets has made it imperative that designers transfer the complexity of hardware to software. It provides multi-standard support for the wireless devices such that software enables manifold radio functions independent of hardware. On this basis, a lot of development is going on in the field of Software Defined Radio using GNU Radio and USRP. USRP provides the hardware platform for transmission and reception of GNU radio. In this paper, transmission of string type data from one CPU to another CPU has been implemented using GNU radio library and USRP.},
keywords={Receivers;Wireless communication;Hardware;Software radio;Modulation;Noise;Benchmark testing;Aloha Protocols (Access Protocols);Software Defined Radio (SDR);Universal Software Radio Peripheral (USRP);Python},
doi={10.1109/ICECE.2012.6471572},
ISSN={},
month={Dec},}
@ARTICLE{192213,
author={Papachristou, C.A. and Immaneni, V.R.},
journal={IEEE Transactions on Computers},
title={Vertical migration of software functions and algorithms using enhanced microsequencing},
year={1993},
volume={42},
number={1},
pages={45-61},
abstract={A scheme for vertical migration of algorithms and functions with complex sequencing structure from software through firmware into microcoded VLSI structures is discussed. The expected benefits of migration are gains in speed, reliability, and stability. The scheme employs a migration model that is based on microcode modularity and is supported by a hardware microcontroller with enhanced sequencing capability. The basic idea is to capture, using effective compilation techniques, the explicit or implicit sequencing structure of a function. Migration is then effected by sequencing calls into a library of microcode modules of a target machine architecture. The modularity of the migration system is well suited for generating VLSI microcode. The experimental results from an environment consisting of several firmware development tools show substantial time performance improvements in comparison to software implementations. Comparisons to traditional migration approaches indicate that the proposed scheme is faster and requires less memory space for the migration of software algorithms into firmware.<>},
keywords={Software algorithms;Microprogramming;Very large scale integration;Stability;Hardware;Microcontrollers;Software libraries;Computer architecture;Software performance;Software tools},
doi={10.1109/12.192213},
ISSN={1557-9956},
month={Jan},}