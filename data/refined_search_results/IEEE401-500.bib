@ARTICLE{9121275,
author={Borelli, Fabrizio F. and Biondi, Gabriela O. and Kamienski, Carlos A.},
journal={IEEE Access},
title={BIoTA: A Buildout IoT Application Language},
year={2020},
volume={8},
number={},
pages={126443-126459},
abstract={Domain-Specific Languages (DSLs) serve a wide variety of purposes in the development of complex applications. The Internet of Things (IoT) brings additional complexity to software development due to its inherent distribution and inclusion of a massive number of heterogeneous devices (sensors and actuators). The process of developing software architectures for IoT involves the interaction of several components that play distinct roles. In this paper, we propose a language called BIoTA (Buildout IoT Application Language), a DSL whose objective is to assist and streamline the building of software architectures for IoT. The specification and implementation of the BIoTA language involve a grammar and a compiler, responsible for syntax and semantic analysis, as well as code generation. They facilitate the formalization of software architectures using automata, which would otherwise be created in an informal and ad-hoc manner to address specific IoT scenarios. We developed an IDE (Integrated Development Environment) capable of reading and creating software architectures using the BIoTA language. With the BIoTA IDE, we demonstrate three examples of software architectures for IoT smart applications in public buildings, irrigation, and parking. The IDE also makes it possible to export architectures to a software distribution package pattern based on containers (Docker Compose) for future deployment.},
keywords={Internet of Things;Software architecture;Software;Computer architecture;Unified modeling language;Connectors;DSL;Systems architecture;Internet of Things;IDE;IoT software development;IoT;design patterns;software architecture;smart applications},
doi={10.1109/ACCESS.2020.3003694},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{1240331,
author={da Silva, M.C.Jr. and de C Guerra, P.A. and Rubira, C.M.F.},
booktitle={18th IEEE International Conference on Automated Software Engineering, 2003. Proceedings.},
title={A Java component model for evolving software systems},
year={2003},
volume={},
number={},
pages={327-330},
abstract={This paper presents a component model for designing and implementing flexible software components in Java. Our model defines a mapping of how the fundamental concepts of component-based development (CBD) should be implemented using the object-oriented (OO) constructs, available in the Java programming language. The benefit of this mapping is to shorten the distance between component-based software architecture and its implementation, enhancing the reusability, adaptability and maintainability of component-based software systems.},
keywords={Java;Software systems;Object oriented modeling;Software architecture;Connectors;Computer languages;Concrete;Packaging;Software design;Software maintenance},
doi={10.1109/ASE.2003.1240331},
ISSN={1938-4300},
month={Oct},}
@INPROCEEDINGS{8805734,
author={Dürschmid, Tobias and Kang, Eunsuk and Garlan, David},
booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)},
title={Trade-Off-Oriented Development: Making Quality Attribute Trade-Offs First-Class},
year={2019},
volume={},
number={},
pages={109-112},
abstract={Implementing a solution for a design decision that precisely satisfies the trade-off between quality attributes can be extremely challenging. Further, typically quality attribute trade-offs are not represented as first-class entities in development artifacts. Hence, decisions might be sub-optimal and lack requirements traceability as well as changeability. We propose Trade-off-oriented Development (ToD), a new concept to automate the selection and integration of reusable implementations for a given design decision based on quality attribute trade-offs. Implementations that vary in quality attributes and that solve reoccurring design decisions are collected in a design decision library. Developers declaratively specify the quality attribute trade-off, which is then used to automatically select the best fitting implementation. We argue that thereby, software could satisfy the trade-offs more precisely, requirements are traceable and changeable, and advances in implementations automatically improve existing software.},
keywords={Contracts;Software;Libraries;Banking;Encryption;Reliability;design decision;software architecture;quality attribute;non functional property;reuse;software design},
doi={10.1109/ICSE-NIER.2019.00036},
ISSN={},
month={May},}
@INPROCEEDINGS{518585,
author={Mohanty, S. and Wilsey, P.A.},
booktitle={Proceedings Sixth IEEE International Workshop on Rapid System Prototyping. Shortening the Path from Specification to Prototype},
title={Rapid system prototyping, system modeling, and analysis in a hardware-software codesign environment},
year={1995},
volume={},
number={},
pages={154-160},
abstract={A hardware-software codesign environment provides the designer with an environment in which the designer can concurrently develop the hardware and software components of the system to satisfy a given set of performance and design constraints. As a design evolves from the conceptual level model of the hardware-software system, to the final implementation, the design progresses through a number of design steps and design environments. There exists a need for a single uniform design environment for specifying design information as it develops. In this paper, we describe our work to use VHDL to build design libraries that support rapid system prototyping and conceptual modeling as software components. Furthermore, the design libraries have been linked with a graphical codesign environment. This graphical environment provides a single framework in which the designer can (i) build the design, (ii) simulate the design for correctness, and (iii) visualize performance results and capacity measures.},
keywords={Software prototyping;Modeling;Hardware;Software libraries;Software performance;Prototypes;Computer architecture;Process design;Monitoring;Contracts},
doi={10.1109/IWRSP.1995.518585},
ISSN={1074-6005},
month={June},}
@INPROCEEDINGS{6032579,
author={Fein, Elad and Razinkov, Natalia and Shachor, Shlomit and Mazzoleni, Pietro and Goh, Sweefen and Goodwin, Richard and Bhand, Manisha and Chen, Shyh-Kwei and Lee, Juhnyoung and Sinha, Vibha Singhal and Mani, Senthil and Mukherjee, Debdoot and Srivastava, Biplav and Dhoolia, Pankaj},
booktitle={2011 33rd International Conference on Software Engineering (ICSE)},
title={Using MATCON to generate CASE tools that guide deployment of pre-packaged applications},
year={2011},
volume={},
number={},
pages={1016-1018},
abstract={The complex process of adapting pre-packaged applications, such as Oracle or SAP, to an organization's needs is full of challenges. Although detailed, structured, and well-documented methods govern this process, the consulting team implementing the method must spend a huge amount of manual effort to make sure the guidelines of the method are followed as intended by the method author. MATCON breaks down the method content, documents, templates, and work products into reusable objects, and enables them to be cataloged and indexed so these objects can be easily found and reused on subsequent projects. By using models and meta-modeling the reusable methods, we automatically produce a CASE tool to apply these methods, thereby guiding consultants through this complex process. The resulting tool helps consultants create the method deliverables for the initial phases of large customization projects. Our MATCON output, referred to as Consultant Assistant, has shown significant savings in training costs, a 20 - 30% improvement in productivity, and positive results in large Oracle and SAP implementations.},
keywords={Computer aided software engineering;Biological system modeling;Business;Software;Metamodeling;Guidelines;information reuse;method authoring;model-driven software development;packaged applications},
doi={10.1145/1985793.1985981},
ISSN={1558-1225},
month={May},}
@INPROCEEDINGS{985782,
author={Eyermann, P.A. and Powell, M.A.},
booktitle={2001 MILCOM Proceedings Communications for Network-Centric Operations: Creating the Information Force (Cat. No.01CH37277)},
title={Maturing the software communications architecture for JTRS},
year={2001},
volume={1},
number={},
pages={158-162 vol.1},
abstract={This paper summarizes the status of the Joint Tactical Radio System (JTRS) software communications architecture (SCA). As the result of steps taken by the JTRS Joint Program Office (JPO) and the Modular Software-programmable Radio Consortium (MSRC), the SCA is at a level of maturity that ensures the goals of the JTRS program can be met. The SCA defines the framework for JTRS implementations in a manner that provides for communications interoperability, portability of application programs, and the ability to leverage commercial development and product availability into JTRS procurements. Key features of the SCA are the core software framework interfaces defined in a standard interface definition language (IDL), communication waveform application program interfaces (APIs) and API building blocks, and requirements for embedded INFOSEC and for INFOSEC APIs. The JTRS JPO has contracted with multiple vendors to implement these elements to validate the architecture. The results have shown that the architecture can be implemented in multiple products providing interoperable communications and that waveforms can be ported between different implementations with greatly reduced effort compared to that required in current radio designs. The SCA is designed and expected to grow as systems are procured and experience is gained with fielded equipment. The efforts to date show that the SCA meets or exceeds the goals and expectations of the JTRS JPO in defining the framework on which to base those equipment designs.},
keywords={Computer architecture;Application software;Hardware;Communication system software;Procurement;Software standards;Software systems;Embedded software;Communication standards;Military communication},
doi={10.1109/MILCOM.2001.985782},
ISSN={},
month={Oct},}
@ARTICLE{9799,
author={Ringeard, C. and Maloeuvre, M.},
journal={IEEE Transactions on Instrumentation and Measurement},
title={CALIBRAT: a software for control and calibration of electronic measurement devices},
year={1988},
volume={37},
number={4},
pages={497-500},
abstract={CALIBRAT is a software package designed to facilitate quality assurance plan implementation, particularly in the French military establishment. CALIBRAT is intended to be used for a quality assurance plan for measurement devices (mainly multimeters). It includes a high-level language for writing control and calibration procedures and a result database for analysis. Complementary tools like operator dialog, specialized editor, and help for the constitution of a devices library, makes its use very easy and versatile. The set of powerful tools has been developed with specific IEEE-488 bus command oriented keywords and an instrument manager to provide independence between the language and the instruments. CALIBRAT can be run on a personal computer with a GPIB-PC1 or -PC2 National Instruments Board IEEE-488 bus controller.<>},
keywords={Calibration;Instruments;Quality assurance;Software packages;Software design;High level languages;Writing;Databases;Data analysis;Constitution},
doi={10.1109/19.9799},
ISSN={1557-9662},
month={Dec},}
@INPROCEEDINGS{756763,
author={Lohier, F. and Garda, P.},
booktitle={Proceedings 1999 IEEE Symposium on Application-Specific Systems and Software Engineering and Technology. ASSET'99 (Cat. No.PR00122)},
title={A software engineering methodology to optimize caching in multi-processor DSP architectures: TMS320C80 results towards the real-time execution of low level image processing},
year={1999},
volume={},
number={},
pages={146-154},
abstract={This paper introduces an original software engineering methodology we developed while focusing on the implementation of a low-level image processing library targeted for a shared memory multi-processor DSP architecture: the TMS320C80. Real-time constraints led us to concentrate on the enhancement of data locality thanks to the software managing of caches based on an advanced multi-dimensional DMA. This contribution compares to other existing C80's image processing libraries in terms of genericity, flexibility and performance improvement. Our approach allows for the composing of concurrent processing chains grounded on a modular library gathering basic processing operators. Generic mechanisms allow to address all basic operator's requirements as well as to quickly expand the library thanks to a re-usable and well defined framework. Flexibility allows to dynamically re-configure a chain or to modify the region of interest and the number of processors. We finally demonstrate experimentally that our approach allows significant performance improvements.},
keywords={Software engineering;Optimization methods;Digital signal processing;Computer architecture;Signal processing algorithms;Reduced instruction set computing;Hardware;Decision support systems;VLIW;Optimizing compilers},
doi={10.1109/ASSET.1999.756763},
ISSN={},
month={March},}
@ARTICLE{5210055,
author={},
journal={IEEE STD 1636-2009 (New Trial-Use Standard)},
title={IEEE Standard for Software Interface for Maintenance Information Collection and Analysis (SIMICA)},
year={2009},
volume={},
number={},
pages={1-38},
abstract={This document provides an implementation-independent specification for a software interface to information systems containing data pertinent to the diagnosis and maintenance of complex systems consisting of hardware, software, or any combination thereof. These interfaces will support service definitions for creating application programming interfaces (API) for the access, exchange, and analysis of historical diagnostic and maintenance information. This will address the pervasive need of organizations to assess the effectiveness of diagnostics for complex systems throughout the product life cycle. The use of formal information models will facilitate exchanging historical maintenance information between information systems and analysis tools. The models will facilitate creating open system software architectures for maturing system diagnostics.},
keywords={IEEE Standards;Maintenance engineering;Software;Information systems;Complex systems;Trademarks;AI-ESTATE;Automated Test Markup Language (ATML);diagnostic maturation;IEEE 1636TM;Maintenance Action Information;maintenance data;Software Interface for Maintenance Information Collection and Analysis (SIMICA);Test Results and Session Information},
doi={10.1109/IEEESTD.2009.5210055},
ISSN={},
month={Aug},}
@ARTICLE{4939017,
author={Vasylchenko, A. and Schols, Y. and De Raedt, W. and Vandenbosch, G. A. E.},
journal={IEEE Antennas and Propagation Magazine},
title={Quality Assessment of Computational Techniques and Software Tools for Planar-Antenna Analysis},
year={2009},
volume={51},
number={1},
pages={23-38},
abstract={The goal of this paper is a thorough investigation of the quality of the software tools widely used nowadays in the field of planar-antenna analysis and synthesis. Six simulation tools - five well-known commercial tools and one developed in-house - are compared with each other for four different planar antennas. It is crucial to point out that all possible efforts have been made to guarantee the most optimal use of each of the software packages, to study in detail any discrepancies between the solvers, and to assess the remaining simulation challenges. The study clearly highlights the importance of understanding EM simulation principles and their inherent limitations for antenna designers. Finally, some designing guidelines are provided that also can simplify the initial selection of EM solvers.},
keywords={Quality assessment;Software tools;Computational modeling;Planar arrays;Software packages;Guidelines;Planar antennas;microstrip antennas;monopole antennas;ultra-wideband antennas;electromagnetic analysis;simulation software;computer aided analysis},
doi={10.1109/MAP.2009.4939017},
ISSN={1558-4143},
month={Feb},}
@INPROCEEDINGS{7970479,
author={Kharitonov, Nikita A. and Tulupyev, Alexander L. and Zolotin, Andrey A.},
booktitle={2017 XX IEEE International Conference on Soft Computing and Measurements (SCM)},
title={Software implementation of reconciliation algorithms in algebraic Bayesian networks},
year={2017},
volume={},
number={},
pages={8-10},
abstract={Algorithms for algebraic Bayesian networks external and internal consistency maintenance are considered in the paper. An implementation of classes' structure representing algebraic Bayesian networks is proposed. The main approaches used in the consistency algorithms implementation as well as use cases of developed methods are provided. The proposed structure can later be re-used in the global inference algorithms implementation.},
keywords={Bayes methods;Software algorithms;Maintenance engineering;Inference algorithms;Probabilistic logic;Software packages;algprobabilistic graphical model;consistency check;machine learning;algebraic Bayesian networks},
doi={10.1109/SCM.2017.7970479},
ISSN={},
month={May},}
@INPROCEEDINGS{8537199,
author={Takase, Hideki and Mori, Tomoya and Takagi, Kazuyoshi and Takagi, Naofumi},
booktitle={2018 International Conference on Embedded Software (EMSOFT)},
title={Work-in-Progress: Design Concept of a Lightweight Runtime Environment for Robot Software Components Onto Embedded Devices},
year={2018},
volume={},
number={},
pages={1-3},
abstract={Although ROS (Robotic Operating System) has attracted attention to enhance the productivity of robot software development, it is necessary to adopt the device with high function and large power consumption enough to install Linux. This paper designs a lightweight runtime environment of ROS nodes onto mid-range embedded devices. Our environment, that is named to mROS, consists of a real-time OS and TCP/IP protocol stack to provide a tiny ROS communication library. mROS provides the connectivity to host and other ROS nodes with the native ROS network protocol. One of advantages for mROS is that native ROS nodes can be ported from Linux-based systems to RTOS-based systems since APIs with the same name of native ROS can be used in the embedded program. Experimental results validate that the performance requirement of mROS can be achieved for the construction of distributed robot systems.},
keywords={Robots;Task analysis;Libraries;TCPIP;Protocols;Real-time systems;Software;robot operating systems;real-time operating systems;TCP/IP},
doi={10.1109/EMSOFT.2018.8537199},
ISSN={},
month={Sep.},}
@ARTICLE{1177934,
author={Winiecki, W. and Karkowski, M.},
journal={IEEE Transactions on Instrumentation and Measurement},
title={A new Java-based software environment for distributed measuring systems design},
year={2002},
volume={51},
number={6},
pages={1340-1346},
abstract={A new, low-cost software environment for distributed measuring systems is described. It permits the design of applications based only on Java technology, and consequently, the securing of full Internet integration, platform independence, and unrestricted access to a measuring system by the WWW. The proposed tool permits the design of panels of virtual measuring instruments. A specialized system server, with a proposed controls library, allows fully distributed implementation of a measuring system.},
keywords={Java;Software measurement;Computer networks;Instruments;Application software;Software design;Buildings;Internet;Control systems;IP networks},
doi={10.1109/TIM.2002.807980},
ISSN={1557-9662},
month={Dec},}
@INPROCEEDINGS{365808,
author={Ning, J.Q. and Miriyala, K. and Kozaczynski, W.},
booktitle={Proceedings of 1994 3rd International Conference on Software Reuse},
title={An architecture-driven, business-specific, and component-based approach to software engineering},
year={1994},
volume={},
number={},
pages={84-93},
abstract={The paper describes an approach to software reuse which is under development and evaluation at Andersen Consulting. Instead of restricting reuse to just code, we are exploring reuse of architectures that include component interfaces, interconnections between components, and platform configuration. The approach assumes that first a desired architecture is chosen and tailored according to the constraints at hand. Then, appropriate components are retrieved from a repository, subjected to restricted modifications if necessary and "glued" together following the architectural guidelines. Finally, a version of a system is automatically packaged from the selected components and the architectural specifications. The paper presents the approach and some initial experiments in the design of an interface specification language and an environment in which modules can be interconnected and their interface specifications used to determining the integrity of the connections.<>},
keywords={Software engineering;Buildings;Software systems;Business;Packaging;Aging;LAN interconnection;Large-scale systems;Companies;Manufacturing},
doi={10.1109/ICSR.1994.365808},
ISSN={},
month={Nov},}
@INPROCEEDINGS{524982,
author={Jaeyoung Choi and Dongarra, J.J.},
booktitle={Proceedings of the Fifth IEEE Computer Society Workshop on Future Trends of Distributed Computing Systems},
title={Scalable linear algebra software libraries for distributed memory concurrent computers},
year={1995},
volume={},
number={},
pages={170-177},
abstract={This paper discusses the core factorization routines included in the ScaLAPACK library. These routines allow the factorization and solution of a dense system of linear equations via LU, QR, and Cholesky. They are implemented using a block cyclic data distribution, and are built using de facto standard kernels for matrix and vector operations (BLAS and its parallel counterpart PBLAS) and message passing communication (BLACS). In implementing the ScaLAPACK routines, a major objective was to parallelize the corresponding sequential LAPACK using the BLAS, BLACS, and PBLAS as building blocks, leading to straightforward parallel implementations without a significant loss in performance. This paper discusses the design of ScaLAPACK a scalable software library for performing dense and banded linear algebra computations on distributed memory concurrent computers. They are implemented using a block cyclic data distribution, and are built using de facto standard kernels for matrix and vector operations (BLAS and its parallel counterpart PBLAS) and message passing communication (BLACS). In implementing the ScaLAPACK routines, a major objective was to parallelize the corresponding sequential LAPACK using the BLAS, BLACS, and PBLAS as building blocks, leading to straightforward parallel implementations without a significant loss in performance. We present the details of the implementation of the ScaLAPACK LU factorization routine, and performance and scalability results on the Intel iPSC/860, Touchstone Delta, and Paragon systems.},
keywords={Linear algebra;Software libraries;Communication standards;Kernel;Vectors;Message passing;Performance loss;Concurrent computing;Distributed computing;Equations},
doi={10.1109/FTDCS.1995.524982},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9774595,
author={Jeppu, Natasha Yogananda and Melham, Tom and Kroening, Daniel},
booktitle={2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)},
title={Active Learning of Abstract System Models from Traces using Model Checking},
year={2022},
volume={},
number={},
pages={100-103},
abstract={We present a new active model-learning approach to generating abstractions of a system implementation, as finite state automata (FSAs), from execution traces. Given an implementation and a set of observable system variables, the generated automata admit all system behaviours over the given variables and provide useful insight in the form of invariants that hold on the implementation. To achieve this, the proposed approach uses a pluggable model learning component that can generate an FSA from a given set of traces. Conditions that encode a completeness hypothesis are then extracted from the FSA under construction and used to evaluate its degree of completeness by checking their truth value against the system using software model checking. This generates new traces that express any missing behaviours. The new trace data is used to iteratively refine the abstraction, until all system behaviours are admitted by the learned abstraction. To evaluate the approach, we reverse-engineer a set of publicly available Simulink Stateflow models from their C implementations.},
keywords={Software packages;Learning automata;Model checking;System implementation;active model learning;execution traces;system abstraction;software model checking},
doi={10.23919/DATE54114.2022.9774595},
ISSN={1558-1101},
month={March},}
@INPROCEEDINGS{9640635,
author={Bikku, Thulasi and Karthik, Jayavarapu and Koteswara Rao, Ganga Rama and Satya Sree, K P N V and Srinivas, P V V S and Prasad, Chitturi},
booktitle={2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)},
title={Brain Tissue Segmentation via Deep Convolutional Neural Networks},
year={2021},
volume={},
number={},
pages={757-763},
abstract={Deep convolutional neural networks were used to successfully segment several important neural tissue classes in MRI brain images, and approaches for integrating prior information into the networks to increase their performance on this task were investigated. Regrettably, only the first of them is addressed in this paper. To make the implementation of nonstandard architectures, which was expected to be required for the second goal, it was determined to provide a framework for defining and training networks by only using fundamental components. While this was an educational experience, the amount of progress accomplished was far less than if a conventional network package had been utilized instead. The requirement to deal with all of the lowest level aspects of network construction, from initialization schemes to adaptive learning rates and all the other components of the optimizer pipeline has left no time for utilizing this infrastructure to do something which has not been accomplished by the existing frameworks, and of course in all other respects it is far more limited than they are. It would in-stead be focused on a clear and detailed analysis of the full pipeline, which is required to build a network for solving the first problem. Despite several difficulties tracking down bugs in the optimizer, GPU memory allocation, and the last-minute accidental deletion of a large portion of the experimental results, the software implementation made available at: achieves DICE results of 0:8, which, while not class leading, would still place well in many benchmarks.},
keywords={Training;Brain;Three-dimensional displays;Pipelines;Software;Windows;Convolutional neural networks;Nonstandard architectures;network construction;optimizer Random Decision Forest;Regression;Autodesk 3D Max software;Prosthetic},
doi={10.1109/I-SMAC52330.2021.9640635},
ISSN={2768-0673},
month={Nov},}
@INPROCEEDINGS{4493639,
author={Bagheri, Hamid and Montaghami, Vajih and Safi, Gholamreza and Mirian-Hosseinabadi, Seyed-Hassan},
booktitle={2008 IEEE/ACS International Conference on Computer Systems and Applications},
title={An evaluation method for aspectual modeling of distributed software architectures},
year={2008},
volume={},
number={},
pages={903-908},
abstract={Dealing with crosscutting requirements in software development usually makes the process more complex. Modeling and analyzing of these requirements in the software architecture facilitate detecting architectural risks early. Distributed systems have more complexity and so these facilities are much useful in development of such systems. Aspect oriented Architectural Description Languages (ADD) have emerged to represent solutions for discussed problems; nevertheless, imposing radical changes to existing architectural modeling methods is not easily acceptable by architects. Software architecture analysis methods, furthermore, intend to verify that the quality requirements have been addressed properly. In this paper, we enhance ArchC# through utilization of aspect features with an especial focus on Non-Functional Requirements (NFR). ArchC# is mainly focused on describing architecture of distributed systems; in addition, it unifies software architecture with an object- oriented implementation to make executable architectures. Moreover, in this paper, a comparative analysis method is presented for evaluation of the result. All of these materials are illustrated along with a case study.},
keywords={Software architecture;Computer architecture;Risk analysis;Application software;Packaging;Software quality;Distributed computing;Programming;Encapsulation;Software testing},
doi={10.1109/AICCSA.2008.4493639},
ISSN={2161-5330},
month={March},}
@INPROCEEDINGS{13085,
author={Madhavji, N.H. and Desharnais, J. and Pinsonneault, L. and Toubache, K.},
booktitle={Proceedings. 1988 International Conference on Computer Languages},
title={Adapting modules to an integrated programming environment},
year={1988},
volume={},
number={},
pages={364-371},
abstract={The design of modules in modular languages, and the model of software development activities portrayed by it, have been well received in batch environments. However, from their experience in the design of the MUPE-2 integrated programming environment, the authors hold the opinion that the model of software activities portrayed by modules in a batch environment is not entirely appropriate in an integrated programming environment. In adapting modules to the MUPE-2 environment, the authors have changed their design and implementation. In particular, they have added a module type, called the supermodule, that can encapsulate related modules, so that the architecture of a software system may be captured, and unified the separate definition and implementation parts of a module into a single module, called the DefImp module, so that some consistency problems due to textual separation can be avoided. They examine the role of modules in a batch environment and give a rationale for their design of modules for integrated environments.<>},
keywords={Programming environments;Programming profession;Packaging;Computer science;Computer architecture;Software packages;Software quality;Modular construction},
doi={10.1109/ICCL.1988.13085},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9476156,
author={JalyZada, Aras J.},
booktitle={2021 7th International Engineering Conference “Research & Innovation amid Global Pandemic" (IEC)},
title={Structural analysis of Supports Reactions by Using Building Information Modelling},
year={2021},
volume={},
number={},
pages={107-111},
abstract={Structural analysis is a key part of the engineering design that structural engineers use to ensure that a structure can resist the different types of forces that it will encounter during its operation. Many powerful and popular structural software are available in this engineering field. Building information modelling (BIM) is one of the most promising recent developments in the Engineering field. Employing BIM enhanced the building design process by introducing new avenues for collaboration among multi-disciplinary designers. Currently, different BIM software packages are used by the multidisciplinary designers. However, not much information can be found in the BIM model that structural engineers can benefit from. Moreover, the structural software programs have not adopted the philosophy of BIM on the framework of the software.The objective of this study is to use BIM technology for analysis of the building structural model. This study is limited to find the reactions of the supports, as a structural element, in the BIM model. Therefore, a new application “Support Reactions application” is implemented, which was created by using Microsoft C# programming language. This application was integrated and interfaced with Autodesk Revit by using the Revit API (Application programming interface). As a result, this new add-in makes its users free from using any other structural software to find the supports reactions in the BIM model.},
keywords={Analytical models;Computer languages;Technological innovation;Software packages;Pandemics;Building information management;Resists;Structural Analysis;BIM;Support reactions;Revit API},
doi={10.1109/IEC52205.2021.9476156},
ISSN={},
month={Feb},}
@INPROCEEDINGS{667832,
author={Maiden, N.A.M. and Ncube, C.},
booktitle={Proceedings of IEEE International Symposium on Requirements Engineering: RE '98},
title={Acquiring COTS software selection requirements},
year={1998},
volume={},
number={},
pages={241-},
abstract={An increasing number of organisations are procuring off-the-shelf systems from commercial suppliers. However, successful selection of off-the-shelf systems to fit customer requirements remains problematic. The London Ambulance Service fiasco in 1992 is a well-known example of system failure due, at least in part, to poor product selection. New methods and techniques for requirements acquisition and product selection are needed. The authors propose a new method which integrates techniques from several disciplines in response to lessons learned from a complex commercial off-the-shelf product selection exercise undertaken by the authors. They report on a recent experience in selecting a complex commercial off-the-shelf software system to be compliant with over 130 customer requirements, and lessons learned from the experience. These lessons learned inform design of PORE (Procurement-Oriented Requirements Engineering), a template-based method for requirements acquisition. This paper reports 11 of these lessons. Particular focus is put on the typical problems which arose during acquisition of requirements to enable this selection, and solutions to avoid these problems in the future.},
keywords={Software tools;Design engineering;Software testing;Guidelines;Software systems;Procurement;Market research;Software measurement;Software prototyping;Knowledge engineering},
doi={10.1109/ICRE.1998.667832},
ISSN={},
month={April},}
@INPROCEEDINGS{1169896,
author={Lepage, R.},
booktitle={ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing},
title={Interactive software package for digital signal processing},
year={1987},
volume={12},
number={},
pages={1887-1890},
abstract={A large number of computer programs are discussed in the scientific literature for the implementation of most digital signal processing algorithms. The reader interested in evaluating this type of algorithm is often discouraged by the time and effort he has to spend interfacing the algorithm to his particular processing environment. This paper presents a software testbed package called the Digital Signal Processing Interactive System (DSPIS) which was designed to be a unified and consistent environment for the evaluation of digital signal processing algorithms. Input and output data are confined to seven vectors: X, Y and V for time domain, A, B and W for spectral domain and, finally, C for coefficient domain. Data can be synthesized or transferred from a file into one of the vectors, processed by one or more algorithms and the results (in one or many vectors) can be stored in files. Any vector can be printed out or displayed against its scaled index (except the vector C). DSPIS is menu oriented and permits interactive execution of commands.},
keywords={Software packages;Digital signal processing;Signal processing algorithms;Software testing;System testing;Packaging;Interactive systems;Signal design;Algorithm design and analysis;Software algorithms},
doi={10.1109/ICASSP.1987.1169896},
ISSN={},
month={April},}
@INPROCEEDINGS{5166892,
author={Selvarani, R. and Nair, T.R. Gopalakrishnan and Prasad, V. Kamakshi},
booktitle={2009 International Conference on Signal Processing Systems},
title={Estimation of Defect Proneness Using Design Complexity Measurements in Object-Oriented Software},
year={2009},
volume={},
number={},
pages={766-770},
abstract={Software engineering is continuously facing the challenges of growing complexity of software packages and increased level of data on defects and drawbacks from software production process. This makes a clarion call for inventions and methods which can enable a more reusable, reliable, easily maintainable and high quality software systems with deeper control on software generation process. Quality and productivity are indeed the two most important parameters for controlling any industrial process. Implementation of a successful control system requires some means of measurement. Software metrics play an important role in the management aspects of the software development process such as better planning, assessment of improvements, resource allocation and reduction of unpredictability. The process involving early detection of potential problems, productivity evaluation and evaluating external quality factors such as reusability, maintainability, defect proneness and complexity are of utmost importance. Here we discuss the application of CK metrics and estimation model to predict the external quality parameters for optimizing the design process and production process for desired levels of quality. Estimation of defect-proneness in object-oriented system at design level is developed using a novel methodology where models of relationship between CK metrics and defect-proneness index is achieved. A multifunctional estimation approach captures the correlation between CK metrics and defect proneness level of software modules.},
keywords={Software measurement;Control systems;Productivity;Resource management;Object oriented modeling;Software engineering;Software packages;Continuous production;Maintenance;Software systems;Quality;design;defect-proneness;internal parameters;metrics;DIT;RFC;WMC;Estimation},
doi={10.1109/ICSPS.2009.163},
ISSN={},
month={May},}
@INPROCEEDINGS{7147740,
author={Krigslund, Jeppe and Hansen, Jonas and Lucani, Daniel E. and Fitzek, Frank H. P. and Medard, Muriel},
booktitle={Proceedings of European Wireless 2015; 21th European Wireless Conference},
title={Network Coded Software Defined Networking: Design and Implementation},
year={2015},
volume={},
number={},
pages={1-6},
abstract={Software Defined Networking (SDN) and Network Coding (NC) are two key concepts in networking that have garnered much attention in recent years. On the one hand, SDN's potential to virtualize services in the Internet allows a large flexibility not only for routing data, but also to manage buffering, scheduling, and processing over the network. On the other hand, NC has shown great potential for increasing robustness and performance when deployed on intermediate nodes in the network. This new paradigm changes the dynamics of network protocols, requiring new designs that exploit its potential. This paper advocates for the use of SDN to bring about future Internet and 5G network services by incorporating NC functionalities. The inherent flexibility of both SDN and NC provides a fertile ground to envision more efficient, robust, and secure networking designs, that may also incorporate content caching and storage, all of which are key challenges of the future Internet and the upcoming 5G networks. This paper proposes some of the keys behind this intersection and supports it with use cases as well as a an implementation that integrated the Kodo library (NC) into OpenFlow (SDN). Our results on single-hop, multi-hop, and multi-path scenarios show that gains of 3x to 11x are attainable over standard TCP and Multi-Path TCP.},
keywords={},
doi={},
ISSN={},
month={May},}
@INPROCEEDINGS{5768325,
author={Yajun, Zhou and Haojie, Lu and Wujia, Yu},
booktitle={2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)},
title={PLC virtual simulation experiment software design and implementation},
year={2011},
volume={},
number={},
pages={1501-1504},
abstract={This paper presented the design and implementation solution of virtual simulation experiment software in .NET framework environment. An OPC client was realized by C# programming language in the program, and communicated with the OPC server based on COM. By using LINQ technology to access SQL server database, simulation controlled objects library was built. Communication between C# application and Flash simulation object was also researched in this work. The experimental result shows that the virtual simulation experiment software is convenient to experiment management, data access, improve the quality of PLC experiment and reduce cost at the same time.},
keywords={Servers;Databases;Software;XML;Libraries;Automation;Visualization;Virtual simulation experiment;OPC communication;LINQ;Flash},
doi={10.1109/CECNET.2011.5768325},
ISSN={},
month={April},}
@INPROCEEDINGS{9089752,
author={Brusaporci, Stefano and Maiezza, Pamela and Tata, Alessandra},
booktitle={2018 Metrology for Archaeology and Cultural Heritage (MetroArchaeo)},
title={Computational Design for As-Built Modeling of Architectural Heritage in HBIM processes},
year={2018},
volume={},
number={},
pages={199-203},
abstract={The complexity of the geometric shapes of historical architecture is difficult to manage by the BIM software. The paper investigates the possibilities offered by computational design for the modeling and parameterization of architectural heritage components.The aim of the studied methodology is the creation of a sort of parametric object library for historical architectures, which allows the management of complex geometries and the optimization of the HBIM process.},
keywords={Buildings;Computational modeling;Geometry;Three-dimensional displays;Generators;Software;Visualization;HBIM;computational design;3D modeling;parametrization},
doi={10.1109/MetroArchaeo43810.2018.13620},
ISSN={},
month={Oct},}
@INPROCEEDINGS{1314660,
author={Denney, W.C. and King, M.W. and Wilck, J.H.},
booktitle={Proceedings of the 2004 IEEE Systems and Information Engineering Design Symposium, 2004.},
title={Implementation of a software tool for a gold electroplating bath operation},
year={2004},
volume={},
number={},
pages={33-39},
abstract={To increase the efficiency of a commercial gold electroplating operation, researchers analyzed historical data for the electroplating baths and developed bath management tools and strategies using statistics and systems design methods. The past process was operating outside of established process specification limits; therefore management desired easy-to-use tools for tracking bath chemical levels and determining chemical adjustments to keep the baths within specifications. After consultation with personnel, the project team accomplished this goal by creating a software tool that was integrated into the initial system. The software tool combines lab data storage, specification chart generation, and stoichiometry in a robust Visual Basic package running inside of Microsoft Excel. Upon the conclusion of this project, the company expects to see improvements in interdepartmental communication, value-added laboratory utilization, and overall part quality. Potential quantitative benefits include a reduction in the annual cost of poor quality, currently estimated at $400,000 for the electroplating process.},
keywords={Software tools;Gold;Chemical processes;Data analysis;Statistical analysis;Personnel;Memory;Robustness;Visual BASIC;Software packages},
doi={10.1109/SIEDS.2004.239766},
ISSN={},
month={April},}
@INPROCEEDINGS{1202423,
author={Gacic, A. and Puschel, M. and Moura, J.M.F.},
booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},
title={Fast automatic software implementations of FIR filters},
year={2003},
volume={2},
number={},
pages={II-541},
abstract={SPIRAL is a generator for platform-adapted libraries of DSP transform algorithms. SPIRAL represents and automatically generates fast algorithms as mathematical formulas and translates them into programs. Adaptation is achieved by searching in the space of algorithmic and coding alternatives for the fastest implementation. We extend SPIRAL to generate platform-adapted implementations of FIR filters. First, we present various filter algorithms and introduce the mathematical constructs needed to include them into SPIRAL's architecture. Then we use SPIRAL to find fast filter implementations. The results show runtime improvements to a standard loop implementation of up to 70% using different blocking techniques. Further, we show that the usefulness of frequency-domain methods is not determined by the number of operations.},
keywords={Finite impulse response filter;Spirals;Signal processing algorithms;Digital signal processing;Discrete transforms;Software libraries;Runtime;Discrete Fourier transforms;Signal generators;Search engines},
doi={10.1109/ICASSP.2003.1202423},
ISSN={1520-6149},
month={April},}
@INPROCEEDINGS{4634780,
author={Wehrwein, Bradley and Matos, Gilberto and Tanikella, Rajanikanth},
booktitle={2008 12th International IEEE Enterprise Distributed Object Computing Conference},
title={A Requirements-Driven and Collaborative Decision Support Approach for Evaluating the Viability of Candidate Implementation Technologies},
year={2008},
volume={},
number={},
pages={293-299},
abstract={Platforms, frameworks, and other forms of software assets are proliferating in the industry for well-documented reasons. Architects may choose from a wide variety of implementation technologies to realize their envisioned software architecture. Each asset provides the ability to fulfill a set of requirements, and imposes a set of constraints. Given these complex compatibility relationships, it is a non-trivial task to determine how best to utilize candidate assets toward a defined business problem. This task is made harder when multiple stakeholders from various backgrounds contribute to the decision-making process, as often occurs in large projects.By grouping requirements by functional area, and relating them to corresponding candidate technologies, we propose an approach that allows stakeholders to collaboratively reason about the satisfaction of requirements, the compatibility of technologies, and integration risk. The goal is to narrow the initial space of technologies to a smaller number of viable candidate technology sets.},
keywords={Computer architecture;Software;Servers;User interfaces;Libraries;Java;Estimation;COTS evaluation;COTS selection;technology assessment;software architecture;software requirements;agile methodologies;software reuse},
doi={10.1109/EDOC.2008.46},
ISSN={1541-7719},
month={Sep.},}
@INPROCEEDINGS{5761433,
author={Grigioni, M. and Barbaro, V. and Daniele, C. and Palombo, A.},
booktitle={1992 14th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={A software package to standardise pulsatile in-vitro testing of prosthetic heart valves},
year={1992},
volume={3},
number={},
pages={1164-1165},
abstract={Data comparability Is a crucial aspect in in-vitro evaluation of prosthetic heart valves and it is still a matter of debate among researchers and standardization bodies. When adopting pulsatile flow testing systems the main difficulties arise from the difference in system design and in protocol implementation. At the laboratory of Biomedical Engineering of the Istituto Superiore dl Sanita efforts are being made towards obtaining comparable data, significant for both surgeons and authorities in decision making situations, A software package has been designed to manage all the phases of the pulsatile testing session, and meant to standardise the procedures involved also when using different pulse duplicators.},
keywords={Biomedical measurements;Prosthetics;Testing;Cardiology},
doi={10.1109/IEMBS.1992.5761433},
ISSN={},
month={Oct},}
@INPROCEEDINGS{5319571,
author={Yinghui, Peng},
booktitle={2009 WRI World Congress on Software Engineering},
title={The Application of PKCS#12 Digital Certificate in User Identity Authentication System},
year={2009},
volume={4},
number={},
pages={351-355},
abstract={A feasible solution is put forward aiming at information security of Campus network. In this paper, user identity authentication system of Campus network based on PKI and digital certification PKCS#12 is designed and implemented. PKCS#12 certificate, by a moveable electronic storage device carrier, has implemented Single Sign on. makes it true that security and stability of digital certificate is improved. In implementation, using MVC model and import Bouncy Castle Crypto APIs software development packages improved reusability and security and maintainability of system.},
keywords={Authentication;Information security;Public key;Web server;Certification;Internet;Public key cryptography;Privacy;Software packages;Data security;PKCS#12digital certificate;SSO(single sign on);BouncyCastle cryptographic software package;MVC model;information security},
doi={10.1109/WCSE.2009.202},
ISSN={},
month={May},}
@INPROCEEDINGS{1251463,
author={Smeda, A. and Oussalah, M. and Khammaci, T.},
booktitle={Proceedings Fifth IEEE Workshop on Mobile Computing Systems and Applications},
title={Software connectors reuse in component-based systems},
year={2003},
volume={},
number={},
pages={543-550},
abstract={Component-based software architecture describes systems as a collection of components that interact with each other using connectors. While components are defined explicitly, connectors are left tangled. Connectors are often considered to be explicit at the level of architecture but implicit in a system's implementation. This ambiguity makes it difficult to redefine or reuse a connector. In this article, we present a clear definition of connectors in component-based systems. We use this definition to describe a number of operational mechanisms to support connectors' reuse in a component-based software architecture.},
keywords={Connectors;Software architecture;Computer architecture;Computer interfaces;Functional programming;Processor scheduling;Packaging;Application software;Filters;Architecture description languages},
doi={10.1109/IRI.2003.1251463},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7009535,
author={Krishnaswamy, Dilip and Qamar, Asif and Krishnan, Ram and Rajagopal, Krishnakumar and Narayan, Naveen and Bijlani, Kamal and Moudgalya, Kannan},
booktitle={2014 IEEE Sixth International Conference on Technology for Education},
title={Bringing Knowledge to the Edge with Jnana Edge and Buddhi Edge: Architecture, Implementation, and Future Directions},
year={2014},
volume={},
number={},
pages={48-51},
abstract={Jnana Edge provides a fundamentally different approach to bringing a knowledge experience, in a qualitatively rich, focused way to specific demographics. This is done through an interdisciplinary convergence of key technological advancements from scalable hierarchical system architectures, cloud computing, dynamic cache hierarchies, and distributed virtualization. Architecture and implementation considerations are presented, particularly for Buddhi Edge which instantiates the Jnana Edge framework in the educational scope. Future directions are also suggested.},
keywords={Servers;Communities;Software;Videos;Internet;Libraries;Synchronization;Virtual machines;Education;Content delivery networks;Distributed data centers;Filtering;Caching;Cloud computing;Virtualization;Software defined networking;Network functions virtualization;Disconnected Operations;Software Containers},
doi={10.1109/T4E.2014.35},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9926586,
author={Fajardo, Jose Manuel and Roldan, Felipe González and Realpe, Sebastian and Hernández, Juan D. and Ji, Ze and Cardenas, Pedro-F.},
booktitle={2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)},
title={FRobs_RL: A Flexible Robotics Reinforcement Learning Library},
year={2022},
volume={},
number={},
pages={1104-1109},
abstract={Reinforcement learning (RL) has become an interesting topic in robotics applications as it can solve complex problems in specific scenarios. The small amount of RL-tools focused on robotics, plus the lack of features such as easy transfer of simulated environments to real hardware, are obstacles to the widespread use of RL in robotic applications. FRobs_RL is a Python library that aims to facilitate the implementation, testing, and deployment of RL algorithms in intelligent robotic applications using robot operating system (ROS), Gazebo, and OpenAI Gym. FRobs_RL provides an Application Programming Interface (API) to simplify the creation of RL environments, where users can import a wide variety of robot models as well as different simulated environments. With the FRobs_RL library, users do not need to be experts in ROS, Gym, or Gazebo to create a realistic RL application. Using the library, we created and tested two environments containing common robotic tasks; one is a reacher task using a robotic manipulator, and the other is a mapless navigation task using a mobile robot. The library is available in GitHub 1.},
keywords={Automation;Navigation;Operating systems;Reinforcement learning;Libraries;Task analysis;Robots;Deep Learning Methods;Reinforcement Learning;Software Architecture for Robotic and Automation},
doi={10.1109/CASE49997.2022.9926586},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{8103698,
author={Labyntsev, A. V. and Poveshenko, L. I.},
booktitle={2017 Radiation and Scattering of Electromagnetic Waves (RSEMW)},
title={The method of synthesis of microstrip filters using HFSS software package},
year={2017},
volume={},
number={},
pages={443-445},
abstract={This paper examines the technique of designing microstrip filters with compact structure and their implementation in HFSS software package. Presented the results of designing of the specific microstrip comb filter, which confirm the accuracy and efficiency of the synthesis method used to design compact selective structures.},
keywords={Resonator filters;Microstrip filters;Band-pass filters;Resonators;Microwave filters;Passband;Attenuation;filter 1;microstrip 2;synthesis 3;designing 4},
doi={10.1109/RSEMW.2017.8103698},
ISSN={},
month={June},}
@INPROCEEDINGS{534132,
author={Jian Chen and Iwan Tjuwito Chau},
booktitle={Proceedings of 1996 Australian Software Engineering Conference},
title={The Hierarchical Dependence Diagram: improving design for reuse in object-oriented software development},
year={1996},
volume={},
number={},
pages={155-166},
abstract={Object-oriented paradigm promises a high level of reusability in software development. However, by just selecting an object-oriented programming language does not guarantee achieving highly reusable software components. Reusable components have to be designed carefully from the early stage of software development. Among many proposed guidelines for improving software reusability, "class independence" is regarded as an important criterion. The guidelines in this category state that the less dependence the class is, the more reusable the class is. However we argue that the use of these guidelines is often very difficult to follow consistently within a group of designers during the design process. This is because the implementation of such guidelines is highly based on individual designer's interpretation and experience. Another problem is that such guidelines are difficult to apply to a large software system, which may consist of hundreds or even thousands of classes. This paper describes a new notation, called the Hierarchical Dependence Diagram (HDD), to support a more systematic use of "components independence" guidelines by extending reusable classes to "clusters", "libraries", and "platforms". Our work establishes a solid basis for tool support for improving reusability and can be more effectively applied to the development of large object-oriented software systems.},
keywords={Guidelines;Software reusability;Process design;Object oriented programming;Software systems;Solids;Accidents;Software design;Proposals;Software standards},
doi={10.1109/ASWEC.1996.534132},
ISSN={},
month={July},}
@INPROCEEDINGS{7984476,
author={Tanev, Georgi and Madsen, Jan},
booktitle={2017 Symposium on Design, Test, Integration and Packaging of MEMS/MOEMS (DTIP)},
title={A correct-by-construction design and programming approach for open paper-based digital microfluidics},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Advances in microfluidic research have allowed digital microfluidic (DMF) chips to be rapid prototyped using inexpensive materials and simple fabrication processes to the extend where the time spend on chip design can be significantly longer than the time required for fabrication. The growing need for application specific DMF chips challenges efficient handling of the increasing chip design and programming complexity. To address this, we propose a correct-by-construction modular chip design approach, which allows chips to be constructed from a component library and verified by simulation before fabrication. After fabrication, the chip is operated from a smartphone by remote instrumentation of a portable DMF chip control device. By combining structured design techniques with custom developed hardware and software tools, we present a full end-to-end solution for fast DMF chip design, simulation and operation.},
keywords={Electrodes;Chip scale packaging;Layout;Fabrication;Substrates;Routing;Complexity theory},
doi={10.1109/DTIP.2017.7984476},
ISSN={},
month={May},}
@INPROCEEDINGS{4137400,
author={Agarwal, Naresh Kumar and Poo, Danny C. C. and Yong, Teo Keng},
booktitle={2006 13th Asia Pacific Software Engineering Conference (APSEC'06)},
title={Component-based Development of MILLS: A Case Study in the development of an Inter-library Loan Software System},
year={2006},
volume={},
number={},
pages={37-44},
abstract={Component-based software development (CBSD) is based on the idea of developing software systems by selecting appropriate off-the-shelf components and integrating them under a specified architecture. Such an approach prevents a software developer from having to reinvent the wheel, reduces software development cost and time, and promotes flexibility and maintainability. In this paper, we describe the application of CBSD in developing a system for automated inter-library loans between the libraries of two major universities of Singapore. Currently, inter-library loan (ILL) is a cumbersome and manual process. Our system helps promote resource-sharing and interoperability and reduces the difficulties involved in the current manual loan system between libraries. Specifically, we describe the CBSD approach, present the design and implementation of the MILLS (managing inter-library loan services) system, and describe how MILLS was developed taking the CBSD approach into consideration. The lessons learnt from this case should be of value to software developers.},
keywords={Milling machines;Software systems;Programming;Software libraries;Computer architecture;Software maintenance;Wheels;Costs;Application software;Educational institutions},
doi={10.1109/APSEC.2006.28},
ISSN={1530-1362},
month={Dec},}
@INPROCEEDINGS{826174,
author={Acheson, D.C.},
booktitle={Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.99CH37035)},
title={Utilizing parametric modeling design software in the motor manufacturing industry},
year={1999},
volume={},
number={},
pages={23-27},
abstract={In today's global economy, every advantage must be utilized to remain competitive. Reduced product development times have become a critical component in the matrix of bringing quality consumer goods to market. This paper suggests the implementation of 3 dimensional mechanical computer aided design (MCAD) software (specifically parametric packages) as well as other technologies that are shaping the way we will do business in the new millennium. In addition to MCAD tools, collaborative design environments (not based on geographical constraints) are rapidly becoming the standard corporate model. Namely, collaborative Internet environments. It should be obvious that the Internet is merely in its infancy stage at this point and is poised to weave itself into every corner of the business sector (and much of our personal lives as well). An additional focus of this paper is to provide background information on several new technologies that should be considered for use in virtually all design and manufacturing facilities.},
keywords={Parametric statistics;Software design;Business;Internet;Product development;Software packages;Packaging;Collaborative tools;Collaboration;Production facilities},
doi={10.1109/EEIC.1999.826174},
ISSN={0362-2479},
month={Oct},}
@INPROCEEDINGS{4722020,
author={Wang, Bin and Sheng, Jinfang},
booktitle={2008 International Conference on Computer Science and Software Engineering},
title={Extending FCD Process to Support COTS Selection},
year={2008},
volume={2},
number={},
pages={139-142},
abstract={In large software system, components depend on each other and should not be evaluated individually. This paper proposes a new process for multiple COTS selection based on extension of a proven system decomposition technique FCD. During the process of decomposition, local requirements are allocated into functional modules as local evaluation criteria for COTS candidates while crosscutting requirements are considered later in global selection. Due to the hierarchical structure of FCD, COTS products with varying granularities are considered. COTS candidates are evaluated through analyzing the gap between COTS features and requirements and fitness score is calculated based on the gap and adjustment cost which are measured by function points. Those COTS products with fitness score higher than a pre-defined threshold keep going into the global selection phase. In global selection, combinations of candidate COTS products for modules are evaluated based on crosscutting requirements.},
keywords={Software systems;Programming;Guidelines;Computer science;Software engineering;Information science;Cost function;Iterative methods;Aggregates;Software development management;COTS-based software development;COTS selection process;COTS evaluation;system decomposition},
doi={10.1109/CSSE.2008.1153},
ISSN={},
month={Dec},}
@ARTICLE{7325198,
author={Fysarakis, Konstantinos and Mylonakis, Damianos and Manifavas, Charalampos and Papaefstathiou, Ioannis},
journal={IEEE Software},
title={Node.DPWS: Efficient Web Services for the Internet of Things},
year={2016},
volume={33},
number={3},
pages={60-67},
abstract={Interconnected computing systems in various forms will soon permeate our lives, realizing the Internet of Things (IoT) and letting us enjoy novel, enhanced services that promise to improve our everyday life. Nevertheless, this new reality introduces significant challenges in terms of performance, scaling, usability, and interoperability. Leveraging the benefits of service-oriented architectures (SOAs) can help alleviate many of the issues that developers, implementers, and users alike must face in the context of the IoT. Node.DPWS is a novel implementation of the Devices Profile for Web Services (DPWS) based on the Node.js platform. It comprises the first set of DPWS libraries available to Node.js developers and can be used to deploy lightweight, efficient, and scalable Web services over heterogeneous nodes, including devices with limited resources. A performance evaluation on typical embedded devices validated the benefits of Node.DPWS compared to alternative DPWS libraries.},
keywords={Libraries;Java;Performance evaluation;Context awareness;Interoperability;Service-oriented architecture;Internet of things;Web services;Software development;Ubiquitous computing;Web services;development tools;software libraries;software development;standards;ubiquitous computing;software engineering;DPWS;Devices Profile for Web Services;Node.DPWS;Node.js},
doi={10.1109/MS.2015.155},
ISSN={1937-4194},
month={May},}
@INPROCEEDINGS{1005035,
author={Cabrera, A. and Sanchez-Solano, S. and Senhadji, R. and Barriga, A. and Jimenez, C.J.},
booktitle={2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291)},
title={Hardware/software codesign methodology for fuzzy controller implementation},
year={2002},
volume={1},
number={},
pages={464-469 vol.1},
abstract={Describes a HW/SW codesign methodology for the implementation of fuzzy controllers on a platform composed of a general-purpose microcontroller and specific processing elements implemented on FPGAs or ASICs. The different phases of the methodology, as well as the CAD tools used in each design stage, are presented, with emphasis on the fuzzy system development environment Xfuzzy. Also included is a practical application of the described methodology for the development of a fuzzy controller for a dosage system.},
keywords={Hardware;Fuzzy control;Fuzzy systems;Control systems;Computer architecture;Microcontrollers;Fuzzy logic;Field programmable gate arrays;Design automation;Functional programming},
doi={10.1109/FUZZ.2002.1005035},
ISSN={},
month={May},}
@INPROCEEDINGS{527430,
author={Petrosjanc, K.O. and Kharitonov, I.A. and Rybov, N.I. and Maltcev, P.P.},
booktitle={Proceedings of EURO-DAC. European Design Automation Conference},
title={Software system for semiconductor devices, monolith and hybrid IC's thermal analysis},
year={1995},
volume={},
number={},
pages={360-365},
abstract={A three level software system for thermal analysis of semiconductor devices, one-chip monolith IC's, multi-chip modules (MCM) and hybrid IC's is presented. For each design level the 3D temperature simulators are described to analyze the steady state and transient thermal behavior and connect the design results with the device and/or IC layout and packaging constructions. Practical examples are discussed illustrating the possibilities of developed techniques and software tools.},
keywords={Software systems;Semiconductor devices;Hybrid integrated circuits;Monolithic integrated circuits;Temperature;Analytical models;Steady-state;Transient analysis;Integrated circuit layout;Integrated circuit packaging},
doi={10.1109/EURDAC.1995.527430},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{713561,
author={Evered, M.},
booktitle={Proceedings. Technology of Object-Oriented Languages. TOOLS 24 (Cat. No.97TB100240)},
title={Unconstraining genericity},
year={1997},
volume={},
number={},
pages={340-349},
abstract={Generic classes and especially generic collection libraries can be of great benefit for efficient software production. Constrained genericity is used to guarantee that the type provided as a parameter to a generic class such as a sorted list will offer the methods that class requires. We argue that constrained genericity is not really the appropriate mechanism for this purpose since it restricts a generic class to one kind of use for each element type. We introduce the concept of 'generic procedure parameters' which allow the properties of a collection class to be specified in the instantiation rather than via the properties of the elements. We show that the concept is very efficiently implementable, more powerful than constrained genericity and more useful for the practical construction of complex data collections.},
keywords={Proposals;Java;Production;Software reusability;Object oriented programming;Packaging;Safety;Data structures;Software libraries;Computer languages},
doi={10.1109/TOOLS.1997.713561},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6418361,
author={Colombo, Tommaso and Vandelli, Wainer},
booktitle={2012 18th IEEE-NPSS Real Time Conference},
title={Novel, highly-parallel software for the online storage system of the ATLAS experiment at CERN: Design and performances},
year={2012},
volume={},
number={},
pages={1-6},
abstract={The ATLAS experiment observes proton-proton collisions delivered by the LHC accelerator at CERN. The ATLAS Trigger and Data Acquisition (TDAQ) system selects interesting events on-line in a three-level trigger system in order to store them at a budgeted rate of several hundred Hz, for an average event size of ~1.5 MB. This paper focuses on the TDAQ data-logging system and in particular on the implementation and performance of a novel software design, reporting on the effort of exploiting the full power of multi-core hardware. In this respect, the main challenge presented by the data-logging workload is the conflict between the largely parallel nature of the event processing, including the recently introduced on-line event-compression, and the constraint of sequential file writing and checksum evaluation. This is further complicated by the necessity of operating in a fully data-driven mode, to cope with continuously evolving trigger and detector configurations. In this paper we will briefly discuss our development experience using recent concurrency-oriented libraries. We will then concentrate on the results of performance measurements performed on the current data-logging hardware. We will show that, even in the worst workload, the new parallel design is able to compete with the previous single-threaded one, while it is outperforming it in more favourable, realistic workloads. We will as well demonstrate the minimal overhead introduced by the above parallel techniques, considering the whole data-logging software performances with respect to the bare processing speed on the same hardware. Finally, we will discuss the effects of simultaneous multi-threading technologies, as found on recent CPUs. The data-logging operation in fact, mixing data processing and I/O, allows to efficiently exploit the features provided by these technologies.},
keywords={Instruction sets;Writing;Throughput;Hardware;Data acquisition;Large Hadron Collider;Production systems},
doi={10.1109/RTC.2012.6418361},
ISSN={},
month={June},}
@INPROCEEDINGS{8589335,
author={Wang, Yi-Lin and Wang, Jun},
booktitle={2018 9th International Conference on Information Technology in Medicine and Education (ITME)},
title={Construction of Interlibrary Loan Information System Based on SaaS Mode},
year={2018},
volume={},
number={},
pages={432-436},
abstract={In order to increase sharing level and effect of books and information between libraries, construction of books-checkout information system in the interlibrary using the system architecture of SaaS (Software as a Service), books- checkout information system consists of four modules, including administrator management, user management, function management and literature management. The system structure and module design of information system software are also introduced in detail, and function analysis of each module are made, task content of each module is designed, the relation between entity class and attribute involved in information system are demonstrated, and system class diagram is listed, finally main module function of information system is implemented by Java Web technology and mysql database},
keywords={Libraries;Information systems;Databases;Software as a service;Java;Tools;information system;books checkout library},
doi={10.1109/ITME.2018.00103},
ISSN={2474-3828},
month={Oct},}
@ARTICLE{5570674,
author={Yen, Ruey-Fong and Kim, Yongmin},
journal={IEEE Transactions on Education},
title={Development and Implementation of an Educational Simulator Software Package for a Specific Microprogramming Architecture},
year={1986},
volume={E-29},
number={1},
pages={1-11},
abstract={Microprogramming is one technique for designing the control unit of a digital computer or computer-based instrument. It has become more widely used than a conventional hardwired logic design technique due to its flexibility and simplicity. We have developed an educational software package for the microprogramming simulation based on a computer architecture defined in a popular undergraduate computer engineering textbook [1]. This software package consists of an assembler, a compiler, and a simulator. The assembler translates a conventional assembly-language program into a macro object file, while the compiler compiles a microprogram into a micro object file. The simulator shows how a macroinstruction is interpreted by executing a series of microinstructions. The simulator is interactive, flexible, and easy to use. This software package, written in standard Pascal, is available for distribution to interested institutions.},
keywords={Registers;Computers;Microprogramming;Computer architecture;Clocks;Logic gates;Software packages},
doi={10.1109/TE.1986.5570674},
ISSN={1557-9638},
month={Feb},}
@INPROCEEDINGS{7863680,
author={Ahmad, Abdel-Mehsen and Majzoub, Roba Al and Charanek, Ola},
booktitle={2016 2nd International Conference on Open Source Software Computing (OSSCOM)},
title={3D gesture-based control system using processing open source software},
year={2016},
volume={},
number={},
pages={1-6},
abstract={The following paper discusses the design and implementation of a 3D gesture-based control system that can substitute any complex human-machine interface with a simpler and more familiar one. This system that can be used by any user disregarding his/her background (age, education, health, language etc....), making it dependent on nothing more than the movements of the user's hands, thus allowing them to be free from all hardware while interfacing, and making the system surpass in its simplicity other systems that include held or touched interfaces. It utilizes the Kinect sensor's image input parts (IR projector and IR camera) for computer vision along with an open source software called Processing for reception and analysis of input data to decision making on what actions and steps to perform, and even for communicating with the database. A MySQL database will be responsible for holding the information of the system and to handle them (adding, deleting, retrieving, etc....). Even though the system will be designed for a library to display information about the books available in it, however the proposed system design will be broad enough to allow its implementation in many other domains, making people's lives more efficient and innovative. Implementation steps are listed along with a detailed explanation of how the system works. The simulation results showing the system performance in different environment conditions and some screenshots are also displayed.},
keywords={Sprites (computer);Libraries;Three-dimensional displays;Control systems;Two dimensional displays;Sensors;Thumb;Open Source;Kinect;Gesture-Based Control;Processing Software;Computer Vision;MySQL},
doi={10.1109/OSSCOM.2016.7863680},
ISSN={},
month={Dec},}
@INPROCEEDINGS{4690636,
author={Zhang, Xin and Li, Zhongjie and Sun, Wei and Jiang, Zhongbo and Adams, Jonathan and Verschueren, Paul},
booktitle={2008 IEEE International Conference on e-Business Engineering},
title={Applying Pattern Approach for Solution Architecture Design: A Case Study in Retail Solution},
year={2008},
volume={},
number={},
pages={351-358},
abstract={Architecture design is an essential phase in software engineering. To effectively re-use pre-verified knowledge is critical for design high-quality architecture. Among several different approaches, architectural patterns are widely investigated as they capture the fundamental structural and behavioral principles of architecture design. Although a lot of patterns have already been defined, the application of patterns is still far from satisfaction because of lacking well-organized framework. In this paper, we introduce the IBM pattern for e-business, which provides a layered framework to organize e-business patterns and also a methodology to apply these patterns systematically across different phases of architecture design. We report a real case study of applying IBM pattern for e-business in designing a retail solution.},
keywords={Computer architecture;Application software;Software systems;Best practices;Design engineering;Software engineering;Software packages;Packaging;Context;Guidelines;pattern;architecture},
doi={10.1109/ICEBE.2008.83},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6832176,
author={Bradatsch, Christian and Kluge, Florian and Ungerer, Theo},
booktitle={2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing},
title={A Cross-Domain System Architecture for Embedded Hard Real-Time Many-Core Systems},
year={2013},
volume={},
number={},
pages={2034-2041},
abstract={The EC project parMERASA investigates techniques for the parallelization of industrial real-time applications from automotive, avionic, and construction machinery domains. The aim is to execute such applications on many-core processors with up to 64 cores. The system software plays a key role in the deployment of applications. However, requirements of application domains differ widely, and thus no general solution can be implemented. In this paper we present the cross-domain system architecture utilized in the parMERASA project to provide Runtime Environments (RTEs) for the three different domains. The approach eases the implementation of domain-specific RTEs through a generic kernel library that provides basic hardware abstractions and timing-analyzable synchronization mechanisms.},
keywords={Kernel;Computer architecture;Hardware;Libraries;Synchronization;automotive;avionics;construction machinery;hard real-time;many-core;system architecture;cross-domain},
doi={10.1109/HPCC.and.EUC.2013.293},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8405331,
author={Masek, Michal and Rymus, Jaroslav and Hazdra, Pavel and Capek, Miloslav},
booktitle={2018 22nd International Microwave and Radar Conference (MIKON)},
title={Implementation of the theory of characteristic modes into antenna modeling tools AToM and visual antenna},
year={2018},
volume={},
number={},
pages={7-10},
abstract={Two software packages suitable for the modeling of antennas and scatterers are presented. The approach of modal decomposition utilized leads to a better understanding of the radiation properties of the antennas studied and promises to reduce the length of the design process. Two examples are shown and the results are compared to an analytical solution, as well as to results from other simulators.},
keywords={Visualization;Matlab;Solid modeling;Method of moments;Geometry;Antenna theory;Numerical analysis;computational electromag-netics;characteristic modes;electrically small antennas;software packages},
doi={10.23919/MIKON.2018.8405331},
ISSN={},
month={May},}
@INPROCEEDINGS{9268283,
author={Nakamura, Matthew and Hafner, Noah and Missaghi, Baseem and Massagram, Wansuree and Brown, Joseph},
booktitle={2020 17th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
title={Reconfigurable Packages for Low Cost Sensor Prototyping},
year={2020},
volume={},
number={},
pages={53-58},
abstract={Presented are sensor packages for prototyping sensors and network configurations to support humanitarian assistance and disaster relief efforts. Hardware prototypes were assembled using commercially available modules in 3D-printed enclosures. The cost of components for a single unit is approximately USD 130. Hardware and software implementation for mobile sensors and network gateways is described with cost vs. capability design decisions highlighted. Results are presented from exercises in Hawaii and Thailand with 15 sensor nodes collecting environmental data and position while worn by people or attached to vehicles. Personnel tracking capability is demonstrated over a Long Range (LoRa) data link. Sensor node current consumption averaged 76 mA in full active tracking mode. Fifteen sensor nodes each transmitted four data update messages per minute to three gateway nodes with single-channel radios. The aggregate message rate of 1 msg/s was above the capacity limit of a single gateway, and sensor nodes automatically switched to use all the gateways.},
keywords={Pupils;Pins;Hardware;Switches;Personnel;Libraries;Logic gates;wireless sensor network;environmental monitoring;3D-printing;low-cost;hardware and software integration},
doi={10.1109/JCSSE49651.2020.9268283},
ISSN={2642-6579},
month={Nov},}
@INPROCEEDINGS{7412294,
author={Yen, Freedman and Hung, Leo and Kao, Nicholas and Jiang, Don Son},
booktitle={2015 IEEE 17th Electronics Packaging and Technology Conference (EPTC)},
title={Mold-flow study for different bump height, bump pitch and die size in FCCSP with molded underfill technology},
year={2015},
volume={},
number={},
pages={1-6},
abstract={Currently electrical products such as smart phone and tablet, light weight and thin feature of them are definitely required. To achieve several requirements, size of IC package assembled in limiting space become more crucial and development orientated. Microelectronics products of FCCSP (Flip Chip-Chip Scale Package) with more increasing challenges are countered to assure molding capability with rapidly advancing encapsulation process in flip chip technology such as decreasing bump height and bump pitch, especially when Molded Underfill (MUF) is used and in particular during transfer molding process. Moldflow simulation is valid method to predict and resolve in air void entrapment severely occurred under the die (air void concentrated within bump region). Optimum solutions would be found out for air void risk free of MUF FCCSP with different bump structure or die size design, which can reduce development cycle time before mass production. In this paper, two molding flow factors for void prediction will be performed by moldflow simulation software. One of the two is about characteristics of bump structure including bump height and bump pitch. By varying different bump dimensions, melt-front position of molding frontier is affected in relevantly significant. In addition, the other factor is package with different die size design. Die size also presents obvious influence on melt-front pattern while molding compound flow through region under die. From this study, some results can be concluded for getting improvement on mold flow performance of MUF FCCSP package during molding process. The first of all is MUF FCCSP with the 58um bump height and 100um bump pitch will perform low air void risk since there is more space under die letting compound flow though more easily. Based on the same concept mention previously, the second one is smaller die arrangement that also can be benefit to compound flowing and get better pattern of melt-front. Finally, the simulation results provide a prediction guideline that MUF FCCSP with suitable bump height/pitch and die size structure condition to prevent void issue occur under die region during molding process.},
keywords={Viscosity;Substrates;Temperature measurement;Compounds;Curing;Kinetic theory;Transfer molding},
doi={10.1109/EPTC.2015.7412294},
ISSN={},
month={Dec},}
@INPROCEEDINGS{4228628,
author={Huynh, Sunny and Cai, Yuanfang},
booktitle={First International Workshop on Assessment of Contemporary Modularization Techniques (ACoM '07)},
title={An Evolutionary Approach to Software Modularity Analysis},
year={2007},
volume={},
number={},
pages={6-6},
abstract={Modularity determines software quality in terms of evolvability, changeability, maintainability, etc. and a module could be a vertical slicing through source code directory structure or class boundary. Given a modularized design, we need to determine whether its implementation realizes the designed modularity. Manually comparing source code modular structure with abstracted design modular structure is tedious and error-prone. In this paper, we present an automated approach to check the conformance of source code modularity to the designed modularity. Our approach uses design structure matrices (DSMs) as a uniform representation; it uses existing tools to automatically derive DSMs from the source code and design, and uses a genetic algorithm to automatically cluster DSMs and check the conformance. We applied our approach to a small canonical software system as a proof of concept experiment. The results supported our hypothesis that it is possible to check the conformance between source code structure and design structure automatically, and this approach has the potential to be scaled for use in large software systems.},
keywords={Software systems;Genetic algorithms;Algorithm design and analysis;Software quality;Software design;Java;Software maintenance;Computer science;Performance analysis;Packaging},
doi={10.1109/ACOM.2007.1},
ISSN={},
month={May},}
@INPROCEEDINGS{5061996,
author={Dale, C. and Liu, J.},
booktitle={IEEE INFOCOM 2009},
title={apt-p2p: A Peer-to-Peer Distribution System for Software Package Releases and Updates},
year={2009},
volume={},
number={},
pages={864-872},
abstract={The Internet has become a cost-effective vehicle for software development and release, particular in the free software community. Given the free nature of this software, there are often a number of users motivated by altruism to help out with the distribution, so as to promote the healthy development of this voluntary society. It is thus naturally expected that a peer-to- peer distribution can be implemented, which will scale well with large user bases, and can easily explore the network resources made available by the volunteers. Unfortunately, this application scenario has many unique characteristics, which make a straightforward adoption of existing peer-to-peer systems for file sharing (such as BitTorrent) suboptimal. In particular, a software release often consists of a large number of packages, which are difficult to distribute individually, but the archive is too large to be distributed in its entirety. The packages are also being constantly updated by the loosely-managed developers, and the interest in a particular version of a package can be very limited depending on the computer platforms and operating systems used. In this paper, we propose a novel peer-to-peer assisted distribution system design that addresses the above challenges. It enhances the existing distribution systems by providing compatible and yet more efficient downloading and updating services for software packages. Our design leads to apt-p2p, a practical implementation that extends the popular apt distributor. apt-p2p has been used in conjunction with Debian-based distribution of Linux software packages and is also available in the latest release of Ubuntu. We have addressed the key design issues in apt-p2p, including indexing table customization, response time reduction, and multi-value extension. They together ensure that the altruistic users' resources are effectively utilized and thus significantly reduces the currently large bandwidth requirements of hosting the software, as confirmed by our existing real user statistics gathered over the Internet.},
keywords={Peer to peer computing;Software packages;Packaging;Internet;Vehicles;Programming;Application software;Operating systems;Lead;Linux},
doi={10.1109/INFCOM.2009.5061996},
ISSN={0743-166X},
month={April},}
@ARTICLE{9211422,
author={Peach, Gregor and Pan, Runyu and Wu, Zhuoyi and Parmer, Gabriel and Haster, Christopher and Cherkasova, Ludmila},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
title={eWASM: Practical Software Fault Isolation for Reliable Embedded Devices},
year={2020},
volume={39},
number={11},
pages={3492-3505},
abstract={As we connect more microcontrollers to the Internet and employ them to control the physical world around us, their reliability and security are increasingly important. Many microcontrollers provide limited facilities for hardware isolation, and real-time OSes offer custom APIs, that require coupling applications into the ecosystem and abstractions of that specific OS to leverage isolation. This article investigates the use of software sandboxing of applications to support isolation for resource-constrained devices. Toward this, we detail the design of eWASM, a processes abstraction that adapts a popular sandbox, Wasm, for microcontrollers. eWASM provides a runtime to constrain memory accesses and control flow, enabled by our aWsm Wasm compiler. We discuss and evaluate its multiple implementations that effectively trade time and space, optimizing for the constraints of embedded systems. This enables popular languages (e.g., C) to be effectively sandboxed by software. We demonstrate performance within 40% of native C on Polybench. We believe this is a practical and compelling result for many IoT domains, and it represents the first compiled sandboxing environment for microcontrollers. We show that restrictions of the current Wasm specification lead to significant memory consumption and provide suggestions for the creation of an embedded-specific Wasm variant.},
keywords={Microcontrollers;Memory management;Safety;Hardware;Runtime;Embedded systems;Control-flow integrity (CFI);embedded systems;sandboxing;software fault isolation (SFI);Web assembly},
doi={10.1109/TCAD.2020.3012647},
ISSN={1937-4151},
month={Nov},}
@INPROCEEDINGS{9848649,
author={Smagin, Alexey},
booktitle={2022 VIII International Conference on Information Technology and Nanotechnology (ITNT)},
title={About semantic segmentation of meshed fencing constructions and searching breaks},
year={2022},
volume={},
number={},
pages={1-5},
abstract={The issues of automated monitoring of the condition of mesh enclosing structures used on farms producing marine biological resources are considered. An algorithm for identifying breaks in mesh fencing underwater conditions is proposed and implemented by a complex of programs using Python with the OpenCV computer vision library and U-net CNN. The results of testing the algorithm are presented. It is shown that computer vision effectively copes with the classification of network cells in noisy and medium-noisy underwater images.},
keywords={Image segmentation;Computer vision;Software packages;Semantics;Software algorithms;Search problems;Classification algorithms;algorithm;computer vision;semantic segmentation;machine learning;software},
doi={10.1109/ITNT55410.2022.9848649},
ISSN={},
month={May},}
@INPROCEEDINGS{738497,
author={Fiutem, R. and Antoniol, G.},
booktitle={Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272)},
title={Identifying design-code inconsistencies in object-oriented software: a case study},
year={1998},
volume={},
number={},
pages={94-102},
abstract={Traceability is a key issue to ensure consistency among software artifacts of subsequent phases of the development cycle. However few works have addressed the theme of tracing object oriented design into its software. This paper presents an approach to check the compliance of OO design with respect to source code. The process works on design artefacts expressed in OMT notation and accepts C++ source code. It recovers an "as is" design from the code, compares recovered design with the actual design and helps the user to deal with inconsistency by pointing out regions of code which do not match with design. The recovery process exploits regular expression and edit distance to bridge the gap between code and design. Results as well as consideration related to presentation issues are reported in the paper.},
keywords={Computer aided software engineering;Signal design;Visualization;Electrical capacitance tomography;Software maintenance;Time to market;Layout;Inspection;Computer industry;Software libraries},
doi={10.1109/ICSM.1998.738497},
ISSN={1063-6773},
month={Nov},}
@INPROCEEDINGS{365783,
author={Itoh, K. and Tamura, Y. and Kishima, S.},
booktitle={Proceedings of 1994 3rd International Conference on Software Reuse},
title={Triadic domain model-based development of software systems},
year={1994},
volume={},
number={},
pages={196-197},
abstract={The authors present the Triadic Domain Model (TDM)-based system development environment. The main purpose is to integrate system specification, system design and system implementation of a software system using domain specific properties. TDM consists of a domain problem model, domain product model and domain process model.<>},
keywords={Software systems;Performance analysis;Time division multiplexing;System analysis and design;Software reusability;Data structures;Libraries;Tellurium;Productivity;Application software},
doi={10.1109/ICSR.1994.365783},
ISSN={},
month={Nov},}
@ARTICLE{56301,
author={Brittain, D.L.},
journal={IEEE Computer Graphics and Applications},
title={Portability of interactive graphics software},
year={1990},
volume={10},
number={4},
pages={70-75},
abstract={One solution to obtaining a portable graphics architecture is presented. By abstracting the functionality present in most 3-D graphics systems and augmenting it with advanced rendering features, a highly portable, efficient, and modern graphics architecture for interactive 3-D graphics applications (including modeling, animation, and scientific visualization) is obtained. Using appropriate object-oriented design procedures ensures the efficiency, maintainability, and portability of the architecture. The design and implementation of the graphics system used to achieve this high degree of portability are described.<>},
keywords={Workstations;Application software;Sun;Computer architecture;Hardware;Computer graphics;Iris;Computer aided manufacturing;Libraries;Design optimization},
doi={10.1109/38.56301},
ISSN={1558-1756},
month={July},}
@INPROCEEDINGS{6719095,
author={Iyapparaja, M. and Sureshkumar, S.},
booktitle={IET Chennai 3rd International on Sustainable Energy and Intelligent Systems (SEISCON 2012)},
title={Coupling and cohesion metrics in Java for adaptive reusability risk reduction},
year={2012},
volume={},
number={},
pages={1-6},
abstract={Software development has nowadays evolved into a extreme change that uses the best modules being run in various closed and open source software. Extracting the best component and fit them into an ongoing component based development software poses great challenges to run the software error free with desired outcomes. In this proposal we have introduced an `Intelligent Risk Analysis Model (IRAM) for reusability in developing component service oriented software, which are developed using eminent object oriented programming language paradigm Java. This model performs surfing operation into Java object oriented programming modules warehouse, which consists of several availability modules of various projects, and gives a list of suitable module. Those modules are tested on cohesion /coupling testing analysis to determine the individual strength and binding capacity of modules before performing Regression test. Final desirable outcomes are tested on performing regression test while integrating successful level module with domain being developed and proper deployment is made on successful expected outcome of the product. Risk analysis of software project is analyzed for transformation of reusability components risk before transformation Analysis, adaptable risk Analysis, and reusability risk Analysis for package in Java programming. In this paper IRAM model to focus Java package the domain and size of package, integration and dependency relationship of package, measuring the coupling and cohesion in risk metric for development and implementation of reusability package without any risk factor.},
keywords={Software reusability;Risk Analysis;Cohesion & Coupling;Packages;IRAM model},
doi={10.1049/cp.2012.2189},
ISSN={},
month={Dec},}
@ARTICLE{585500,
author={Wellings, A. and Burns, A.},
journal={IEEE Transactions on Software Engineering},
title={Implementing atomic actions in Ada 95},
year={1997},
volume={23},
number={2},
pages={107-123},
abstract={Atomic actions are an important dynamic structuring technique that aid the construction of fault-tolerant concurrent systems. Although they were developed some years ago, none of the well-known commercially-available programming languages directly support their use. This paper summarizes software fault tolerance techniques for concurrent systems, evaluates the Ada 95 programming language from the perspective of its support for software fault tolerance, and shows how Ada 95 can be used to implement software fault tolerance techniques. In particular, it shows how packages, protected objects, requeue, exceptions, asynchronous transfer of control, tagged types, and controlled types can be used as building blocks from which to construct atomic actions with forward and backward error recovery, which are resilient to deserter tasks and task abortion.},
keywords={Fault tolerant systems;Computer languages;Fault tolerance;Redundancy;Fault detection;Computer Society;Packaging;Protection;Error correction;Abortion},
doi={10.1109/32.585500},
ISSN={1939-3520},
month={Feb},}
@INPROCEEDINGS{6263759,
author={Fayez, Almohanad S. and Kaminski, Nicholas J. and Young, Alexander R. and Bostian, Charles W.},
booktitle={2012 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)},
title={Embedded SDR system design case study: An implementation perspective},
year={2012},
volume={},
number={},
pages={1-6},
abstract={Cognitive Radios (CRs) and Software Defined Radios (SDRs) have ubiquitous applications ranging from handheld to base station devices. In order to meet the computational requirements of such radios, computing heterogeneity, the mixed usage of General Purpose Processors (GPPs), Digital Signal Processors (DSPs), and Field-Programmable Gate Arrays (FPGAs), is attractive. Developing SDR and CR applications already requires a diverse set of skills, and computing heterogeneity further complicates the process. This paper presents a developmental workflow used successfully by the authors for SDR and CR application running on a platform combining DSP and GPP based processors. The paper discusses tools used to set up the platform, create compilation environment, develop code for GPP/DSP communication, integrate the DSP into GNU Radio, and use the environment to develop SDR/CR applications. It presents a case study showing how computing heterogeneity can be used to address diverse application needs.},
keywords={Digital signal processing;Program processors;Field programmable gate arrays;Finite impulse response filter;Libraries;Radio frequency;embedded sdr;system design;software defined radio;cognitive radio},
doi={10.1109/WoWMoM.2012.6263759},
ISSN={},
month={June},}
@INPROCEEDINGS{4526505,
author={Center, Kenneth B.},
booktitle={2008 IEEE Aerospace Conference},
title={Developing the Process Tools and Software Architecture for the PnPSat Initiative},
year={2008},
volume={},
number={},
pages={1-8},
abstract={Over the past few years, the Air Force Research Laboratories in Albuquerque, New Mexico have been leading the charge to establish a new paradigm for the satellite development process. Central to this development is the space plug&play avionics (SPA) standards, which define standard electrical, data, and mechanical interfaces for all components that are used to construct the system. "Components" consist of both hardware and software elements, all capable of being integrated and tested rapidly to create functional capability. It is envisioned that with the diligence being applied, it will ultimately be possible to draw from stock items at a depot to design, assemble, and launch a satellite in a matter of days. An essential enabling aspect of the process is a collection of highly interoperable software modules, conforming to the data portion of the SPA standards, which can be selected from a library based upon their ability to collectively meet a set of prescribed mission objectives. If properly constructed, the modules can self-configure on the data network - ideally without human intervention or modification. Abolishing the segment of the satellite life cycle associated with the development of flight software is one of the most critical goals to achieve if the "six-day-satellite" concept is to become reality. Design_Net Engineering has been active in the refinement of these standards, as well as a primary contributor to the development of a flight software architecture to validate the approach. We have also created a development environment that takes advantage of the network-based data standards to allow code to be written and tested without physical hardware. This capability, termed flight software in the loop (FSWIL), utilizes a robust simulation framework to present behavioral models of hardware devices to the software developer that are indistinguishable from the actual articles. The PnPSat program is an initiative that has been established by AFRL to serve as a technology demonstration for the SPA standards. Due to the fact that many of the core technologies were being matured in parallel, it became necessary to develop the FSWIL capability to allow software efforts to progress without a supporting hardware infrastructure. The tools have important implications for the community beyond PnPSat however, as they allow developers to write and test code (or hypothetical hardware models) remotely before installing new capability in the responsive space testbed (the home of the SPA initiative). This paper will describe the FSWIL tool as well as the SPA-based flight software architecture and implementation products that support the PnPSat program.},
keywords={Software architecture;Hardware;Standards development;Satellites;Aerospace electronics;Software standards;Laboratories;Software testing;Assembly;Software libraries},
doi={10.1109/AERO.2008.4526505},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{4217331,
author={Li, Min and Bougard, Bruno and Absar, Javed and Horlin, Francois and Van Der Perre, Liesbet and Catthoor, Francky},
booktitle={2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
title={Efficient QRD for SRI-RLS Based Equalization on Programmable Architecture},
year={2007},
volume={2},
number={},
pages={II-5-II-8},
abstract={Advanced adaptive filters have been shown to be very powerful for tracking time varying channels in various wireless communications system. However, the performance comes at the expense of highly resource-demanding implementations, especially in the context of programmable architecture based SDR. We present the optimizations for programmable implementation of QRD based SRI-RLS, which represents a large family of advanced adaptive filters. The key contribution of our work is to comprehensively and systematically remove the redundant operations in the QRD for SRI-RLS. Although most signal processing and scientific libraries implement householder reflection based QRD, we explore different alternatives and then choose given rotations based QRD to enable the aforementioned systematic redundancy removals. Our work significantly reduces the resource requirements (cycle count, energy consumption, etc.) of SRI-RLS implementation. Comparing to the widely accepted QRD implementation in numerical recipes, our work reduces 96.4% cycle-count on a typical baseband DSP (TI TMS320C6713), enabling efficient implementations. The paper shows that removing redundancy is very effective for modern statistical signal processing algorithms that largely rely on cascaded matrix operations.},
keywords={Adaptive filters;Time varying systems;Wireless communication;Context;Adaptive signal processing;Libraries;Reflection;Energy consumption;Baseband;Digital signal processing;Equalizer;QRD;DSP Implementation;Software Defined Radio},
doi={10.1109/ICASSP.2007.366158},
ISSN={2379-190X},
month={April},}
@INPROCEEDINGS{1285448,
author={Ozarin, N.},
booktitle={Annual Symposium Reliability and Maintainability, 2004 - RAMS},
title={Failure modes and effects analysis during design of computer software},
year={2004},
volume={},
number={},
pages={201-206},
abstract={Performing FMEA on computer software presents problems and challenges not found in FMEA of electronic hardware. Contractual directions are usually very limited or nonexistent, leaving the analyst to establish and tailor guidelines needed for a particular analysis. Where code is unavailable or off limits to the analysis, the FMEA is of limited usefulness but can still contribute to a more reliable system design. Unfortunately, many reliability analysts have more difficulty developing an approach to software analysis than doing it. An understanding of the software design process and a discussion of various approaches to software design FMEA is presented to make development of an appropriate approach and performance of the analysis itself easier to understand. Moving from the lowest level of analysis to the highest level typically from the method level to the module or package level - a FMEA becomes less accurate, less precise, and less informative, while the process becomes less difficult, less tedious, and less time-consuming. Moving from the lowest level of analysis to the highest also means a FMEA is based increasingly on the stated intent of the software designers and less on the actual product behavior. For any analysis above the code level, the analyst's conclusions about effects at each level is unfortunately be no better than the descriptions that the software designers provide.},
keywords={Failure analysis;Software design;Software performance;Performance analysis;Process design;Programming;Mission critical systems;Fault trees;Hardware;Guidelines},
doi={10.1109/RAMS.2004.1285448},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9581047,
author={Burdonov, Igor and Yevtushenko, Nina and Kossachev, Alexandr},
booktitle={2021 IEEE East-West Design & Test Symposium (EWDTS)},
title={Verifying Multiple Virtual Networks in Software Defined Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Software Defined Network (SDN) technology is one of the modern network virtualization technologies. When implementing a virtual network on the SDN data plane, undesired effects may occur: the appearance of undesired paths where packages can be sent, “looping” when the packages are infinitely cycled and infinitely cloned, duplicate paths when the host receives the same package several times. We show that these effects can occur for the joint implementation of several virtual networks even if the implementation of each separate virtual network does not cause these effects. A method for verifying the implementation of several virtual networks is proposed. A sufficient condition is established for the graph of physical connections when any set of virtual networks can be implemented without the occurrence of the above undesirable effects.},
keywords={Sufficient conditions;Software algorithms;Complexity theory;Software defined networking;Virtualization;Software Defined Networks (SDN);Network Virtualization;Graph paths;Edge Simple Paths;Arc Closure;Verification},
doi={10.1109/EWDTS52692.2021.9581047},
ISSN={2472-761X},
month={Sep.},}
@INPROCEEDINGS{8262556,
author={Sutrisno and Panduwinata, Frans and Yugopuspito, Pujianto},
booktitle={2017 International Conference on Soft Computing, Intelligent System and Information Technology (ICSIIT)},
title={Nanoservices as Generalization Services in Service-Oriented Architecture},
year={2017},
volume={},
number={},
pages={131-137},
abstract={In software methodology, a service is related to an application in internet technology whereas web-based application is popular in the service-oriented architecture. SOA is a framework for developing an application in the enterprise system. It builds and runs on top of a web-based technology. Each service represents a business activity, and the technology supports this services via an operation known as a web-service. Meanwhile, a microservice architecture is a fine-grained of the web service. So microservice is an approach in implementation phase of a SOA. It is a bottom-up approach in application software development that is potentially used for small company and focused on a specific product. In this paper, a nanoservice is introduced as an implication of transforming a web service into microservices that yields some similarities or intersection among microservices. We showed that a nanoservice is an existence of generalization of microservices, as web service API as an example.},
keywords={Service-oriented architecture;Computer architecture;Uniform resource locators;Servers;software methodology;nanoservice;microserv-ice;web-service;service-oriented architecture},
doi={10.1109/ICSIIT.2017.21},
ISSN={},
month={Sep.},}
@ARTICLE{5475204,
author={Ramírez-Hernández, José A. and Crabtree, Jason and Yao, Xiaodong and Fernandez, Emmanuel and Fu, Michael C. and Janakiram, Mani and Marcus, Steven I. and O'Connor, Matilda and Patel, Nipa},
journal={IEEE Transactions on Semiconductor Manufacturing},
title={Optimal Preventive Maintenance Scheduling in Semiconductor Manufacturing Systems: Software Tool and Simulation Case Studies},
year={2010},
volume={23},
number={3},
pages={477-489},
abstract={This paper presents the architecture and implementation of a preventive maintenance optimization software tool (PMOST), based on algorithms for the optimal scheduling of preventive maintenance (PM) tasks in semiconductor manufacturing operations. We also present results from four complex simulation case studies, based on real industrial data and employing full fab models, to illustrate the use, data needs and outcomes produced by PMOST. These results demonstrate significant improvements in tool production and consolidation of PM tasks. We give a description of the different software modules that compose PMOST, to provide guidelines as well as a template for other implementations of the PM optimization algorithms utilized by PMOST.},
keywords={Preventive maintenance;Job shop scheduling;Manufacturing systems;Software tools;Optimal scheduling;Software algorithms;Computer architecture;Scheduling algorithm;Pulp manufacturing;Semiconductor device manufacture;Optimal preventive maintenance (PM) scheduling;simulation case studies;software tool},
doi={10.1109/TSM.2010.2051731},
ISSN={1558-2345},
month={Aug},}
@INPROCEEDINGS{4296801,
author={Kurzak, Jakub and Buttari, Alfredo},
booktitle={15th Annual IEEE Symposium on High-Performance Interconnects (HOTI 2007)},
title={Introduction to Programming High Performance Applications on the CELL Broadband Engine},
year={2007},
volume={},
number={},
pages={11-11},
abstract={Summary form only given. Programming the STI CELL processor is about successfully exploiting its potential for delivering very high performance. The purpose of this tutorial is to give the programmer practical guidelines for achieving this goal. We begin by a brief overview of the main CELL architectural features and its software development environment. Then we discuss three basic aspects of CELL programming: SPE SIMD kernel development (vectorization), SPE parallelization and intra-chip communication. We show how high performance SPE kernels are created by replacing scalar operations with vector ones, heavily unrolling loops, and exploiting dual-issue nature of the SPE architecture. We explain coding using SIMD C language extensions (intrinsics), as well as using assembly language and discuss aspects specific to code development in assembly. We present static performance analysis using the spu-timing tool. The presentation of intra-chip communication follows, with emphasis on DMA communication both for bulk data transfers as well as for synchronization. We discuss message size and alignment restrictions, enforcing of message ordering using barrier and fence mechanisms and creation of complex data transfers using DMA lists. We conclude the topic with guidelines on implementing pipelined processing with direct local store to local store communication. We discuss basic profiling techniques using the SPE decrementer. We conclude with a set of practical tips and tricks and a list of "gotchas" or common rookie mistakes. A brief overview of academic and commercial CELL programming packages follows, and a discussion of a real life example - scanning network traffic using DFA- based string matching. The tutorial ends with a presentation of techniques for programming multi-CELL systems using message passing with MPI.},
keywords={Engines;Guidelines;Kernel;Assembly;Programming profession;Parallel programming;Computer architecture;Performance analysis;Packaging;Telecommunication traffic},
doi={10.1109/HOTI.2007.30},
ISSN={2332-5569},
month={Aug},}
@INPROCEEDINGS{7603867,
author={Li, Guoli and Zhang, Qian and Chen, Dong and Liu, Tong and Ma, Zhenglei and Sun, Lei and Ning, Qingchao},
booktitle={2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)},
title={Design and implementation of monitoring interface for combustion process using C# language},
year={2016},
volume={},
number={},
pages={1741-1743},
abstract={This paper introduces software for a monitoring system of the industrial furnace based on the c# language. Server and client interfaces are implied on the Windows's. Form class. The communication between the server and the client is realized though the socket class, which is included in the .NET class library. Most of the commonly useful information can be demonstrated in our system, such as gas concentration line charts, video monitoring data, the temperature pseudo-color figure, and so on. The gas concentration data value is stored in the database. Finally, a friendly man-machine interface which is able to collect, display, store and query field data is achieved.},
keywords={Software;Servers;Monitoring;Combustion;Furnaces;Temperature measurement;Protocols;c# language;software interface;gas curve;UDP;SQL server},
doi={10.1109/ICIEA.2016.7603867},
ISSN={2158-2297},
month={June},}
@INPROCEEDINGS{9265877,
author={Hu, Jun and Hu, Jiancheng and Wang, Wenxuan and Kang, Jiexiang and Wang, Hui and Gao, Zhongjie},
booktitle={2020 6th International Symposium on System and Software Reliability (ISSSR)},
title={Constructing Formal Specification Models from Domain Specific Natural Language Requirements},
year={2020},
volume={},
number={},
pages={52-60},
abstract={One important way to improve the quality of safety-critical software is to produce a good software requirement satisfying several key properties, such as: integrity, consistency, and well organized, etc. Our work is based on airborne software domain, and propose a framework to translate the software requirements, which are itemized with domain natural language in avionics, effectively into a formal specification model VRM (Variable Relation Model), which has table-style structures with formal semantics. Firstly, considering avionics domain characteristics, a domain concept library is established including different types of variables and concepts. Then, a set of domain-oriented requirements templates are defined, such as: general event/condition, display event/condition, etc. According to VRM model element semantics, three types model construction algorithms are designed to complete the translation automatically. And in the case study, the Engine Indication and Crew Warning System (EICAS) was selected to show how to construct formal models from natural language requirements.},
keywords={Software;Mathematical model;Libraries;Natural languages;Aerospace electronics;Semantics;Data models;safety-critical software;VRM;EICAS;domain template library;model transition},
doi={10.1109/ISSSR51244.2020.00017},
ISSN={},
month={Oct},}
@INPROCEEDINGS{37946,
author={Sullivan, M. and Anderson, D.},
booktitle={[1989] Proceedings. The 9th International Conference on Distributed Computing Systems},
title={Marionette: a system for parallel distributed programming using a master/slave model},
year={1989},
volume={},
number={},
pages={181-188},
abstract={Marionette, a software package for distributed parallel programming in an environment of networked heterogeneous computer systems is described. It uses a master/slave model in which otherwise sequential application programmes can invoke worker operations (asynchronous remote procedure calls executed by slave processes) and context operations (updates to slaves' process states). The master and slaves also interact through shared data structures that can be modified only by the master. The Marionette runtime system is a heterogeneous remote procedure call package. It maintains the consistency of shared data structures, recovers transparently from slave processor failure, and assigns operations to slaves. The Marionette system includes tools for debugging, automated compilation of program binaries for multiple architectures, and distributing binaries to remote file systems. Measurements of a UNIX-based implementation to Marionette and a parallel ray-tracing renderer are presented.<>},
keywords={Parallel programming;Master-slave;Data structures;Software packages;Computer networks;Concurrent computing;Distributed computing;Context modeling;Application software;Packaging},
doi={10.1109/ICDCS.1989.37946},
ISSN={},
month={June},}
@ARTICLE{642969,
author={Mirotznik, M.S. and Prather, D.},
journal={IEEE Spectrum},
title={How to choose electromagnetic software},
year={1997},
volume={34},
number={12},
pages={53-58},
abstract={The rapid growth in communication and high-speed electronics industries is demanding more-much more-of electromagnetic simulation software. Here, the authors describe how a range of packages is available not only to predict the electromagnetic behavior of today's very high-speed devices, but also to accurately analyze and help optimize a design before a physical prototype is built.},
keywords={High-speed electronics;Communication industry;Computer industry;Electronics industry;Electronics packaging;Electromagnetic devices;Electromagnetic analysis;Design optimization;Software prototyping;Prototypes},
doi={10.1109/6.642969},
ISSN={1939-9340},
month={Dec},}
@ARTICLE{747259,
author={Turletti, T. and Tennenhouse, D.},
journal={IEEE Communications Magazine},
title={Complexity of a software GSM base station},
year={1999},
volume={37},
number={2},
pages={113-117},
abstract={There is increasing interest in developing radio-based applications in software. The new architecture for implementing mobile telephony base stations has the potential of offering many benefits: great cost savings by using one transceiver per base transceiver station (BTS) instead of one per channel, tremendous flexibility by moving system-specific parameters to the digital part, and allowing the support of a wide range of modulation and coding schemes. A very important problem in designing software radio applications is the need to estimate the required complexity of processing to dimension systems. For example, with a software GSM BTS it is critical to estimate the number of channels that can be supported by a given processor configuration, and to predict the impact of future processor enhancements on its capacity. This article focuses on the design of a software implementation of a GSM BTS and proposes a platform-independent evaluation of its computational requirements based on SPEC benchmarks. It focuses on the design and performance of a library of software modules. Portability and computational requirements are discussed.},
keywords={GSM;Base stations;Application software;Transceivers;Software design;Computer architecture;Telephony;Digital modulation;Modulation coding;Software radio},
doi={10.1109/35.747259},
ISSN={1558-1896},
month={Feb},}
@INPROCEEDINGS{9613569,
author={Sonnleithner, Lisa and Wiesmayr, Bianca and Ashiwal, Virendra and Zoitl, Alois},
booktitle={2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )},
title={IEC 61499 Distributed Design Patterns},
year={2021},
volume={},
number={},
pages={1-8},
abstract={IEC 61499 emerged as a language for modeling distributed control systems. An Application is a platform-independent model that is comprised of modular components. High reusability of these components and high reconfigurability of the underlying system configuration can only be achieved with advanced design patterns. We show two example implementations of such designs and extended a pattern to foster reuse. All designs are compared based on a set of evaluation criteria. We show that our proposed design provides improved understandability and adaptability, while maintaining a slim library with highly reusable Function Block types.},
keywords={Conferences;Decentralized control;Tools;Libraries;IEC Standards;Manufacturing automation;IEC 61499;Distributed control system;Software design;Software architecture;Distributed design;Design pattern;skill;choreography},
doi={10.1109/ETFA45728.2021.9613569},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{812593,
author={Shrivastava, A. and Kumar, H. and Kapoor, S. and Kumar, S. and Balakrishnan, M.},
booktitle={VLSI Design 2000. Wireless and Digital Imaging in the Millennium. Proceedings of 13th International Conference on VLSI Design},
title={Optimal hardware/software partitioning for concurrent specification using dynamic programming},
year={2000},
volume={},
number={},
pages={110-113},
abstract={An important aspect of hardware-software co-design is partitioning of tasks to be scheduled on the hardware and software resources. Existing approaches separate partitioning and scheduling in two steps. Since partitioning solutions affect scheduling results and vice versa, the existing sequential approaches may lead to sub-optimal results. In this paper, we present an integrated hardware/software scheduling, partitioning and binding strategy. We use dynamic programming techiques to devise an optimal solution for partitioning of a given concurrent task graph which models the co-design problem, for execution on one software (single CPU) and several hardware resources (multiple FPGAs), with the objective of minimizing the total execution time. Our implementation shows that we can solve problem instances where the task graph has 40 nodes and 600 edges in less than a second.},
keywords={Dynamic programming;Field programmable gate arrays;Hardware;Computer architecture;Processor scheduling;Heuristic algorithms;Partitioning algorithms;Flow graphs;Testing;Software libraries},
doi={10.1109/ICVD.2000.812593},
ISSN={1063-9667},
month={Jan},}
@INPROCEEDINGS{4046966,
author={Polak, E.},
booktitle={1981 20th IEEE Conference on Decision and Control including the Symposium on Adaptive Processes},
title={Interactive software for computer-aided-design of control systems via optimization},
year={1981},
volume={},
number={},
pages={408-412},
abstract={Any computer-aided design package is an implementation of concepts which define both the nature of the design methodology and the nature of the appropriate software. This paper describes some of the general concepts that have evolved in Berkeley in the process of developing a powerful software system for interactive optimization-based computer-aided-design of multivariable control systems. Facilities permitting, a prototype interactive design package will be used to illustrate how these concepts have been implemented in practice.},
keywords={Control systems;Packaging;Design optimization;Constraint optimization;Control system synthesis;Software packages;Cost function;Computational modeling;Algorithm design and analysis;Frequency},
doi={10.1109/CDC.1981.269558},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6270830,
author={Kaplan, Larry and Briggs, Preston and Ohlrich, Miles and Leslie, Will},
booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum},
title={Resilience to Various Failures for Read-mostly In-memory Data Structures},
year={2012},
volume={},
number={},
pages={1572-1580},
abstract={As massively parallel processing (MPP) machines and their associated applications become larger, more work on resiliency is needed if those applications are to have a chance of running for significant lengths of time in the face of the expected component failure rates. This paper describes an approach for protecting large read-mostly in-memory data structures from various forms of failures by applying the concept of software erasure-correcting codes. A prototype library for this scheme was implemented on the Cray XMT and applied to a sample application. It is also portable to other global shared memory architectures that meet certain requirements, including the Cray XE.},
keywords={Data structures;Libraries;Databases;Face;Xenon;Memory management;Registers;resilience;data structures;erasure codes},
doi={10.1109/IPDPSW.2012.198},
ISSN={},
month={May},}
@INPROCEEDINGS{7814818,
author={Mishra, Amogh and Kishore, Kishan and Kumar, Viraj},
booktitle={2016 IEEE Eighth International Conference on Technology for Education (T4E)},
title={An Eclipse Plugin to Assist Learners in Selecting Hash Functions},
year={2016},
volume={},
number={},
pages={172-175},
abstract={Hashing is an important technique to achieve high code performance in a variety of data processing applications. The concept is emphasized in Computer Science curricula, and the IT industry values graduates who can use hashing skillfully. Although several implementation details of hashing are routinely handled by software libraries, it remains the responsibility of the programmer to choose a suitable hash function (a poor hash function can degrade performance). Researchers have designed a number of generic hash functions, but environments for code development do not offer these as off-the-shelf solutions. It is also curious that textbooks and reference books do not point learners to this rich resource. Our paper remedies this deficiency by providing learners with an easy way to compare their own hash function's performance with these alternatives. Our assistive tool is an Eclipse plugin for Java programs, and we have focused only on traditional hash functions (non-cryptographic hash functions that do not preserve distance). However, our approach can be extended easily to other programming languages, development environments and hash function classes.},
keywords={Java;Data structures;Force;Guidelines;Computers;Hashing;Non-cryptographic hash functions;Data Structures;Running Time},
doi={10.1109/T4E.2016.043},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6622309,
author={Destercke, Sébastien and Buche, Patrice and Charnomordic, Brigitte and Guillard, Valérie},
booktitle={2013 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
title={Decision support system using flexible query and reliability assessment - application to biodegradable and biosourced packaging design},
year={2013},
volume={},
number={},
pages={1-8},
abstract={In decision tasks, imprecision and uncertainty can arise from many sources such as data uncertainty, data reliability, or the necessity to use intermediate (non-fully reliable) models. User preferences may also be included into the decision process, making it even more complex. This is particularly true for processes involving biological materials. Soft computing methods have the potential to be the kingpin of specialized software that can be integrated in decision support systems intended to solve the mentioned issues. This work presents three such methods and their implementation: (i)-simulation module with uncertain inputs and interval analysis, (ii)-reliability module allowing to rank candidates according to expert criteria, and (iii)-bipolar flexible querying module, that makes the difference between constraints and wishes in a data base query. A decision support system architecture is proposed and illustrated on a case study, dealing with biodegradable and biosourced packaging design.},
keywords={Mathematical model;Uncertainty;Data models;Biological system modeling;Decision support systems;Software reliability;software;data reliability;flexible querying;uncertainty simulation},
doi={10.1109/FUZZ-IEEE.2013.6622309},
ISSN={1098-7584},
month={July},}
@INPROCEEDINGS{6811924,
author={Yingke Gao and Diancheng Wu and Quanquan Li and Tiejun Zhang and Chaohuan Hou},
booktitle={2013 IEEE 10th International Conference on ASIC},
title={Design and implementation of transaction level processor based on UVM},
year={2013},
volume={},
number={},
pages={1-4},
abstract={As the complexity of integrated circuit increases, the transaction level model (TLM) bridges the architecture and the hardware implementation. With SuperV_EF01 DSP as the research prototype, this paper presents a new method to design and implement the transaction level model based on UVM, which provides plenty of SystemVerilog libraries. This model can accelerate software development and be used as a golden reference model in the verification of RTL model without complex interface function.},
keywords={Time-varying systems;Time-domain analysis;Integrated circuit modeling;Computer architecture;Software;Computational modeling;Hardware;TLM;UVM;SuperV_EF01;reference model;software development;verification},
doi={10.1109/ASICON.2013.6811924},
ISSN={2162-755X},
month={Oct},}
@INPROCEEDINGS{1620124,
author={Ali, N. and Perez, J. and Ramos, I. and Carsi, J.A.},
booktitle={5th Working IEEE/IFIP Conference on Software Architecture (WICSA'05)},
title={Introducing Ambient Calculus in Mobile Aspect-Oriented Software},
year={2005},
volume={},
number={},
pages={233-234},
abstract={Currently most software systems have a distributed nature. The development of distributed and mobile software is a complex task. As a result, it is important to take into account distribution and mobility from the early stages of the development process instead of delaying their considerations to the implementation stage. In this work, we present how to consider distribution and mobility features at the architectural level.},
keywords={Calculus;Software architecture;Mobile computing;Information systems;Software systems;Software libraries;Programming;Algebra;Computer architecture;Technological innovation},
doi={10.1109/WICSA.2005.41},
ISSN={},
month={Nov},}
@ARTICLE{6081847,
author={Steinbiss, Sascha and Kurtz, Stefan},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
title={A New Efficient Data Structure for Storage and Retrieval of Multiple Biosequences},
year={2012},
volume={9},
number={2},
pages={345-357},
abstract={Today's genome analysis applications require sequence representations allowing for fast access to their contents while also being memory-efficient enough to facilitate analyses of large-scale data. While a wide variety of sequence representations exist, lack of a generic implementation of efficient sequence storage has led to a plethora of poorly reusable or programming language- specific implementations. We present a novel, space-efficient data structure (GtEncseq) for storing multiple biological sequences of variable alphabet size, with customizable character transformations, wildcard support, and an assortment of internal representations optimized for different distributions of wildcards and sequence lengths. For the human genome (3.1 gigabases, including 237 million wildcard characters) our representation requires only 2 + 8 · 10-6 bits per character. Implemented in C, our portable software implementation provides a variety of methods for random and sequential access to characters and substrings (including different reading directions) using an object-oriented interface. In addition, it includes access to metadata like sequence descriptions or character distributions. The library is extensible to be used from various scripting languages. GtEncseq is much more versatile than previous solutions, adding features that were previously unavailable. Benchmarks show that it is competitive with respect to space and time requirements.},
keywords={Particle separators;Bioinformatics;Software;Genomics;Encoding;Libraries;Data structures;Data storage representations;biology and genetics;software engineering;reusable libraries.},
doi={10.1109/TCBB.2011.146},
ISSN={1557-9964},
month={March},}
@INPROCEEDINGS{7501188,
author={Setka, Vlastimil and Štětina, Milan},
booktitle={2016 17th International Carpathian Control Conference (ICCC)},
title={Software tools for embedded reconfigurable control algorithm code generation},
year={2016},
volume={},
number={},
pages={711-716},
abstract={This paper deals with implementation of control algorithms for various target platforms such as microcontrollers (MCUs) or digital signal processors (DSPs). Our approach is automatic conversion of a function block diagram, which is a declarative description of control algorithm structure, into a target platform source code. The function blocks are implemented as a platform independent library covering wide application range from a simple logic and arithmetic operations to complex motion control blocks. This allows reuse of work and easy transfer from simulation environment to a target device running the real time control algorithm. The proposed approach is demonstrated on the problem of a motor controller development. It allows very easy extension of control algorithms running inside the controller by engineer friendly function block diagram modification.},
keywords={Libraries;Software algorithms;Algorithm design and analysis;Software packages;Signal processing algorithms;Real-time systems},
doi={10.1109/CarpathianCC.2016.7501188},
ISSN={},
month={May},}
@INPROCEEDINGS{4062552,
author={Mahboubi, Zouhair and Clarke, Stella},
booktitle={2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)},
title={.NET API Wrapping for Existing C++ Haptic APIs},
year={2006},
volume={},
number={},
pages={67-71},
abstract={For a long time haptic devices were expensive and therefore only accessible to a specialized community. But with companies like Novint Technologies introducing a peripheral intended to sell for about US$100, haptic devices can be expected to be affordable for a wider public. But considering that most haptic APIs are in C++, a language intended for expert programmers, novice programmers wanting to program haptic devices would face a steep learning curve. However, if the APIs were to be usable from within the .NET framework, it would allow the more novice users to program using over 20 programming languages and extensive programming solutions and therefore they would be able to easily and efficiently develop software with haptic capabilities. This paper presents a set of guidelines for a design architecture that would allow migrating an existing C++ API to the .NET framework without having to rewrite it from scratch. The presented architecture was implemented by wrapping the Sensable Ghost SDK 3.0. It was then used in both software and hardware based scenarios},
keywords={Wrapping;Haptic interfaces;Programming profession;Computer architecture;Hardware;Computer languages;Manufacturing;Engines;Conferences;Machine tools},
doi={10.1109/HAVE.2006.283806},
ISSN={},
month={Nov},}
@INPROCEEDINGS{390723,
author={Aguilera, L.M. and Penz, B. and Heping Song and Binder, Z.},
booktitle={Proceedings of IEEE Systems Man and Cybernetics Conference - SMC},
title={Design and implementation of a scheduling software system},
year={1993},
volume={4},
number={},
pages={276-282 vol.4},
abstract={This paper presents a scheduling software system. The system design is based on oriented object concepts and the scheduling algorithm developments are supported by a coordinated decentralized control approach. The system has three aims: 1) it supports research and development works on scheduling algorithms; 2) it is an educational aid tool which supports practical experiments in Scheduling Theory courses. The system is used in industrial applications. In this case, a complete life cycle of algorithms is carried out. It comprises several phases such as modelling of the practical problem, development of algorithms, adaptation to industrial problems, evaluation of performances and industrial installation.<>},
keywords={Software systems;Production systems;Job shop scheduling;Scheduling algorithm;Production control;Distributed control;Electrical equipment industry;Research and development;Application software;Single machine scheduling},
doi={10.1109/ICSMC.1993.390723},
ISSN={},
month={Oct},}
@ARTICLE{9328759,
author={Li, Bin and Feng, Feng and Chen, Xiaojie and Cao, Yan},
journal={IEEE Access},
title={Reconfigurable and High-Efficiency Password Recovery Algorithms Based on HRCA},
year={2021},
volume={9},
number={},
pages={18085-18111},
abstract={Cryptographic algorithms are widely used in information security fields such as network protocol authentication and commercial encryption software. Password recovery based on the hash algorithm is an important means of electronic forensics, encrypted information restoration, illegal information filtering, and network security maintenance. The traditional password recovery system is based mainly on the CPU and GPU and has a low energy efficiency ratio and cracking efficiency and cannot meet high-performance computing requirements. To further improve the computational efficiency and application flexibility of password recovery algorithms, this paper proposes a reconfigurable computing kernel design method based on a hybrid reconfigurable computing array (HRCA). Through in-depth analysis of the hash algorithm, the basic computing kernel set is extracted, and the combination design is carried out from the unit kernel, interconnection and storage structure to reconstruct the hash algorithm to match the application with the appropriate structure. Second, combined with the pipeline technology, the full pipeline hash and high-speed password attack algorithms are optimized and implemented to meet the needs of high-performance computing. Finally, an advanced computing kernel library is established, and the combination of a computing kernel map from the control and communication levels to achieve multidimensional reconfigurable computing and an overall placement strategy is used to make full use of the chip resources to improve computational efficiency. The experimental results and analysis show that compared with traditional CPU and GPU methods, the password recovery algorithm designed in this paper has the highest cracking speeds at 78.22 times and 2.65 times that of the CPU and GPU, respectively, and the highest energy efficiency ratio is 25.88 times and 3.16 times that of the CPU and GPU, respectively. Furthermore, the recovery efficiency has been significantly improved and meets the requirements of high-performance password recovery computing.},
keywords={Kernel;Password;Graphics processing units;Field programmable gate arrays;Hardware;Scalability;Computer architecture;HRCA;computing kernel;reconfigurable;hash algorithm;password recovery},
doi={10.1109/ACCESS.2021.3053068},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7954374,
author={Jäger, Sven and Maschotta, Ralph and Jungebloud, Tino and Wichmann, Alexander and Zimmermann, Armin},
booktitle={2016 4th International Conference on Model-Driven Engineering and Software Development (MODELSWARD)},
title={An EMF-like UML generator for C++},
year={2016},
volume={},
number={},
pages={309-316},
abstract={Model-driven architecture is a well-known approach for the development of complex software systems. The most famous tool chain is provided by Eclipse with the tools of the Eclipse modeling project. Like Eclipse itself, these tools are based on Java. However, there are numerous legacy software packages written in C++, which often use only an implicit meta-model. A real C++ implementation of this meta-model would be necessary instead to be used at run time. This paper presents a generator for C++ to create the classes, meta-model packages, and factories to realize modeling, transformation, validation, and comparison of UML models. It gives an overview of its workflow and major challenges. Moreover, a comparison between Java and C++ implementations is given, considering different benchmarks.},
keywords={Unified modeling language;C++ languages;Generators;Java;Load modeling;Production facilities;Tools;Model based Software Development;Code Generation;Meta Modeling;C++;UML;MOF;Ecore},
doi={},
ISSN={},
month={Feb},}
@ARTICLE{5405143,
author={Staszewski, Roman and Staszewski, Robert Bogdan and Jung, Tom and Murphy, Thomas and Bashir, Imran and Eliezer, Oren and Muhammad, Khurram and Entezari, Mitch},
journal={IEEE Journal of Solid-State Circuits},
title={Software Assisted Digital RF Processor (DRP™) for Single-Chip GSM Radio in 90 nm CMOS},
year={2010},
volume={45},
number={2},
pages={276-288},
abstract={This paper proposes and describes a new software and application programming interface view of an RF transceiver. It demonstrates benefits of using highly programmable digital control logic in an RF wireless system realized in a digital nanoscale CMOS process technology. It also describes a microprocessor architecture design in Digital RF Processor (DRPTM) and how it controls calibration and compensation for process, temperature and voltage variations of the analog and RF circuits to meet the required RF performance. A few calibration examples to reduce a DCO bias current and improve device reliability, as well as to optimize transmit modulation and receive performance, are given. The presented circuits and techniques have enabled successful implementation of a commercial single-chip GSM radio in 90 nm CMOS.},
keywords={Radio frequency;GSM;CMOS process;Calibration;Application software;Transceivers;Digital control;CMOS logic circuits;Logic programming;Programmable control;All-digital phase-locked loop (ADPLL);application programming interface (API);built-in self-test (BIST);calibration;compensation;digitally-controlled oscillator (DCO);digital processor;digitally-assisted analog;mobile phones;nanometer scale CMOS;RF;software;software-defined radio (SDR);time-to-digital converter (TDC)},
doi={10.1109/JSSC.2009.2036763},
ISSN={1558-173X},
month={Feb},}
@ARTICLE{8978572,
author={Rafique, Wajid and Zhao, Xuan and Yu, Shui and Yaqoob, Ibrar and Imran, Muhammad and Dou, Wanchun},
journal={IEEE Internet of Things Journal},
title={An Application Development Framework for Internet-of-Things Service Orchestration},
year={2020},
volume={7},
number={5},
pages={4543-4556},
abstract={Application development for the Internet of Things (IoT) poses immense challenges due to the lack of standard development frameworks, tools, and techniques to assist end users in dealing with the complexity of IoT systems during application development. These challenges invoke the use of model-driven development (MDD) along with the representational state transfer (REST) architecture to develop IoT applications, supporting model generation at different abstraction levels while generating software implementation artifacts for heterogeneous platforms and ensuring loose coupling in complex IoT systems. This article proposes an IoT application development framework, named IADev, which uses attribute-driven design and MDD to address the above-mentioned challenges. This framework is composed of two major steps, including iterative architecture development using attribute-driven design and generating models to guide the transformation using MDD. IADev uses attribute-driven design to transform the requirements into a solution architecture by considering the concerns of all involved stakeholders, and then, MDD metamodels are generated to hierarchically transform the design components into the software artifacts. We evaluate IADev for a smart vehicle scenario in an intelligent transportation system to generate an executable implementation code for a real-world system. The case study experiments proclaim that IADev achieves higher satisfaction of the participants for the IoT application development and service orchestration, as compared to conventional approaches. Finally, we propose an architecture that uses IADev with the Siemens IoT cloud platform for service orchestration in industrial IoT.},
keywords={Internet of Things;Software;Computer architecture;Complexity theory;Stakeholders;Hardware;Computational modeling;Attribute-driven design;Internet-of-Things (IoT) application development;IoT service orchestration;model-driven design;representational state transfer (REST) application programming interface (API);software architecture},
doi={10.1109/JIOT.2020.2971013},
ISSN={2327-4662},
month={May},}
@INPROCEEDINGS{475341,
author={Morgan, G.W. and Lear, F.A.},
booktitle={Proceedings Software Education Conference (SRIG-ET'94)},
title={The role of a software engineering project within an undergraduate applied computing degree},
year={1994},
volume={},
number={},
pages={230-236},
abstract={Australian and Tasmanian employment figures show that there is a diminishing number of employment opportunities for computing graduates each year and in the particular case of graduates wishing to work in Tasmania, even fewer opportunities exist. Curriculum design must consider how to give students as much competitive advantage as possible in the job market. Applicants who can point to a completed working and well-documented software package as evidence of practical skills which extend theoretical knowledge are favoured. An informal survey of past graduates and potential employers in the Northern region of Tasmania indicates that prospective employers value the inclusion of a software engineering project as a vital component of the degree. The structure, management and difficulties inherent in running such a unit are discussed. There is a varying emphasis placed on the practical implementation of a software engineering project across institutions.<>},
keywords={Software engineering;Employment;Job design;Australia;Mathematics;Packaging;Project management;Engineering management;Software packages;Appraisal},
doi={10.1109/SEDC.1994.475341},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7748869,
author={Kookarinrat, Pakorn and Temtanapat, Yaowadee},
booktitle={2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE)},
title={Design and implementation of a decentralized message bus for microservices},
year={2016},
volume={},
number={},
pages={1-6},
abstract={A new software architecture, known as microservices, becomes rapidly popular recently. Microservices could help developers cope well with the problems of software complexity and demands on an adaptive development process that needs to respond to changes quickly. In this architecture, a single monolithic large application would be divided into small multiple isolated services. They are separately deployed and communicated to other services via remote calls. This architectural style allows any changes on one service not affecting the others. However, if services directly make remote calls, it would create interdependencies and tight couplings between them. To remove such problem, this paper proposes a decentralized message bus to use as a communication tool between services. Our message bus provides a framework for services to collaborate. It divides into four main components, public API, message bus, messaging and service discovery. The API uses the HTTP and RESTful style of communication. We use decentralized service discovery to avoid a single point of failure of the system. The messaging uses a simple TCP connection with only a header and body in its message. We also define three necessary communication messages for the services, viz. request/response, notification and publish/subscribe. The proposed framework is implemented and tested with a real-world scenario. It works correctly without any problem. Also, to realize how it could be scaled, we run the system continuously with incremental services and traffics. From the observation on the resource consumption of CPU, memory and network I/O, we found that the network consumption grows linearly while the CPU and memory usages have little change in consumption.},
keywords={Protocols;Complexity theory;Computer architecture;Scalability;Iris;Computer science;Load modeling;microservices;message bus;software architecture},
doi={10.1109/JCSSE.2016.7748869},
ISSN={},
month={July},}
@INPROCEEDINGS{1662488,
author={Chu, D. and Lin, K. and Linares, A. and Nguyen, G. and Hellerstein, J.M.},
booktitle={2006 5th International Conference on Information Processing in Sensor Networks},
title={Sdlib: a sensor network data and communications library for rapid and robust application development},
year={2006},
volume={},
number={},
pages={432-440},
abstract={Sensor network applications tend to exhibit significant high-level commonalities along several major dimensions that have heretofore been underexposed, particularly in the areas of collection and dissemination. We have developed a component library, Sdlib, which presents the fundamental abstractions of collection and dissemination as part of a dataflow system. This allows application developers to rapidly develop applications at the nesC level. This means that Sdlib maintains significant expressivity while operating efficiently. We have built four applications, each faithful to a mature monolithic application, on top of Sdlib to compare its performance to that of original. We find that applications implemented with Sdlib are much simpler to write, just as resource efficient, and perform comparably to monolithic implementations},
keywords={Libraries;Robustness;Application software;Software engineering;Wireless sensor networks;Permission;Buffer storage;Computer science;Software architecture;Software reusability;Wireless sensor networks;software library;collection;dissemination},
doi={10.1145/1127777.1127843},
ISSN={},
month={April},}
@INPROCEEDINGS{808159,
author={Niclet, M. and Zaytoon, J.},
booktitle={Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411)},
title={ALISA: a software tool for automated-systems assisted design},
year={1999},
volume={2},
number={},
pages={941-946 vol.2},
abstract={Presents a tool to aid in the development of automated systems design based on a coherent integration of static and dynamic aspects of the meta-modelling of automatic discrete event systems.},
keywords={Software tools;Production systems;Construction industry},
doi={10.1109/CCECE.1999.808159},
ISSN={0840-7789},
month={May},}
@ARTICLE{1593881,
author={Woon-Seng Gan and Kuo, S.M.},
journal={IEEE Transactions on Education},
title={Teaching DSP software development: from design to fixed-point implementations},
year={2006},
volume={49},
number={1},
pages={122-131},
abstract={In this paper, a digital signal processing (DSP) software development process is described. It starts from the conceptual algorithm design and computer simulation using MATLAB, Simulink, or floating-point C programs. The finite-word-length analysis using MATLAB fixed-point functions or Simulink follows with fixed-point blockset. After verification of the algorithm, a fixed-point C program is developed for a specific fixed-point DSP processor. Software efficiency can be further improved by using mixed C-and-assembly programs, intrinsic functions, and optimized assembly routines in DSP libraries. This integrated software-development process enables students and engineers to understand and appreciate the important differences between floating-point simulations and fixed-point implementation considerations and applications.},
keywords={Software development management;Computer science education;Floating point arithmetic;Roundoff errors;Program assemblers;Signal processing;Digital signal processing (DSP) software development;floating-point and fixed-point C programming;real-time digital signal processing},
doi={10.1109/TE.2005.863425},
ISSN={1557-9638},
month={Feb},}
@INPROCEEDINGS{6037523,
author={Radivojevic, Zaharije and Cvetanovic, Milos and Ðordevic, Jovan},
booktitle={2011 Second Eastern European Regional Conference on the Engineering of Computer Based Systems},
title={Design of the Simulator for Teaching Computer Architecture and Organization},
year={2011},
volume={},
number={},
pages={124-130},
abstract={This paper presents a general purpose discrete event simulator, named SLEEP, that helps students to bridge the gap between theory and practice in the domain of Computer Architecture and Organization simulator design. The motivation for developing SLEEP is given after an analysis of simulators available in the open literature. The analysis is followed by implementation details explaining execution and simulation algorithms of SLEEP. Then, the SLEEP simulator features are briefly described. Finally, the performance evaluation with generated test workload is presented.},
keywords={Physics;Libraries;Integrated circuits;Java;Organizations;Computer architecture;Instruction sets;general purpose discrete event simulator;computer architecture and organization;concurrent programming;distributed programming;simulation software},
doi={10.1109/ECBS-EERC.2011.26},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{547690,
author={Allred, L.G. and Kelly, P.B. and Harames, J.P.},
booktitle={Conference Record. AUTOTESTCON '96},
title={Automated experimental design for automatic test equipment software},
year={1996},
volume={},
number={},
pages={156-159},
abstract={Achieving an effective stimulation pattern for an electronic circuit card is an elusive and labor intensive task. In contrast to the vectorless testing concept which assumes nothing about the circuit card, our implementation would contain a circuit topology and a designation of devices in the circuit, including standard designation input devices, output devices, voltage and current sources, etc. A library interface is supplied to specify (when required) the safe ranges of stimulation, signal sources and analog waveforms, probe paths and if desired, an operating range and quantization of a device. As opposed to passive testing, this technique allows the tester to jump into the operating range of the device. Stimulation pattern effectiveness is measured in terms of output entropy. While the initial stimulation pattern may be selected at random, directed search techniques allow the optimization of the stimulation by eliminating redundancy, and changing existing patterns toward a stimulation pattern of increased entropy. A digital application of this concept is being developed for the Electronic Work Bench (EWB), a new VXI system using components from Talon. While a fully automatic process is not always practical, this concept should make considerable headway toward reducing to human labor cost while improving the overall process.},
keywords={Design for experiments;Automatic test equipment;Circuit testing;Entropy;Electronic circuits;Circuit topology;Voltage;Libraries;Probes;Quantization},
doi={10.1109/AUTEST.1996.547690},
ISSN={1088-7725},
month={Sep.},}
@INPROCEEDINGS{8075249,
author={Wagner, Florian and Dalton, Sean William and Bergmann, Arno},
booktitle={2017 International Conference on Research and Education in Mechatronics (REM)},
title={Benefits and drawbacks of target specific model-based testing},
year={2017},
volume={},
number={},
pages={1-5},
abstract={Model-Based Testing rises hopes of project teams of meeting both eager time and budget constraints as well as achieving better system quality by thorough testing. However, toolchain and method impose a certain skill set on the project engineer. This paper presents a possible way forward and introduces the constraints to the system architecture.},
keywords={Testing;Hardware;Analytical models;Software packages;Data models;Computer science;Model-Based Design;Model-Based Testing;Verification & Validation;Embedded Systems;Software-Testing;Model-in-the-Loop;target specific implementation model;Simulink Test;Simulink Verification and Validation},
doi={10.1109/REM.2017.8075249},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9291645,
author={Liu, Yongtao and Sun, Ruizhi and Zhang, Tianyi and Zhang, Xiangnan and Li, Li and Shi, Guoqing},
booktitle={2020 International Conferences on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)},
title={Fast Fire Identification Soft-Core Package Design Based on FPGA},
year={2020},
volume={},
number={},
pages={642-647},
abstract={At present, there are various methods of fire detection. The pure software-based fire identification systems have problems such as higher requirements on the hardware system, identification jams and poor efficiency etc. The rapid development of FPGA (Field Programmable Gate Array) and processor combination technology provides a new solution for fire detection based on video images. The system completes the FPGA system architecture construction through the combination of software and hardware. We use the inter-frame difference method of the image R (Red) component and LK (Lucas-Kanade) pyramid optical flow method for the early image extraction and judgment, and later introduce the image processing methods such as the median filter, mean filter, Gaussian filter and grayscale processing etc., so as to realize the soft-core design and packaging of the flame recognition FPGA. Finally, the identification and boundary calibration of the flame in the video are simulated by MATLAB, and the detection process is fast and accurate. The method is realized by building FPGA and Nois II video capture system, which provides an effective solution for rapid fire identification.},
keywords={Fires;Optical flow;Field programmable gate arrays;SDRAM;Optical filters;Image color analysis;Thin film transistors;fire identification;inter-frame difference method;LK pyramid optical flow method;soft core package},
doi={10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00112},
ISSN={},
month={Nov},}