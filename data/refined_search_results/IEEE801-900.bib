@INPROCEEDINGS{8728919,
author={Takeda, Tomohiro and Takahashi, Masakazu and Yumoto, Tsuyoshi and Masuda, Satoshi and Matsuodani, Tohru and Tsuda, Kazuhiko},
booktitle={2019 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)},
title={Applying Change Impact Analysis Test to Migration Test Case Extraction Based on IDAU and Graph Analysis Techniques},
year={2019},
volume={},
number={},
pages={131-139},
abstract={The importance of software testing in enterprise system development is growing more and more from cost reduction, quality improvement and time-to-market of their enterprise services. Especially in recent years, companies with the spread of API economy trend has been faced with the need to publish their services via public API-Gateway as Restful-API services. Simultaneously, there is a need for software testing for a part of migrated function from a legacy monolithic architecture to microservice one. In this situation, we have a concern how far range implementation is influenced by getting rid of migrated function's implementation, new function as microservice and isolated data on cloud container. Despite existing several test case extraction methodologies, these are not enough to reveal rage of influence in this case. Therefore, we propose a new test case extraction methodology for a part of system modification and system transition like migrating to microservices from a monolithic system. Our approach focuses on the interaction between function and data to extract test cases from only influenced ranges. On that account, we leverage improved "Impact Data All Used" method as "Code-Based - Impact Data All used." Moreover, we apply graph mining techniques to extracted test cases for reducing the number of test cases efficiently. As a result of this study, by exhaustively searching CRUD operations in source codes level, clarified that it is possible to extract dependencies between functions and data as test cases which are not able to be detected by previous study's IDAU method. Moreover, we suggest the possibility of a test case reduction model by Bonachich Power Centrality and Link-Community analysis.},
keywords={Data mining;Software;Software testing;Business;Computer bugs;Measurement;Software testing;Microservice;API;Test Case creation;Impact Analysis},
doi={10.1109/ICSTW.2019.00041},
ISSN={},
month={April},}
@INPROCEEDINGS{6391782,
author={Rico, Timóteo M. and Pilla, Maurício L. and Du Bois, André R.},
booktitle={2012 13th Symposium on Computer Systems},
title={Energy Consumption on Software Transactional Memories},
year={2012},
volume={},
number={},
pages={194-201},
abstract={With the spreading of multicore architectures, new challenges have been added to software development. Among those, efficiently avoiding race conditions through synchronization is one of the greatest difficulties in concurrent programming. Transactional memories have been proposed to reduce the issues and limitations found on previous synchronization techniques based in locks, such as mutexes, semaphores, and monitors. The use of transactions allows for a higher abstraction on writing code, leaving for the compiler or library the determination of which variables can be accessed concurrently. The runtime system is responsible for detecting conflicts during execution, and solving them in a way that the desired semantics is preserved. In this context, this paper analyzes energy consumption and performance of three Software Transactional Memory implementations, TL2, TinySTM, and Swiss TM, using the STAMP benchmarks. Different from previous works, the workloads are not simulated but executed in a computer. The results show that TinySTM and Swiss TM have very similar performance, even more when the number of threads is increased. On the other hand, TL2 presents worse performance for all benchmarks but Genome. Energy consumption closely follows the same trend, as no specific power management is employed, hence execution time is the main variable determining power.},
keywords={Benchmark testing;Instruction sets;Genomics;Bioinformatics;Hardware;Computational modeling;software transactional memories;green computing;parallel processing},
doi={10.1109/WSCAD-SSC.2012.26},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9283164,
author={Xu, Xinhai and Li, Xianglong and Zhangy, Feng and Shen, Tianlong and Zhang, Shuai and Li, Hao},
booktitle={2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
title={Glue: Enhancing Compatibility and Flexibility of Reinforcement Learning Platforms by Decoupling Algorithms and Environments},
year={2020},
volume={},
number={},
pages={1860-1865},
abstract={Reinforcement Learning (RL) platforms play an important role in translating the rapid advances of RL algorithms into the successes of real-world tasks. These platforms integrate multiple simulation environments, allowing testing, evaluating and finally applying RL algorithms in different scenarios. However, the algorithm code is required to execute in the same runtime system with the underlying environments, which limits platforms’ compatibility when adapting an algorithm and flexibility when switching between different algorithms. We propose GLUE to resolve this issue, by decoupling the executions of algorithms and environments first, then leveraging the RPC protocol to orchestrate a seamless workflow between them. GLUE is further implemented as a library, which hides the handling of language-specific RPCs from users. We evaluate GLUE by adapting 6 RL algorithm implementations to a representative RL platform. Compared with the baseline approach, GLUE enables algorithms to achieve competitive performance, but reduces lines of algorithm code to be changed in adaption by 27.77% , at the cost of 5.40% longer training time, on average.},
keywords={Training;Switches;Reinforcement learning;Transforms;User interfaces;Libraries;Testing;Reinforcement Learning;Software Architecture},
doi={10.1109/SMC42975.2020.9283164},
ISSN={2577-1655},
month={Oct},}
@INPROCEEDINGS{9452969,
author={Li, Jian and Wang, Yan},
booktitle={2021 5th International Conference on Trends in Electronics and Informatics (ICOEI)},
title={Design and development of programmable controller based on Embedded Technology},
year={2021},
volume={},
number={},
pages={1563-1566},
abstract={With the development of social productivity, people's requirements for industrial automation continue to improve, the proportion of industrial automation equipment in the production process is growing. At present, PLC controller has been widely used in various fields and industries. Usually, the core of a complete embedded system is embedded processor and embedded operating system. Embedded processor belongs to chip industry, and the related industry chain has been very mature. Embedded processors can be subdivided into design, wafer manufacturing, packaging and testing. In this paper, a low-cost PLC controller design scheme is proposed. From the aspects of hardware circuit construction, product reliability design and software design, Bing explains in detail the PLC controller hardware and software design and specific implementation.},
keywords={Industries;Software design;Automation;Semiconductor device reliability;Reliability engineering;Hardware;Software;Embedded technology;Controller;Programmable Device;System Design;Hardware Structure},
doi={10.1109/ICOEI51242.2021.9452969},
ISSN={},
month={June},}
@INPROCEEDINGS{1371920,
author={Zhang, Z. and Yang, H.},
booktitle={11th Asia-Pacific Software Engineering Conference},
title={Incubating services in legacy systems for architectural migration},
year={2004},
volume={},
number={},
pages={196-203},
abstract={Legacy systems are valuable assets for organisations. They continuously evolve with new emerged technologies in rapidly changing business environment. Web services, together with service-oriented architectures, facilitate legacy system webification and evolution in service-oriented computing environment. Traditional approaches to integrate legacy systems with Web service technology are wrapping a legacy system as a black-box without adequate system understanding. In this paper, we proposed a reengineering approach which applies an improved agglomerative hierarchical clustering algorithm to restructure legacy code and to facilitate legacy code extraction for Web service construction. It supports service identification and service packaging and archives legacy system migration into service-oriented architectures by providing functional legacy code as Web services.},
keywords={Web services;Service oriented architecture;Logic;Business process re-engineering;Wrapping;Application software;Software systems;Software engineering;Laboratories;Clustering algorithms;Legacy System;Software Reengineering;Software Evolution;Hierarchical Clustering;Web Services;Service-Oriented Architectures (SOA)},
doi={10.1109/APSEC.2004.61},
ISSN={1530-1362},
month={Nov},}
@INPROCEEDINGS{7039169,
author={Abdulsalam, Sarah and Lakomski, Donna and Gu, Qijun and Jin, Tongdan and Zong, Ziliang},
booktitle={International Green Computing Conference},
title={Program energy efficiency: The impact of language, compiler and implementation choices},
year={2014},
volume={},
number={},
pages={1-6},
abstract={Today reducing the energy usage of computing systems becomes a paramount task, no matter they are lightweight mobile devices, complex cloud computing platforms or large-scale supercomputers. Many existing studies in green computing focus on making the hardware more energy efficient. This is understandable because software running on low-power hardware will automatically consume less energy. Little work has been done to explore how software developers can play a more proactive role in saving energy by writing greener code. In fact, very few programmers consider energy-efficiency when writing code and even fewer know how to evaluate and improve the energy-efficiency of their code. In this paper, we quantitatively study the impact of languages (C/C++/Java/Python), compiler optimization (GNU C/C++ compiler with O1, O2, and O3 flags) and implementation choices (e.g. using malloc instead of new to create dynamic arrays and using vector vs. array for Quicksort) on the energy-efficiency of three well-known programs: Fast Fourier Transform, Linked List Insertion/Deletion and Quicksort. Our experiments show that by carefully selecting an appropriate language, optimization flag and data structure, significant energy can be conserved for solving the same problem with identical input size.},
keywords={Java;Optimization;Software;Arrays;Libraries;Vectors;Resource management;energy-efficient programming;software optimization;green computing},
doi={10.1109/IGCC.2014.7039169},
ISSN={},
month={Nov},}
@ARTICLE{9568895,
author={Autiosalo, Juuso and Siegel, Joshua and Tammi, Kari},
journal={IEEE Access},
title={Twinbase: Open-Source Server Software for the Digital Twin Web},
year={2021},
volume={9},
number={},
pages={140779-140798},
abstract={Digital twins are expected to form a network, a “Digital Twin Web,” in the future. Digital Twin Web follows a similar structure to the World Wide Web and consists of meta-level digital twins that are described as digital twin description documents and distributed via Digital Twin Web servers. Standards must be established before the Digital Twin Web can be used efficiently, and having an easily accessible server implementation can foster the development of those standards. Twinbase is an open-source, Git-based Digital Twin Web server developed with user-friendliness in mind. Twinbase stores digital twin documents in a Git repository, modifies them with Git workflows, and distributes them to users via a static web server, from which the documents can be accessed via a client library or a regular web browser. A demo server is available at https://dtw.twinbase.org and new server instances can be initialized free-of-charge at GitHub via its browser interface. Twinbase is built with GitHub repository, Pages, and Actions but can be extended to support other providers or self-hosting. We describe the underlying architecture of Twinbase to support the creation of derivative and alternative server implementations. The Digital Twin Web requires permanent, globally accessible, and transferable identifiers to function properly, and to address this issue, we introduce the concept of digital twin identifier registry. Performance measurements showed that the median response times for fetching a digital twin document from Twinbase varied between 0.4 and 1.2 seconds depending on the identifier registry.},
keywords={Digital twin;Standards;Software development management;Web servers;Computer architecture;Open source software;Tools;Cyber-physical systems;cyberspace;digital twins;digital twin web;Internet of Things;internet topology;metadata;metamodeling;open-source software;semantic web;web services},
doi={10.1109/ACCESS.2021.3119487},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8053055,
author={Licht, Abigail S. and Shemelya, Corey S. and DeMeo, Dante F. and Carlson, Emily S. and Vandervelde, Thomas E.},
booktitle={2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
title={Optimization of GaSb thermophotovoltaic diodes with metallic photonic crystal front-surface filters},
year={2017},
volume={},
number={},
pages={843-846},
abstract={A promising technology for waste-heat recovery applications is thermophotovoltaics (TPVs), which use photovoltaic diodes to convert thermal energy into electricity. The most commonly used TPV diode material is gallium antimonide (GaSb). Recently, GaSb TPV diodes were fabricated with front-surface metallic photonic crystal (MPhC) filters to more optimally convert the incident spectrum. This method showed promising initial results, in part due to a shifting of the photogenerated carriers away from the front-surface and into the device. In this paper, we use the Atlas-Silvaco software package to optimize the TPV diode structure for MPhCs. We investigate the addition of an intrinsic region in the device to take advantage of the shifted photogeneration profile from the MPhCs. This design allows for a 10% improvement in internal quantum at the peak MPhC transmission wavelength.},
keywords={Photonic crystals;Semiconductor diodes;Electric fields;Photonics;Photovoltaic systems;Epitaxial growth;Thermophotovoltaics;GaSb;Photonic Crystals},
doi={10.1109/MWSCAS.2017.8053055},
ISSN={1558-3899},
month={Aug},}
@INPROCEEDINGS{8070136,
author={Xie, Xianjie and Yang, Zhijun and Yu, Jiankun and Zhang, Weifeng},
booktitle={2016 5th International Conference on Computer Science and Network Technology (ICCSNT)},
title={Design and implementation of bank financial business automation testing framework based on QTP},
year={2016},
volume={},
number={},
pages={143-147},
abstract={The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.},
keywords={Testing;Software;Tools;Automation;Standardization;Object recognition;Libraries;software testing;test automation framework;QTP automated testing tool},
doi={10.1109/ICCSNT.2016.8070136},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7336309,
author={Gardner, William B. and Gumtie, Alicia and Carter, John D.},
booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
title={Supporting Selective Formalism in CSP++ with Process-Specific Storage},
year={2015},
volume={},
number={},
pages={1057-1065},
abstract={Communicating Sequential Processes (CSP) is a formal language whose primary purpose is to model and verify concurrent systems. The CSP++ toolset was created to realize the concept of selective formalism by making machine-readable CSPm specifications both executable (through automatic C++ code generation) and extensible (by allowing integration of C++ user-coded functions, UCFs). However, UCFs were limited by their inability to share data with each other, thus their application was constrained to solving simple problems in isolation. We extend CSP++ by providing UCFs in the same CSP process with safe access to a shared storage area, similar in concept and API to Pthreads' thread-local storage, enabling cooperation between them and granting them the ability to undertake more complex tasks without breaking the formalism of the underlying specification. Process-specific storage is demonstrated with a line-following robot case study, applying CSP++ in a soft real-time system. Also described is the Eclipse plug-in that supports the CSPm design flow.},
keywords={Robot sensing systems;Switches;Libraries;System recovery;Writing;Real-time systems;CSPm;Timed CSP;C++;code generation;software synthesis;formal methods;model-based design;selective formalism;soft real-time;embedded systems;Eclipse},
doi={10.1109/HPCC-CSS-ICESS.2015.265},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9327521,
author={Hui, Zhong and Chang, Wang and XiangYu, Meng},
booktitle={2020 Chinese Automation Congress (CAC)},
title={Research on Mechanical Product Component Design Technology Based on Standardized Design Process},
year={2020},
volume={},
number={},
pages={2054-2057},
abstract={A component development environment for mechanical product design, a standardized roadheader cutting head component design system architecture was constructed, and the parametric design of the cutting head was carried out using the skeleton model method in the top-down component design mode. The system mainly makes the cutting head design parameterized, process-oriented, modular, and simple; it mainly realizes the arrangement of cutting teeth and data generation, visual layout plan, cutting efficiency, cutting force, recommended drilling power, recommended drilling Advance sweep speed, vibration frequency, arrangement effect, chip chart and automatically generate output reports; realize the input based on software design parameters, calculation, design results and evaluation index output, cutting head design software parameters and 3D design software Creo barrier-free data conversion, transmission. It can better solve the system scalability in the design process, can realize the parallel collaborative work, improve the design efficiency, and shorten the cutting head design cycle.},
keywords={Milling;Wheels;Software;Solid modeling;Libraries;Product design;Spirals;Standardized component design;parameterization;data conversion;mechanical products},
doi={10.1109/CAC51589.2020.9327521},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{884671,
author={Mena, E. and Illarramendi, A. and Goni, A.},
booktitle={Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops},
title={Customizable software retrieval facility for mobile computers using agents},
year={2000},
volume={},
number={},
pages={479-484},
abstract={Two tasks that entail a certain degree of difficulty when dealing with computers are retrieving and installing new software. So, the need arises to provide users with tools that help them retrieve the necessary software and install it. In the context of mobile computers, those tasks acquire a special relevance due to their limited resources (memory, disk space, autonomy, etc.). The authors present a software retrieval service that provides mobile computer users with mechanisms to select and retrieve the selected software in an easy and efficient way. Although this service can be used for fixed computers, it puts special emphasis on optimizing the use of battery and wireless communications. The implementation of that software retrieval service is based on agent technology.},
keywords={Mobile computing;Wireless communication;Antarctica;Large scale integration;Software tools;Batteries;Computer architecture;Communication system software;Cost function;Web pages},
doi={10.1109/PADSW.2000.884671},
ISSN={},
month={July},}
@INPROCEEDINGS{917299,
author={Jarrar, Y.F. and Al-Mudimigh, A. and Zairi, M.},
booktitle={Proceedings of the 2000 IEEE International Conference on Management of Innovation and Technology. ICMIT 2000. 'Management in the 21st Century' (Cat. No.00EX457)},
title={ERP implementation critical success factors-the role and impact of business process management},
year={2000},
volume={1},
number={},
pages={122-127 vol.1},
abstract={Variously called enterprises resource planning (ERP) systems, enterprise-wide systems, or enterprise business system, these comprehensive, package software solutions seek to integrate the complete range of a business's processes and functions in order to present a holistic view of the business from a single information and IT architecture. The critical success factors for ERP implementation include top management support, a clear business vision and issues specific to ERP such as ERP strategy and software configuration. However, some of the more important factors are the issue related to re-engineering business processes and the integration of various core processes to the ERP system.},
keywords={Enterprise resource planning;Business process re-engineering;Application software;Companies;Quality management;Total quality management;Best practices;Spine;Management information systems;Electronic mail},
doi={10.1109/ICMIT.2000.917299},
ISSN={},
month={Nov},}
@INPROCEEDINGS{72805,
author={Turner, P.R.},
booktitle={Proceedings of 9th Symposium on Computer Arithmetic},
title={A software implementation of SLI arithmetic},
year={1989},
volume={},
number={},
pages={18-24},
abstract={An implementation of the symmetric level-index (SLI) system, some of its special features, and some computational experience with it are described. The particular implementation discussed was developed for use on IBM-compatible PC machines and is written in Turbo Pascal. This allows many of the attractive features of a potential hardware implementation of SLI arithmetic to be readily incorporated. The ease of performing extended computational operations, such as scalar products and evaluation of polynomials, is evident from the package. The computational experiments reported also show the great simplicity of program structure which this robust arithmetic permits.<>},
keywords={Hardware;Polynomials;Mathematics;Performance evaluation;Packaging machines;Robustness;Digital arithmetic;Computer languages;Vehicles;Government},
doi={10.1109/ARITH.1989.72805},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{542290,
author={Ellmer, E. and Merkl, D. and Quirchmayr, G. and Tjoa, A.M.},
booktitle={Proceedings of 20th International Computer Software and Applications Conference: COMPSAC '96},
title={Process model reuse to promote organizational learning in software development},
year={1996},
volume={},
number={},
pages={21-26},
abstract={Software development often suffers from well-known problems such as wrong schedules and cost estimations, low productivity, and low product quality. In order to overcome these problems we suggest adapting the concepts of "organizational memory" and "organizational learning" and we argue in favor of establishing a reuse culture of software process models. We introduce an approach based on the process definition/instantiation/enaction paradigm and on the reuse of explicit software process descriptions (process models). The key features of our approach are the division of process descriptions into a goal-oriented process definition document and a formal implementation-oriented process model on the one hand and the use of an artificial neural network, more precisely a self-organizing map, for classification and retrieval purposes on the other. We present an exposition of our approach and discuss the promising results of an experiment in structuring a software process library and retrieving reuse candidates for upcoming projects.},
keywords={Programming;Scheduling;Costs;Productivity;Software libraries;Software engineering;Artificial neural networks;Neural networks;Production;Runtime environment},
doi={10.1109/CMPSAC.1996.542290},
ISSN={0730-3157},
month={Aug},}
@INPROCEEDINGS{4962,
author={Wirsing, M.},
booktitle={[Proceedings] COMPEURO 88 - System Design: Concepts, Methods and Tools},
title={Algebraic description of reusable software components},
year={1988},
volume={},
number={},
pages={300-312},
abstract={An approach to the description of reusable software components is presented which is based on the algebraic specification of abstract data types. Reusable components are described by an extension of the specification language ASL, which contains features for hierarchical structuring, parameterization, encapsulation of components, extension by enrichment, export-import interfaces, abstraction from the observable behavior, and the combination of components. Simple examples of ASL specifications are given, a notion of implementation is presented, and a few transformations of specifications are shown. A reusable component consists of tree formal specifications where a specification is a child of another specification if it is an implementation. Every node of the tree is itself a structured specification. In contrast to other approaches to software reusability these trees are considered as objects of the language and can be constructed and manipulated by operators of the language.<>},
keywords={Software reusability;Software libraries;Application software;Formal specifications;Algorithms;Specification languages;Encapsulation;Concrete;Costs;Data processing},
doi={10.1109/CMPEUR.1988.4962},
ISSN={},
month={April},}
@ARTICLE{7837640,
author={Dłotko, Paweł and Kapidani, Bernard and Specogna, Ruben},
journal={IEEE Transactions on Magnetics},
title={Topoprocessor: An Efficient Computational Topology Toolbox for h-Oriented Eddy Current Formulations},
year={2017},
volume={53},
number={6},
pages={1-4},
abstract={When solving eddy-current problems containing topologically non-trivial conductors with formulations using the magnetic scalar potential in the insulators, cohomology generators are necessary to obtain a well-defined problem. The Dłotko-Specogna (DS) algorithm is a simple and efficient tool to compute the lazy generators of the first cohomology group of the insulator that can be used in such potential design. This paper introduces an upgrade in the DS algorithm that speeds up the execution for very complicated geometries. Moreover, this paper provides, for the first time, a detailed comparison of computational resources needed for the topological pre-processing by our toolbox and by the tool to compute a standard cohomology basis available in the mesh generator GMSH. In addition, we make our implementation of DS algorithm available for download on request for non-profit use as a Topoprocessor package.},
keywords={Generators;Eddy currents;Software algorithms;Standards;Heating;Conductors;Insulators;Cohomology;computer aided software engineering;cuts;eddy currents;magnetic scalar potential;mathematical software},
doi={10.1109/TMAG.2017.2661480},
ISSN={1941-0069},
month={June},}
@INPROCEEDINGS{6836548,
author={Saito, Takuya and Mase, Kenichi},
booktitle={2013 International Conference on Advanced Computer Science Applications and Technologies},
title={DronePilot.NET Development: AR.Drone SDK Supporting Native and Managed Code},
year={2013},
volume={},
number={},
pages={60-64},
abstract={AR.Drone is a remote-controlled quad-rotor helicopter that is operated by computer instruction. Because communications between AR.Drone and a computer are complex, it is difficult to program AR.Drone software. Existing software development kits (SDKs) reduce those complexities, however, SDKs have many limitations. They can be difficult to use because the structure is too complex to understand, or their extensibility is too minimal for making a multifunctional application. To address these problems, we developed the new DronePilot.NET SDK. The DronePilot.NET SDK supports managed code, and it enables creation of user application programs using C# and Visual Basic. Moreover, because the proposed SDK includes code written in C++/CLI, it supports unmanaged code and enables direct access to native libraries. In addition, the DronePilot.NET SDK supports high-definition video data, image analysis by OpenCV, marker recognition by ARToolkit, and 3D object display by OpenGL. We measured the performance of our proposed SDK for processing video images and have verified its satisfactory performance.},
keywords={Libraries;Visual BASIC;Image resolution;Three-dimensional displays;High definition video;Face detection;AR.Drone;remote-controlled helicopter;managed code;native code},
doi={10.1109/ACSAT.2013.19},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5612812,
author={Yamashita, Makoto and Fujisawa, Katsuki},
booktitle={2010 IEEE International Symposium on Computer-Aided Control System Design},
title={Efficient parallel software for large-scale Semidefinite Programs},
year={2010},
volume={},
number={},
pages={1-6},
abstract={SemiDefinite Program (SDP) is one of principal problems in mathematical programming. Its application range is very wide and covers some problems arising from control theory; for example, a stability condition for differential inclusions and discrete-time optimal control problems. Solving these applications, however, sometimes requires long computation time, since they generate largescale SDPs. When Primal-Dual Interior-Point Methods (PDIPMs) are employed for solving large-scale SDPs, most of the computation time is occupied by the computation related to the Schur Complement Matrix (SCM). We have developed SDPARA (SemiDeflnite Programming Algorithm paRAllel version) to deal with such largescale SDPs. In particular, the latest version of SDPARA can handle sparse SCMs adequately. In this paper, we concisely describe how parallel implementation of SDPARA shortens the computation time of the SCM and then discuss the latest implementation for sparse SCMs. Numerical results show that SDPARA achieves remarkable parallel scalability and enables us to solve large-scale SDPs from control theory.},
keywords={Program processors;Scalability;Control theory;Sparse matrices;Tin;Software packages;Optimal control},
doi={10.1109/CACSD.2010.5612812},
ISSN={2165-302X},
month={Sep.},}
@INPROCEEDINGS{195501,
author={Sharpe, R.T. and Galyean, P.H. and Perga, A.W.},
booktitle={IEEE PLANS '88.,Position Location and Navigation Symposium, Record. 'Navigation into the 21st Century'.},
title={The Magnavox 4800 product family: a modular design for GPS user equipment},
year={1988},
volume={},
number={},
pages={323-328},
abstract={The architecture of a family of GPS (Global Positioning System) user equipment is discussed. Hardware and software design issues are examined including partitioning of the receiver electronics, system bus structure, processing algorithms, and receiver channel management strategies. A design is presented that is based on a small set of common hardware modules. The architecture described is extended to support receivers with 2 to 16 channels. This modular design approach is shown to meet a range of user equipment needs including differential GPS reference stations, pseudolites, navigators, and time recovery units.<>},
keywords={Global Positioning System;Packaging;Computer architecture;Hardware;Satellite navigation systems;Automatic control;Communication system control;Fires;Frequency synchronization;Software design},
doi={10.1109/PLANS.1988.195501},
ISSN={},
month={Nov},}
@INPROCEEDINGS{1515375,
author={Haeng-Kon Kim and Lee, R.Y. and Hae-Sool Yang},
booktitle={Fourth Annual ACIS International Conference on Computer and Information Science (ICIS'05)},
title={Notice of Violation of IEEE Publication Principles: Development of embedded software with component integration based on ABCD architectures},
year={2005},
volume={},
number={},
pages={54-60},
abstract={The state-of-the-art approaches to embedded real-time software development are very costly. The high development cost can be reduced significantly by using model-based integration of reusable components. To the ABCD (architecture, basic, common and domain) architecture, we propose an architecture that supports integration of software components and their behaviors, and reconfiguration of component behavior at executable-code-level. In the architecture, components are designed and used as building blocks for integration, each of which is modeled with event-based external interfaces, a control logic driver, and service protocols. The behavior of each component is specified as a finite state machine (FSM), and the integrated behavior is modeled as a nested finite state machine (NFSM). These behavior specifications can be packed into a control plan program, and loaded to a runtime system for execution or to a verification tool for analysis. With this architecture, embedded software can be constructed by selecting and then connecting (as needed) components in an asset library, specifying their behaviors and mapping them to an execution platform. Integration of heterogeneous implementations and vendor neutrality are also supported. Our evaluation based on machine tool control software development using this architecture has shown that it can reduce development and maintenance costs significantly, and provide high degrees of reusability.},
keywords={},
doi={10.1109/ICIS.2005.52},
ISSN={},
month={July},}
@INPROCEEDINGS{109815,
author={Harris, R.M. and Maseeh, F. and Senturia, S.D.},
booktitle={IEEE 4th Technical Digest on Solid-State Sensor and Actuator Workshop},
title={Automatic generation of a 3-D solid model of a microfabricated structure},
year={1990},
volume={},
number={},
pages={36-41},
abstract={The automatic construction of a 3-D solid model from a specification of mask layout and process sequence is demonstrated. The process sequence consists of planar deposition and masked etch. The generated 3-D solid model is directly usable by mechanical CAD software and is used to do a deformation analysis of the structure. An overview of the CAD system is given, and the structure simulator is described in detail.<>},
keywords={Solid modeling;Design automation;Material properties;Semiconductor device modeling;Mechanical sensors;Actuators;Predictive models;Microelectronics;Computer aided manufacturing;Packaging},
doi={10.1109/SOLSEN.1990.109815},
ISSN={},
month={June},}
@ARTICLE{238205,
author={Moshref, A. and Rodolakis, A.J. and Barnes, R. and Baba, Z. and Shah, S.},
journal={IEEE Computer Applications in Power},
title={Flexible transient stability software features user-defined models},
year={1993},
volume={6},
number={4},
pages={46-51},
abstract={The authors focus on CYMSTAB-UDM, a transient stability program that was designed to circumvent the restrictions associated with library-based simulation tools. Equipment libraries were kept available to the program, while at the same time allowing the user to carry out simulations using novel control strategies. Principles of implementation and the user interface of this approach are briefly described, and two successful applications are highlighted.<>},
keywords={Power system transients;Power system modeling;Power system stability;Power system simulation;Computational modeling;Equations;Power system analysis computing;Computer interfaces;Transient analysis;Computer simulation},
doi={10.1109/67.238205},
ISSN={1558-4151},
month={Oct},}
@INPROCEEDINGS{7754107,
author={Sundaramurthy, R. and Nagarajan, V.},
booktitle={2016 International Conference on Communication and Signal Processing (ICCSP)},
title={Design and implementation of reconfigurable virtual instruments using Raspberry Pi core},
year={2016},
volume={},
number={},
pages={2309-2313},
abstract={Virtual Instrument is a combination of hardware and software that allows the emulation of an instrument through a custom virtual console and a graphical user interface. A virtual instrument consists of a PC equipped with powerful application software, cost-effective hardware such as plug-in boards, which together perform the functions of traditional instruments. In a virtual instrument, it is the software which performs the actual process of measurement. Using virtual instruments one can design a customized instrument and automation setup that is user-defined instead of being limited by traditional fixed-function vendor-defined instruments. Virtual instruments are not efficient systems to handle time critical instrument tasks since they are run by a PC operating system which introduced substantial timing errors into the measurement. The Reconfigurable Virtual Instrument (RVI) system can be considered as a general purpose measurement instrument designed with reconfigurable hardware like FPGA connected to PC through a standard port. By designing a high level software application, one can select any specific instrument functionality from a library of instruments. The high level software application configures the RVI system to convert it into the selected instrument(s) with its associated console. By this technique, one can emulate multiple instrument functionalities like function generator, oscilloscope, multimeter, logic analyzer in a single hardware platform. In this paper, hardware realization of RVI is done using FPGA and Raspberry Pi core.},
keywords={Instruments;Hardware;Field programmable gate arrays;Pins;Kernel;Software measurement;Reconfigurable virtual instruments;Software Defined Instrumentation},
doi={10.1109/ICCSP.2016.7754107},
ISSN={},
month={April},}
@ARTICLE{1213677,
author={Correa, C.R. and Awad, S.S.},
journal={IEEE Transactions on Instrumentation and Measurement},
title={Embedded controller software and algorithm development tool},
year={2003},
volume={52},
number={3},
pages={885-890},
abstract={This paper describes the design and implementation of a flexible tool for use in developing embedded software and software algorithms. This tool is new and novel because of its capability of monitoring variables used in multiple internal processes (tasks) inside a modern microcontroller while simultaneously acquiring digital and analog data from a physical system to which the microcontroller is connected. Additionally, these data are automatically converted to engineering units. Many types of analog and digital signals (e.g., thermocouples, strain gauges, speeds, solenoid signals) that are not monitored by the processes inside the controller can be acquired. The internal microcontroller data is time aligned with the external digital and analog data so that information, on events and conditions that a control algorithm internal to the controller is subjected to, can be obtained and correlated to the internal state of the process running in the microcontroller. All data acquired with this tool is processed and sent to a host laptop computer via an Ethernet link and archived directly on the hard-drive of the laptop. Another novelty and new development with this tool is a new file format that accommodates large data files and allows for a post-analysis software package to be used to analyze the data.},
keywords={Embedded software;Software tools;Software algorithms;Microcontrollers;Signal processing;Portable computers;Algorithm design and analysis;Monitoring;Data engineering;Capacitive sensors},
doi={10.1109/TIM.2003.814358},
ISSN={1557-9662},
month={June},}
@ARTICLE{1207448,
author={Reifer, D.J. and Maurer, F. and Erdogmus, H.},
journal={IEEE Software},
title={Scaling agile methods},
year={2003},
volume={20},
number={4},
pages={12-14},
abstract={Using agile methods to develop large systems presents a thorny set of issues. If large teams are to produce lots of software functionality quickly, the agile methods involved must scale to meet the task. After all, a small team could create the software if the functionality to be delivered was small and, conversely, could be delivered given we had the time. Scaling agile teams thus becomes an issue if the only option for meeting a system delivery deadline is to have many developers working concurrently.},
keywords={Application software;Meeting planning;System testing;Software development management;Guidelines;Computer architecture;Software packages;Packaging;Software testing;Writing},
doi={10.1109/MS.2003.1207448},
ISSN={1937-4194},
month={July},}
@INPROCEEDINGS{9771705,
author={Assafra, Khadija and Alaya, Bechir and Abid, Mohamed},
booktitle={2022 IEEE Wireless Communications and Networking Conference (WCNC)},
title={Privacy preservation and security management in VANET based to Software Defined Network},
year={2022},
volume={},
number={},
pages={96-101},
abstract={Software Defined Network (SDN) is a new topology in the computer network; it offers several advantages such as virtualization and the division between the data plane and the control plane. These days we talk a lot about the SDN based on the vehicular network in particular on Vehicular Ad hoc Network VANET. The SDN solution in VANET is secure thanks to the presence of a controller, but this security remains insufficient which leads us to propose a more secure and lightweight solution. So our solution is composed of two phases; a phase for registering a vehicle near the VANET network controller, and a phase for authentication and generation session key between two vehicles. In both phases, we used Identity Based Encryption (IBE) to secure the exchange between the various entities of the architecture. We tested the performance of our solution by simulating it with the library MIRACL which offers implementations of elliptic curves and IBE. We have also formally validated our solution with Automated Validation of Internet Protocols and Applications (AVISPA). In conclusion, we have shown that our solution meets the security objectives of SDN in VANET while being a lightweight solution.},
keywords={Privacy;Elliptic curves;Security management;Vehicular ad hoc networks;Libraries;Routing protocols;Trajectory;SDN;SDVN;VANET;Security;Authentication;Cryptography},
doi={10.1109/WCNC51071.2022.9771705},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{4291142,
author={Jiang, Li and Eberlein, Armin},
booktitle={31st Annual International Computer Software and Applications Conference (COMPSAC 2007)},
title={A Tool For Requirements Engineering Process Development},
year={2007},
volume={2},
number={},
pages={319-325},
abstract={Using software engineering (SE) knowledge to support the software development process is challenging due to the complex structure of SE knowledge and the uncertain nature of large-scale software projects. However, already before developing software, establishing a development process suitable for the project at hand is another challenge. This paper presents a requirements engineering (RE) tool that contains a knowledge base to support RE process development and selection of RE techniques. The tool is built based on the Framework for Requirements Engineering pRocess dEvelopment (FRERE). The major merits of the tool over others is that the tool uses knowledge representation to manage the knowledge of the RE process and its technique, thus assisting development of the most suitable RE process for a software project.},
keywords={Software libraries;Knowledge engineering;Software tools;Computer aided software engineering;Application software;Guidelines;Computer architecture;Software engineering;Software quality;Programming},
doi={10.1109/COMPSAC.2007.47},
ISSN={0730-3157},
month={July},}
@INPROCEEDINGS{6156985,
author={Ginsberg, Myron and Frailey, Dennis J.},
booktitle={1975 IEEE 3rd Symposium on Computer Arithmetic (ARITH)},
title={The design and use of a floating-point (software) simulator for testing the arithmetic behavior of mathematical software},
year={1975},
volume={},
number={},
pages={56-63},
abstract={An important aspect of any evaluative procedure for developing high quality mathematical software is testing the effects of arithmetic behavior on algorithmic implementations. This paper describes a proposed design approach and various applications of a high-level language floating-point simulator which has two inputs: the program to be tested and a description of the floating-point arithmetic under which the routine is to be executed. A brief discussion of the motivation for this approach is given along with a review of existing efforts to study the influences of computer arithmetic on the accuracy and reliability of mathematical software. An overview of the simulator's structure is presented as well as suggestions for experiments to assist in determining the effects of floatingpoint behavior across several different computer architectures. Present and future uses of the simulator are also indicated.},
keywords={Accuracy;Software;Computers;Digital arithmetic;Testing;Libraries;Floating-point arithmetic},
doi={10.1109/ARITH.1975.6156985},
ISSN={},
month={Nov},}
@ARTICLE{8325321,
author={Palma, Francis and Moha, Naouel and Guéhéneuc, Yann-Gaël},
journal={IEEE Transactions on Software Engineering},
title={UniDoSA: The Unified Specification and Detection of Service Antipatterns},
year={2019},
volume={45},
number={10},
pages={1024-1053},
abstract={Service-based Systems (SBSs) are developed on top of diverse Service-Oriented Architecture (SOA) technologies or architectural styles. Like any other complex systems, SBSs face both functional and non-functional changes at the design or implementation-level. Such changes may degrade the design quality and quality of service (QoS) of the services in SBSs by introducing poor solutions-service antipatterns. The presence of service antipatterns in SBSs may hinder the future maintenance and evolution of SBSs. Assessing the quality of design and QoS of SBSs through the detection of service antipatterns may ease their maintenance and evolution. However, the current literature lacks a unified approach for modelling and evaluating the design of SBSs in term of design quality and QoS. To address this lack, this paper presents a meta-model unifying the three main service technologies: REST, SCA, and SOAP. Using the meta-model, it describes a unified approach, UniDoSA (Unified Specification and Detection of Service Antipatterns), supported by a framework, SOFA (Service Oriented Framework for Antipatterns), for modelling and evaluating the design quality and QoS of SBSs. We apply and validate UniDoSA on: (1) 18 RESTful APIs, (2) two SCA systems with more than 150 services, and (3) more than 120 SOAP Web services. With a high precision and recall, the detection results provide evidence of the presence of service antipatterns in SBSs, which calls for future studies of their impact on QoS.},
keywords={Simple object access protocol;Quality of service;Service-oriented architecture;Maintenance engineering;DSL;Antipatterns;service-based systems;REST;SCA;SOAP;web services;specification;detection;quality of service;design;software maintenance and evolution},
doi={10.1109/TSE.2018.2819180},
ISSN={1939-3520},
month={Oct},}
@INPROCEEDINGS{4382768,
author={Chateau, Frederic and Anvar, Shebli},
booktitle={2007 15th IEEE-NPSS Real-Time Conference},
title={A Framework for the Development and Integration of Configurations within Real-time, Embedded and Distributed Software in HEP Experiments},
year={2007},
volume={},
number={},
pages={1-6},
abstract={Real-time, embedded and distributed systems play an increasing part in HEP1 experiments. The increasing size and complexity of the associated software call for tools that make the development of such systems feasible. The Km3Net design study for a future underwater cubic kilometer neutrino telescope has given us the opportunity to develop a software framework simplifying the implementation and integration of configurations for such systems. In this paper, we present the features of this framework and the added value it brings about for designers and end-users. Important issues are addressed such as: adaptability to HEP collaborations development processes based on parallel team-work and collaboration-wide integration; automatic mapping of configurations on RDBMS2; example-based configuration specification; multi-OS GUI3 widgets for control applications; API4 for configuration access in embedded applications. This framework will be used both within the online software of the future cubic kilometer and the many test benches needed for the development of the whole system.},
keywords={Embedded software;Collaboration;Application software;Real time systems;Software tools;Optical design;Neutrino sources;Telescopes;Automatic control;Software testing},
doi={10.1109/RTC.2007.4382768},
ISSN={},
month={April},}
@INPROCEEDINGS{6569894,
author={Gramoli, Vincent and Guerraoui, Rachid and Letia, Mihai},
booktitle={2013 IEEE 27th International Symposium on Parallel and Distributed Processing},
title={Composing Relaxed Transactions},
year={2013},
volume={},
number={},
pages={1171-1182},
abstract={As the classic transactional abstraction is sometimes considered too restrictive in leveraging parallelism, a lot of work has been devoted to devising relaxed transactional models with the goal of improving concurrency. Nevertheless, the quest for improving concurrency has somehow led to neglect one of the most appealing aspects of transactions: software composition, namely, the ability to develop pieces of software independently and compose them into applications that behave correctly in the face of concurrency. Indeed, a closer look at relaxed transactional models reveals that they do jeopardize composition, raising the fundamental question whether it is at all possible to devise such models while preserving composition. This paper shows that the answer is positive. We present outheritance, a necessary and sufficient condition for a (potentially relaxed) transactional memory to support composition. Basically, outheritance requires child transactions to pass their conflict information to their parent transaction, which in turn maintains this information until commit time. Concrete instantiations of this idea have been used before, classic transactions being the most prevalent example, but we believe to be the first to capture this as a general principle as well as to prove that it is, strictly speaking, equivalent to ensuring composition. We illustrate the benefits of outheritance using elastic transactions and show how they can satisfy outheritance and provide composition without hampering concurrency. We leverage this to present a new (transactional) Java package, a composable alternative to the concurrency package of the JDK, and evaluate efficiency through an implementation that speeds up state of the art software transactional memory implementations (TL2, LSA, SwissTM) by almost a factor of 3.},
keywords={History;Concurrent computing;Software;Data structures;Semantics;Face;System recovery;transactional memory;multicore processing;scalability},
doi={10.1109/IPDPS.2013.42},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{1639556,
author={Quaglia, F.},
booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium},
title={Enhancing the performance of HLA-based simulation systems via software diversity and active replication},
year={2006},
volume={},
number={},
pages={8 pp.-},
abstract={In this paper we explore active replication based on software diversity for improving the responsiveness of simulation systems. Our proposal is framed by the high-level-architecture (HLA), namely the emerging standard for interoperability of simulation packages, and results in the design and implementation of an active replication management layer (ARML), which supports the execution of multiple software diversity-based replicas of a same simulator in a totally transparent manner. Beyond presenting the replication framework and the design/implementation of ARML, we also report the results of an experimental evaluation on a case study, quantifying the benefits from our proposal in terms of execution speed},
keywords={Software performance;Software systems;Context modeling;Proposals;Application software;Delay;Packaging;Production systems;Middleware;Data structures},
doi={10.1109/IPDPS.2006.1639556},
ISSN={1530-2075},
month={April},}
@INPROCEEDINGS{9304933,
author={Bolme, David S. and Srinivas, Nisha and Brogan, Joel and Cornett, David},
booktitle={2020 IEEE International Joint Conference on Biometrics (IJCB)},
title={Face Recognition Oak Ridge (FaRO): A Framework for Distributed and Scalable Biometrics Applications},
year={2020},
volume={},
number={},
pages={1-8},
abstract={The facial biometrics community has seen a recent abundance of high-accuracy facial analytic models become freely available. Although these models' capabilities in facial detection, landmark detection, attribute analysis, and recognition are ever-increasing, they aren't always straightforward to deploy in a real-world environment. In reality, the use of the field's ever growing collection of models is becoming exceedingly difficult as library dependencies update and deprecate. Researchers often encounter headaches when attempting to utilize multiple models requiring different or conflicting software packages. Face Recognition Oak Ridge (FaRO) is an open-source project designed to provide a highly modular, flexible framework for unifying facial analytic models through a compartmentalized plug-and-play paradigm built on top of the gRPC (Google Remote Procedure Call) protocol. FaRO's server-client architecture and flexible portability allows easy construction of modularized and heterogeneous face analysis pipelines, distributed over many machines with differing hardware and software resources. This paper outlines FaRO's architecture and current capabilities, along with some experiments in model testing and distributed scaling through FaRO.},
keywords={Face recognition;Biological system modeling;Pipelines;Servers;Protocols;Biometrics (access control);Libraries},
doi={10.1109/IJCB48548.2020.9304933},
ISSN={2474-9699},
month={Sep.},}
@INPROCEEDINGS{6645063,
author={Gorringe, Chris and Brown, Malcolm},
booktitle={2013 IEEE AUTOTESTCON},
title={Recommendations and best practices for creating reusable Test Signal Framework definitions},
year={2013},
volume={},
number={},
pages={1-9},
abstract={Critical to the successful implementation of Open System Architecture (OSA) test software, in accordance with the requirements of IEEE 1641[1][2], is the implementation Signal Libraries using the Test Signal Frameworks (TSFs) that provide the test program set (TPS) Developer with the suite of defined signals to be used for the test software. This paper aims to provide insight for the TPS developers and guidance on the best practices to be followed when creating and reusing Signal Libraries. It also considers issues to be kept in mind when bringing together a collection of existing Signal Libraries to be used for testing, and references examples that are available for future developers. The paper considers research into the effects of different methods that could be used for matching the TSFs used in describing UUT test requirements and instrument capabilities. This includes evaluation of their relative merits using a variety of “use cases” and example TSFs. Typical User questions are also considered along with their answers. The example TSFs referenced within the paper represent a collection of Signal Libraries available used in previous demonstrations and brought up to the IEEE Std. 1641-2010 standard. These include Signal Libraries provided as part of 1641 demonstrations and previous reports and form the basis of an OSA Signal Library. The technical analysis considers both symbolic signal expression and signal simulation, to address issues such as signal equivalence, quantization, phase jitter and overall performance. The purpose of the paper being to produce material for inclusion into recommendations and guidelines that will ensure best practice can be followed when generating Signal libraries for a wide range of signal types. This will ensure that Signal libraries are fit for purpose, and achieve the desired level of quality necessary for future matching UUT test requirements against the instrument capabilities. In addition, this will ensure that the UUT requirements are NOT over specified against the instrument capability used to initially implement the test solution. To ensure best practice across OSA RTS users, formal guidelines are required for the process of creating and defining IEEE 1641 TSFs in order to minimize differences between signal libraries and any effects that become apparent when implemented on different ATEs, using different instrumentation. The paper considers guidelines which could form the basis of a recommended practice to ensure standardization across the 1641 user base for use on Military or Commercial Automatic Test Systems (ATS).},
keywords={Libraries;IEEE standards;Abstracts;Instruments;XML;Accuracy;Signal Library;IEEE Std 1641;IEEE Std 1671;ATML;Test Signal Framework;TSF;simulation;modelling},
doi={10.1109/AUTEST.2013.6645063},
ISSN={1558-4550},
month={Sep.},}
@INPROCEEDINGS{9842121,
author={Frivaldsky, M. and Spanik, P. and Resutik, P. and Sedo, J.},
booktitle={2022 International Symposium on Power Electronics, Electrical Drives, Automation and Motion (SPEEDAM)},
title={Comparison of loss behavior of discrete type and power module SiC transistor in 3-phase NPC converter},
year={2022},
volume={},
number={},
pages={517-522},
abstract={The paper initially deals, with the design procedure of precise loss - simulation model of SiC power transistor in PLECS simulation software. Because SiC technology is currently spreading within most of the power converter applications, many manufactures are adapting their products to this technology. There are various power components differing by packaging technology, or given design approach, thus power transistors are exhibiting invariant performance when comparing individual components. However, the efficiency performance of any power semiconductor system is currently main qualitative indicator due to several reasons. Therefore, optimal selection of power transistor components represents essential design issue within initial design stages of power converter. Evaluation of the accuracy of PLECS loss-model compared to the results of mathematical calculations recommended for analyzed converter topology (NPC converter) is given here. Consequently, suitable SiC transistor structures are compared, while evaluation of the NPC converter efficiency was the main criterion for proper transistor selection guideline.},
keywords={Analytical models;Adaptation models;Silicon carbide;Multichip modules;Switching loss;Voltage;Power transistors;switching losses;conduction losses;NPC converter;efficiency;SiC transistor;comparison},
doi={10.1109/SPEEDAM53979.2022.9842121},
ISSN={},
month={June},}
@INPROCEEDINGS{5676852,
author={Feng, Jing and Huang, Liwei and Shen, Ye},
booktitle={2010 International Conference on Computational Intelligence and Software Engineering},
title={Research of Software Configuration Components Classification and Optimal Query},
year={2010},
volume={},
number={},
pages={1-4},
abstract={Software configuration management (SCM) controls and maintains the revision, integrity and traceability of software systems throughout the entire software life cycle. In order to solve the efficiency problems in construction, management and maintenance of software configuration component library, a component classification method based on priority-facet (PF-CCM) was proposed. Unifying the three kinds of component retrieval mechanisms, i.e., index, key word and facet, an optimized matching algorithm with pruning (POMA) was introduced, which sorts the query results according to the priority of facets. The experiments show that these works can improve the query efficiency.},
keywords={Software;Semantics;Libraries;Silicon;Linux;Algorithm design and analysis;Classification algorithms},
doi={10.1109/CISE.2010.5676852},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9640200,
author={Subramanya, Rakshith and Sierla, Seppo and Yli-Ojanperä, Matti and Makkonen, Henri and Pourakbari-Kasmaei, Mahdi and Vyatkin, Valeriy},
booktitle={2021 IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)},
title={Interfacing Third Party Cloud Services to a Virtual Power Plant},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Cloud computing is a megatrend in industry digitalization. The virtual power plant (VPP) is especially suited for cloud deployment since it can manage energy resources that are not co-located. However, there is a lack of research in VPP cloudification, mainly related to multi-tenancy, a key technology behind the efficiency benefits of cloud computing. Cloudification is complicated as power systems and distributed energy resources frequently employ interfaces and protocols from an earlier era. In particular, IEC 60870-5-104 is a well-established standard for telecontrol in electrical engineering and power system automation applications. This paper proposes a new perspective on VPP interoperability via the application of cloud computing. IEC 60870-5-104 enabled systems are integrated into third-party systems in the cloud. Examples of such third-party systems are the Internet of Things-enabled distributed energy resources or electricity market information systems. This paper proposes a new problem definition of VPP-connected systems through establishing the said third party systems as tenants in a multi-tenant architecture. To define a general industry standards-based system architecture, both the software design methods and cloud computing architectural concepts are applied. An implementation is presented that is ready to integrate into systems in the field.},
keywords={Industries;Cloud computing;Unified modeling language;Europe;Systems architecture;Virtual power plants;Power systems;virtual power plant;IEC 104;REST API;software as a service;cloud computing;smart grid},
doi={10.1109/ISGTEurope52324.2021.9640200},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8445086,
author={Sarcher, Julian and Scheglmann, Christian and Zoellner, Alexander and Dolereit, Tim and Schaeferling, Michael and Vahl, Matthias and Kiefer, Gundolf},
booktitle={2018 IEEE 29th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
title={A Configurable Framework for Hough-Transform-Based Embedded Object Recognition Systems},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Real-time object recognition on low-power embedded devices is a widely requested task, needed in manifold applications. However, it is still a demanding challenge to achieve desired performance goals. For example, for advanced driver assistance systems (ADAS) or autonomously driven cars, object recognition and lane detection are indispensable tasks. Another field of application is the continuous retrieval of the construction progress on-site for validation of the construction site status, by detecting installed components using a given CAD model. This paper presents a framework for highly customizable object detection systems implemented on a single heterogeneous computing chip leveraging FPGA logic and standard processors. The FPGA logic is used to implement a custom variation of the Hough Transform and further image processing tasks efficiently. The dedicated logic is supplemented with a software stack, which consists of a Linux operating system, including hardware access drivers, as well as high-level libraries like OpenCV and Robot Operating System (ROS) - all running on the same device. The capabilities of the system are demonstrated for three application scenarios, namely race track recognition, lane recognition and object detection tasks performed within a construction assistance system.},
keywords={Transforms;Hardware;Field programmable gate arrays;Object recognition;Computer architecture;Software;Generalized Hough Transform;FPGA;Heterogeneous Computing;Object Recognition;Computer Vision},
doi={10.1109/ASAP.2018.8445086},
ISSN={2160-052X},
month={July},}
@INPROCEEDINGS{929568,
author={Correa, C.R. and Awad, S.},
booktitle={IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)},
title={Embedded controller software and algorithm development tool},
year={2001},
volume={3},
number={},
pages={2105-2110 vol.3},
abstract={This paper describes the design and implementation of a flexible tool for use in developing embedded software and software algorithms. This tool is new and novel because of its capability of monitoring variables used in multiple internal processes (tasks) inside a modern micro-controller while simultaneously acquiring digital and analog data from a physical system that the micro-controller is connected to. Many types of analog and digital signals (e.g. thermocouples, strain gauges, speeds, solenoid signals) that are not monitored by the processes inside the controller can Ire acquired. The internal micro-controller data is time aligned with the external digital and analog data so that information, on events and conditions that a control algorithm internal to the controller is subjected to, can be obtained and correlated to the internal state of the process running in the micro-controller. All data acquired with this fool is processed and sent to a host laptop computer via TCP/IP on an Ethernet link and archived directly on the hard-drive of the laptop. Another novelty and new development with this fool is a new file format that accommodates large data files and allows for a post-analysis software package to be used to analyze the data.},
keywords={Embedded software;Software tools;Software algorithms;Signal processing;Portable computers;Algorithm design and analysis;Monitoring;Capacitive sensors;Solenoids;Strain control},
doi={10.1109/IMTC.2001.929568},
ISSN={1091-5281},
month={May},}
@INPROCEEDINGS{8627346,
author={Tavante, H. C. A. and Bonatto, B. D. and Coutinho, M. P.},
booktitle={2018 13th IEEE International Conference on Industry Applications (INDUSCON)},
title={Open Source Implementations of Electromagnetic Transient Algorithms},
year={2018},
volume={},
number={},
pages={825-828},
abstract={This paper describes an open source implementation of one of the most popular algorithms to solve electromagnetic transients circuits. Python was the selected language given its broad adoption into the science and engineering fields. This work reports the project structure and provides ideas for future implementations of an open source electromagnetic transient circuits program.},
keywords={Python;Tools;Software algorithms;Matlab;RLC circuits;Libraries;Industry Applications;Open Source Software;Electromagnetic Transients;Python;Functional Programming;Electrical Engineering},
doi={10.1109/INDUSCON.2018.8627346},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8760735,
author={Carrondo, Kristelle and Gil, Henrique},
booktitle={2019 14th Iberian Conference on Information Systems and Technologies (CISTI)},
title={The Potencial of «QR Code» in Education a Study in the 1st Cycle of Basic Education},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This study was carried out in the context of Supervised Practice in 1st Cycle Teaching, with a class of the 4th year of schooling at the Faria de Vasconcelos Basic School in Castelo Branco. The research focused on the potential of using the QR code in the 1st Cycle of Basic Education. As such, the objectives of this research were based on the promotion of the use of the QR Code in the 1st Cycle of Basic Education, in the implementation of the use of the QR Code in the scope of the curricular area of Portuguese, in the evaluation of the contribution of the QR Code in the teaching and learning process and in the analysis of the opinions of the students and the Cooperating Adviser regarding the contribution and impact of the QR Code in the curricular area of Portuguese. This study followed as a principle a methodology of qualitative nature in the research-action modality. Data collection instruments included: participant observation, field notes, photographic records, questionnaire survey and semi-structured interview. After the data collection, treatment and analysis, it was verified that the use of the digital application “QR Code” as a pedagogical resource was a decisive element for the improvement of students' vocabulary development, of textual production, more concretely in the writing of the synopses, in reading comprehension, in cooperation with others and in the students' sense of interest in the teaching and learning process. In addition, the project developed with the School Library was an added value, because it allowed the students to produce materials that demonstrated what they are capable, valuing their learning. In this way, a sense of pride and confidence grew in them, when they were authors of their own QR Codes.},
keywords={Education;Instruments;Software;Data collection;Interviews;Vocabulary;1st Cycle of Basic Education;Educational Software;Information and Communication Technologies;“QR Code”;Educational Software},
doi={10.23919/CISTI.2019.8760735},
ISSN={2166-0727},
month={June},}
@INPROCEEDINGS{9648807,
author={Chernov, Serhii and Titov, Serhii and Chernova, Liudmyla and Piterska, Varvara and Chernova, Liubava and Kunanets, Nataliia},
booktitle={2021 IEEE 16th International Conference on Computer Sciences and Information Technologies (CSIT)},
title={Three-Index Optimization Transportation Model},
year={2021},
volume={2},
number={},
pages={315-318},
abstract={This paper presents the features of the project implementation based on the developed mathematical model for optimizing delivery of products or resources (for instance: grain and oil crops) to the seaports on the south of Ukraine to form a regular batch for a vessel. The objective of the research is to form a mathematic model for minimizing the project cost of delivering the products from terminals to the seaport. The mathematic model of delivery cost minimization is reduced to a three-index transportation problem. Today we know both rigorous and approximate methods of solving such logistics problems. With account taken of a big number of variables in real-world problems, we composed a program of solving the problem in a Maple® symbol math computer package environment. The model example of optimization calculation provided in the paper shows reasonability of an automated approach to logistics problems for minimization of shipment cost. The practical value consists in the fact that the model is based on the today's condition of logistics structure in Ukraine. The scientific result obtained confirms it to be worth recommending to carry out such calculations. The paper includes an abstract of the program source code and the model problem solution, as well as recommendations on further refinement of the model.},
keywords={Costs;Computational modeling;Oils;Crops;Seaports;Minimization;Mathematical models;project management;project implementation;mathematic model;optimization;three-index transportation model;Maple® software;model solution},
doi={10.1109/CSIT52700.2021.9648807},
ISSN={2766-3639},
month={Sep.},}
@INPROCEEDINGS{7966898,
author={Jouet, Simon and Pezaros, Dimitrios P.},
booktitle={2017 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS)},
title={BPFabric: Data Plane Programmability for Software Defined Networks},
year={2017},
volume={},
number={},
pages={38-48},
abstract={In its current form, OpenFlow, the de facto implementation of SDN, separates the network's control and data planes allowing a central controller to alter the match-action pipeline using a limited set of fields and actions. To support new protocols, forwarding logic, telemetry, monitoring or even middlebox-like functions the currently available programmability in SDN is insufficient. In this paper, we introduce BPFabric, a platform, protocol, and language-independent architecture to centrally program and monitor the data plane. BPFabric leverages eBPF, a platform and protocol independent instruction set to define the packet processing and forwarding functionality of the data plane. We introduce a control plane API that allows data plane functions to be deployed on-the-fly, reporting events of interest and exposing network internal state to the centralised controller. We present a raw socket and DPDK implementation of the design, the former for large-scale experimentation using environment such as Mininet and the latter for high-performance low-latency deployments. We show through examples that functions unrealisable in OpenFlow can leverage this flexibility while achieving similar or better performance to today's static design.},
keywords={Protocols;Instruction sets;Control systems;Pipelines;Computer architecture;Hardware;SDN;OpenFlow;BPFabric;eBPF;Programmable Data Plane},
doi={10.1109/ANCS.2017.14},
ISSN={},
month={May},}
@INPROCEEDINGS{8675585,
author={Bardaro, Gianluca and Semprebon, Andrea and Chiatti, Agnese and Matteucci, Matteo},
booktitle={2019 Third IEEE International Conference on Robotic Computing (IRC)},
title={From Models to Software Through Automatic Transformations: An AADL to ROS End-to-End Toolchain},
year={2019},
volume={},
number={},
pages={580-585},
abstract={Modelling complex systems is a common practice and de facto standard across most application domains in engineering. Although it would seem unreasonable - and quite impractical - to build a structure as complex as a bridge without a reference blueprint detailing how to arrange all of its building blocks, in Software Development, and, particularly in the context of Robotics, examples adhering to rigorous modelling routines are still relatively rare to find. Yet, models help understanding complex problems while pinpointing their potential solutions, through abstraction. Further, models aid communication, i.e., the unambiguous exchange of reasoning processes across the involved agents. The complexity of Robotic Software Systems suggests that a widespread application of modelling techniques, from the very initial implementation stages, would (i) ease the definition, engineering and debugging of the related sub-features significantly, and (ii) guide collaborative efforts towards a common standard. To this aim, we presented a toolchain conceived for parsing an input AADL model into a compilable code suite. Keeping the model building and the linkage of the robot application with the ROS environment in the developer's hands, this framework delegates all the remaining tasks to an automated code generator, producing a fully-functioning ROS packages (i.e., already configured and ready for compiling) as output. We first presented the discussed framework, highlighted its related advantages - when compared to the only other similar approach found in the literature -, and used it as an exemplary use case, to prompt broader discussions on the benefits of model-based software development in Robotics.},
keywords={Robots;Message systems;Peer-to-peer computing;Computer architecture;Analytical models;Software packages;AADL;ROS;Code generation;Modeling;Robotics},
doi={10.1109/IRC.2019.00118},
ISSN={},
month={Feb},}
@INPROCEEDINGS{6726900,
author={Vallée, Geoffroy and Naughton, Thomas and Bohm, Swen and Engelmann, Christian},
booktitle={2013 First International Symposium on Computing and Networking},
title={A Runtime Environment for Supporting Research in Resilient HPC System Software & Tools},
year={2013},
volume={},
number={},
pages={213-219},
abstract={The high-performance computing (HPC) community continues to increase the size and complexity of hardware platforms that support advanced scientific workloads. The runtime environment (RTE) is a crucial layer in the software stack for these large-scale systems. The RTE manages the interface between the operating system and the application running in parallel on the machine. The deployment of applications and tools on large-scale HPC computing systems requires the RTE to manage process creation in a scalable manner, support sparse connectivity, and provide fault tolerance. We have developed a new RTE that provides a basis for building distributed execution environments and developing tools for HPC to aid research in system software and resilience. This paper describes the software architecture of the Scalable runTime Component Infrastructure (STCI), which is intended to provide a complete infrastructure for scalable start-up and management of many processes in large-scale HPC systems. We highlight features of the current implementation, which is provided as a system library that allows developers to easily use and integrate STCI in their tools and/or applications. The motivation for this work has been to support ongoing research activities in fault-tolerance for large-scale systems. We discuss the advantages of the modular framework employed and describe two use cases that demonstrate its capabilities: (i) an alternate runtime for a Message Passing Interface (MPI) stack, and (ii) a distributed control and communication substrate for a fault-injection tool.},
keywords={Topology;Runtime;Substrates;Context;Fault tolerance;Fault tolerant systems;Detectors},
doi={10.1109/CANDAR.2013.38},
ISSN={2379-1896},
month={Dec},}
@INPROCEEDINGS{9978213,
author={Bree, Déaglán Connolly and Cinnéide, Mel Ó},
booktitle={2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
title={The Energy Cost of the Visitor Pattern},
year={2022},
volume={},
number={},
pages={317-328},
abstract={Design patterns are applied frequently during software evolution in order to make the software more flexible and amenable to extension. One little-studied aspect of design patterns is their propensity to increase run time energy consumption due to the indirection and additional structure they introduce. In this paper we study the impact of the Visitor pattern on energy efficiency. The Visitor pattern separates an algorithm from the objects it acts upon and improves maintainability by placing each algorithm within a single visitor class, at the cost of increased indirection due to the double dispatch required when the algorithm is invoked. We experimentally investigate the energy impact of varying the implementation of this pattern, and of removing the pattern entirely from the software. In our results we observe energy consumption reductions of greater than 7% in the textbook example when the pattern is implemented using reflective casting, and reductions of over 10% when experimenting with an open source project, JavaParser. The complete removal of the pattern yields more complex results, with little impact in the textbook example but reductions of over 7% in the JavaParser study. Our results highlight the energy savings that may be achieved when the Visitor pattern is removed, and show that energy savings may also be achieved by varying the implementation of the pattern.},
keywords={Energy consumption;Software maintenance;Casting;Costs;Software algorithms;Programming;Libraries;Empirical;Design Patterns;Visitor Pattern;Green Technology;Energy Efficiency;Refactoring;Software Transformation;Software Design;Object-Oriented Programming},
doi={10.1109/ICSME55016.2022.00036},
ISSN={2576-3148},
month={Oct},}
@ARTICLE{8493283,
author={Ventre, Pier Luigi and Tajiki, Mohammad Mahdi and Salsano, Stefano and Filsfils, Clarence},
journal={IEEE Transactions on Network and Service Management},
title={SDN Architecture and Southbound APIs for IPv6 Segment Routing Enabled Wide Area Networks},
year={2018},
volume={15},
number={4},
pages={1378-1392},
abstract={The SRv6 architecture (segment routing based on IPv6 data plane) is a promising solution to support services like Traffic Engineering, service function chaining and virtual private networks in IPv6 backbones and datacenters. The SRv6 architecture has interesting scalability properties as it reduces the amount of state information that needs to be configured in the nodes to support the network services. In this paper, we describe the advantages of complementing the SRv6 technology with an software defined networking (SDN) based approach in backbone networks. We discuss the architecture of a SRv6 enabled network based on Linux nodes. In addition, we present the design and implementation of the Southbound API between the SDN controller and the SRv6 device. We have defined a data-model and four different implementations of the API, respectively based on gRPC, REST, NETCONF, and remote command line interface. Since it is important to support both the development and testing aspects we have realized an Intent-based emulation system to build realistic and reproducible experiments. This collection of tools automate most of the configuration aspects relieving the experimenter from a significant effort. Finally, we have realized an evaluation of some performance aspects of our architecture and of the different variants of the Southbound APIs and we have analyzed the effects of the configuration updates in the SRv6 enabled nodes.},
keywords={Linux;Routing;Hardware;Multiprotocol label switching;Virtual private networks;Software defined networking;Software defined networking (SDN);segment routing (SR);SRv6;Southbound APIs;open source},
doi={10.1109/TNSM.2018.2876251},
ISSN={1932-4537},
month={Dec},}
@INPROCEEDINGS{8892015,
author={Giamblanco, Nicholas V. and Anderson, Jason H.},
booktitle={2019 29th International Conference on Field Programmable Logic and Applications (FPL)},
title={A Dynamic Memory Allocation Library for High-Level Synthesis},
year={2019},
volume={},
number={},
pages={314-320},
abstract={One impediment to the uptake of high-level synthesis (HLS) design methodologies is their lack of support for constructs frequently employed by software engineers - a primary example being dynamic memory allocation routines. No commercial HLS tool supports these constructs, forcing designers to rewrite programs to remove any dynamic memory allocation function calls (e.g.malloc(), free()), replacing them with statically allocated data. This shortcoming limits the portability of C/C++ descriptions, may introduce software bugs, and forces users to overestimate memory requirements, consuming precious on-chip BRAM resources. We address these problems by extending the capabilities of modern HLS tools through introduction of a tool-independent, HLS-friendly C library of five dynamic memory allocation schemes. Additionally, we developed a benchmark suite to evaluate and compare all five allocation schemes for their performance, area and memory trade-offs. We use the high-level synthesis tool, LegUp, to conduct our experiments. Our results indicate that each allocator in our library is best-suited for certain applications, in terms of performance, area and memory usage. We provide usage guidelines to assist HLS developers in selecting an appropriate allocation scheme.},
keywords={Resource management;Memory management;Dynamic scheduling;Hardware;Random access memory;Libraries;Tools;High-Level Synthesis, Dynamic Memory Allocation, Algorithms, Abstract Data Structures},
doi={10.1109/FPL.2019.00057},
ISSN={1946-1488},
month={Sep.},}
@INPROCEEDINGS{5756905,
author={Bischoff, Rainer and Guhl, Tim and Prassler, Erwin and Nowak, Walter and Kraetzschmar, Gerhard and Bruyninckx, Herman and Soetens, Peter and Haegele, Martin and Pott, Andreas and Breedveld, Peter and Broenink, Jan and Brugali, Davide and Tomatis, Nicola},
booktitle={ISR 2010 (41st International Symposium on Robotics) and ROBOTIK 2010 (6th German Conference on Robotics)},
title={BRICS - Best practice in robotics},
year={2010},
volume={},
number={},
pages={1-8},
abstract={In the past, the process of developing a new robot application has had more of the design of a piece of artwork or of an act of ingenious engineering than of a structured and formalized process. The prime objective of BRICS is to structure and formalize the robot development process itself and to provide tools, models, and functional libraries, which allow reducing the development time by a magnitude. BRICS is working together with academic as well as industrial providers of robotics "components" (hardware and software), to identify and document best practices in the development of complex robotics systems, to refactor (together) the existing components in order to achieve a much higher level of reusability and robustness, and to support the robot development process with a structured tool chain and code repository. BRICS is a joint research project funded by the European Commission ICT Challenge 2 under grant number 231940. First results include the analysis of existing robot development processes, the first steps towards harmonizing robot control interfaces and component models and the set-up of robot systems for best practice analyses.},
keywords={Robustness;Robot kinematics;Software;Hardware;Service robots;Best practices},
doi={},
ISSN={},
month={June},}
@INPROCEEDINGS{8711853,
author={Aslam, Sohaib and Ahsan, Muhammad and Hannan, Sundas and Hamza, Muhammad and Jaffery, Mujtaba},
booktitle={2019 International Conference on Engineering and Emerging Technologies (ICEET)},
title={Development of a Software Based PIC24F Series Microcontroller Educational Trainer},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Microcontroller based system designing is playing an important role in embedded systems industry. Therefore, microcontroller subject is considered as one of the vital subjects in scheme of studies offered to students of Electrical and Computer Engineering in universities and other colleges of science, engineering and technology. To enhance the expertise in embedded systems implementation, this paper presents designing of a software based 16-bit PIC24F series microcontroller educational trainer by using MPLAB and Proteus Professional software packages. This is to help students to apply their theoretical knowledge to real-time problems at any time. The trainer includes number of experiments i-e interfacing of LEDs, seven segment display, LCD, Keypad, DC motor, UART and EPROM. At first step, the designing of trainer for various experiments include development of algorithms in MPLAB and then simulations are done in Proteus.},
keywords={Microcontrollers;Pulse width modulation;Liquid crystal displays;Registers;Pins;DC motors;Software;Educational Trainer;MPLAB PIC microcontroller;Proteus},
doi={10.1109/CEET1.2019.8711853},
ISSN={2409-2983},
month={Feb},}
@ARTICLE{5712775,
author={},
journal={IEEE Std 26514-2010},
title={IEEE Standard for Adoption of ISO/IEC 26514:2008 Systems and Software Engineering--Requirements for Designers and Developers of User Documentation},
year={2011},
volume={},
number={},
pages={1-72},
abstract={This standard provides requirements for the design and development of software user documentation as part of the life cycle processes. It defines the documentation process from the viewpoint of the documentation developer. It also covers the documentation product. It specifies the structure, content, and format for user documentation, and also provides informative guidance for user documentation style. It is independent of the software tools that may be used to produce documentation, and applies to both printed documentation and on-screen documentation. Much of this standard is also applicable to user documentation for systems including hardware.},
keywords={IEEE standards;IEC standards;ISO standards;Software engineering;Testing;26514;information design;information development;procedures;software user documentation;user manual},
doi={10.1109/IEEESTD.2011.5712775},
ISSN={},
month={Jan},}
@ARTICLE{846162,
author={Frommel, M. and Hoffmann-Schulz, G. and Litvinenko, E. and Ziem, P.},
journal={IEEE Transactions on Nuclear Science},
title={BEAN-a new standard program for data analysis at BER-II},
year={2000},
volume={47},
number={2},
pages={272-275},
abstract={A program package BEAN (BENSC Analysis Program) has been developed to provide a standard for the analysis of one-dimensional neutron spectra gathered at the experiment facilities of BENSC. The main purpose was to replace the large number of heterogeneous software packages which has been developed in the past for each neutron spectrometer separately. BEAN runs on a UNIX application server which is embedded in a client/server architecture with NFS filesystem. Data display is performed by means of the PV-WAVE software tools. For easy use the graphical user interface follows the common styling guidelines of Windows programs.},
keywords={Data analysis;Neutrons;File servers;Packaging;Standards development;Software packages;Spectroscopy;Application software;Computer architecture;Displays},
doi={10.1109/23.846162},
ISSN={1558-1578},
month={April},}
@INPROCEEDINGS{8289775,
author={Ward, Aaron and Awad, Selim S.},
booktitle={2017 13th International Computer Engineering Conference (ICENCO)},
title={A novel language-adaptable accent reduction software template},
year={2017},
volume={},
number={},
pages={124-129},
abstract={This paper presents key elements of an Android mobile phone application designed to improve English speech fluency by accent reduction, with techniques designed to be generalizable to other languages and accessible to researchers with limited financial resources for implementation. After development, the software was implemented on a Samsung Galaxy S6, a common device for personal and business use. This paper will present existing approaches to this problem and associated issues, selection and use of existing open-source speech-recognition tools, and a general software architecture for using these tools in accent reduction applications. In particular, use of the CMU Sphinx software and associated corpi on the Android platform, changes that must be made to use the software in an accent reduction application, and practical considerations when designing an associated Graphical User Interface will be discussed. Finally, the Android Python port ”Kivy” and its practicality for this purpose will also be discussed. It was found that CMU Sphinx can run well on Android if implemented carefully, and be used to provide a rich user experience with both aural and visual feedback, although finding appropriate corpi for some languages can pose difficulty. Unfortunately, Kivy was found to be unreliable due to packaging errors.},
keywords={Software;Dictionaries;Smart phones;Google;Acoustics;Speech;Visualization;Phonemes;Finite State Machine;Speech Therapy;Accents;Mobile;Android;Human Factors;Embedded},
doi={10.1109/ICENCO.2017.8289775},
ISSN={2475-2320},
month={Dec},}
@INPROCEEDINGS{973002,
author={Jung-Eun Cha and Young-Jung Yang and Mun-Sub Song and Hang-Gon Kim},
booktitle={2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236)},
title={Design and implementation of component repository for supporting the component based development process},
year={2001},
volume={2},
number={},
pages={735-740 vol.2},
abstract={CBD (component based software development) has become an interesting field in the development of business applications. Because CBD represents a new development paradigm for composing applications from software components, increasing requirements for productivity of flexible system development can be solved using CBD technologies. The component repository is the most important part in the CBD process. In practice, to reuse components in CBD deployment, we must store and manage the related work-products from each step of component development as well as the component itself using a component repository. In this paper, we try to clarify CBD-related theories as practical techniques to be applied to real systems. So, we suggested individual technique theory for repository construction to support and realize the CBD process. CRPS (component repository prototyping system) was also constructed for supporting the CBD process based on architecture. CRPS supports the CBD process by managing the variety of component products classified by each step of the component life cycle and business domain based on component architecture.},
keywords={Component architectures;Application software;Prototypes;Assembly;Business;Productivity;Software engineering;Telecommunication computing;Programming;Computer architecture},
doi={10.1109/ICSMC.2001.973002},
ISSN={1062-922X},
month={Oct},}
@INPROCEEDINGS{5750327,
author={Larsen, R. S.},
booktitle={2010 17th IEEE-NPSS Real Time Conference},
title={PICMG xTCA standards extensions for Physics: New developments and future plans},
year={2010},
volume={},
number={},
pages={1-7},
abstract={After several years of planning and workshop meetings, a decision was reached in late 2008 to organize PICMG xTCA for Physics Technical Subcommittees to extend the ATCA and MTCA telecom standards for enhanced system performance, availability and interoperability for physics controls and applications hardware and software. Since formation in May-June 2009, the Hardware Technical Subcommittee has developed a number of ATCA, ARTM, AMC, MTCA and RTM extensions to be completed in mid-to-late 2010. The Software Technical Subcommittee is developing guidelines to promote interoperability of modules designed by industry and laboratories, in particular focusing on middleware and generic application interfaces such as Standard Process Model, Standard Device Model and Standard Hardware API. The paper describes the prototype design work completed by the lab-industry partners to date, the timeline for hardware releases to PICMG for approval, and the status of the software guidelines roadmap. The paper also briefly summarizes the program of the 4th xTCA for Physics Workshop immediately preceding the RT2010 Conference.},
keywords={Physics;Timing;Backplanes;Hardware;Software;Availability;Prototypes;PICMG - PCI Industrial Computer Manufacturers Group;a consortium of over 250 companies dedicated to the development and maintenance of PICMG open-source specifications including PCI and ATCA platforms;ATCA - Advanced Telecommunications Computing Architecture;the first architecture designed for high availability of 5-nines (0.99999);ARTM - ATCA Rear Transition Module;AMC - Advanced Mezzanine Card;which can reside on an ATCA Carrier board or in a separate MTCA shelf;MTCA - MicroTCA;specifically the chassis or shelf that supports AMC cards in the same manner as an ATCA carrier;μRTM - Micro Rear Transition Module;a feature allowed but not specified nor implemented in current industrial designs;xTCA - the generic ATCA - and TCA family of specifications},
doi={10.1109/RTC.2010.5750327},
ISSN={},
month={May},}
@INPROCEEDINGS{9426081,
author={Lata, Kusum and Saini, Sandeep},
booktitle={2020 IEEE International Symposium on Smart Electronic Systems (iSES) (Formerly iNiS)},
title={Hardware Software Co-Simulation of an AES-128 based Data Encryption in Image Processing Systems for the Internet of Things Environment},
year={2020},
volume={},
number={},
pages={260-264},
abstract={Security of the data is a major challenge in the deployment and management of the Internet of Things (IoT) systems in the heterogeneous environment, where data gets transferred very widely and rapidly in multiple modes across the globe. Concomitant with the advancement of the technology, the number of devices and systems which are involved in transferring the image data has increased in the heterogeneous IoT environment. At present, image processing devices have become an integral part of the IoT edge devices which can collect the images and automatically share with the network. Because of the multifaceted usage of images in multimedia applications in the IoT environment, it is essential to protect the data from unauthorized access. The Advanced Encryption Standard (AES) is a well-established cryptography algorithm used in numerous applications to protect digital data. In this paper, we present a Hardware-Software Co-Simulation with Xilinx System Generator of an AES-128 bit encryption and decryption for IoT Edge devices. Hardware Co-Simulation makes it possible to integrate a design running in an FPGA directly into Simulink simulation. AES-128 bit algorithm has been implemented on the SPARTAN-6 (XC6SLX45-CSG324) FPGA board with XILINXISE software. Authors can get the successful results for image encryption and decryption both while implementing on grey and colored images. For Hardware Co-Simulation of AES-128 bit algorithm with Xilinx system generator, a point-to-point Ethernet approach is used. This implementation is done using Xilinx ISE14.2 and MATLAB 2011a for both grey image and colored image of size 448*298.},
keywords={Performance evaluation;Software packages;Image edge detection;Software algorithms;Computer architecture;Generators;Hardware;Cryptography;FPGA;AES-128;VHDL;Image encryption;Image decryption;Hardware Co-Simulation;Internet of Thing;Image Processing},
doi={10.1109/iSES50453.2020.00065},
ISSN={},
month={Dec},}
@ARTICLE{1617814,
author={},
journal={IEEE Std 1666-2005},
title={IEEE Standard SystemC(R) Language Reference Manual},
year={2006},
volume={},
number={},
pages={1-423},
abstract={SystemC(R) is defined in this standard. SystemC(R) is an ANSI standard C++ class library for system and hardware design for use by designers and architects who need to address complex systems that are a hybrid between hardware and software. This standard provides a precise and complete definition of the SystemC(R) class library so that a SystemC(R) implementation can be developed with reference to this standard alone. The primary audiences for this standard are the implementers of the SystemC(R) library, the implementers of tools supporting the class library, and users of the class library. The IEEE 1666™ program grants public access to view and download the current individual IEEE standard at no charge in PDF format thanks to the Open System C Initiative. Visit http://standards.ieee.org/about/get/index.html for details.},
keywords={IEEE Standards;Patents;Libraries;Hardware;Manuals;Design automation;C++;computer languages;digital systems;discrete event simulation;electronic design automation;electronic system level;electronic systems;embedded software;fixed-point;hardware description language;hardware design;hardware verification;SystemC;system modeling;system-on-chip;transaction level},
doi={10.1109/IEEESTD.2006.99475},
ISSN={},
month={March},}
@INPROCEEDINGS{9782923,
author={Thu, Yein M. and Shestopalova, Tatyana A. and Tyagunov, Michael G. and Haiyang, He},
booktitle={2022 VI International Conference on Information Technologies in Engineering Education (Inforino)},
title={Program for the Selection of Sites to construct Renewable Energy Plants based on the Method of Analytic Hierarchy Process (AHP)},
year={2022},
volume={},
number={},
pages={1-5},
abstract={Modern energy development involves the widespread use of power plants based on renewable energy sources (RES), such as hydropower, solar, wind, geothermal, tidal, wave, etc. This direction is associated not only with the struggle for carbon neutrality, but also with ensuring the energy security of territories that provide themselves with energy from their own energy resources, and renewable energy sources in one ratio or another are available in any country in the world. However, the modern view of the use of renewable energy sources is mostly related to the gross potential of energy resources. Although, all organizations that have built at least one plant of this kind clearly understand that there are many reasons that do not allow using the rich gross potential of renewable energy in practice. There are natural or climatic anomalies, instability of international or internal political relations, and the absence or lack of qualified personnel, the necessary design, construction and operation of renewable energy facilities. The task of choosing the location for the construction of priority renewable energy facilities is one of the central ones for the energy strategy of the countries. This task is the subject of this article, which proposes the practical use of the methodology created bythe authors in the form of the software package "Program for the placement of installations based on renewable energy sources in a given territory" in C ++ language for choosing optimal places for the construction of renewable energy plants using the method of analytical hierarchies. The power complex, the location of which is assessed by the program, includes a solar photovoltaic plant, a hydraulic plant, a wind plant, and a tidal electric plant. With the help of the "Program for the placement of installations based on renewable energy sources in a given area", the selection of optimal locations for the construction of renewable energy plants in Myanmar was carried out.},
keywords={Renewable energy sources;Visualization;Wind;Software packages;Energy resources;Hydraulic systems;Analytic hierarchy process;software package "Program for the placement of installations based on renewable energy sources in a given area";Energy complex;renewable energy sources;solar;wind;hydraulic and tide},
doi={10.1109/Inforino53888.2022.9782923},
ISSN={},
month={April},}
@INPROCEEDINGS{9448964,
author={Javel, A. de and Gomez, J. S. and Martins, P. and Rougier, J. L. and Nivaggioli, P.},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)},
title={Towards a new open-source 5G development framework: an introduction to free5GRAN},
year={2021},
volume={},
number={},
pages={1-5},
abstract={5G technology has been designed with flexibility and software reusability in mind. In this context, open-source developments are critical enablers for mastering software architecture and associated codes, which are of the utmost importance for all technology stakeholders (ranging from manufacturers to operators and service users). free5GRAN is a new open-source 5G development framework. It focuses on research and education. It provides a modular architecture and a set of well-documented APIs, which enable easy experiment reproduction. free5GRAN aims at easing the understanding of 5G standards and the development of new technology components. The global objective is to be as modular as GnuRadio project [1], but with full system implementation. It has not been designed with performances in mind, unlike other open-source projects such as srsLTE [2] and OpenAirInterface [3]. The current release implements a significant part of the PHY layer on the receiver side, and the MAC layer will be part of a future release. Its architecture, which is composed of a library and an implementation part, is described. Moreover, RAN components are explained, and custom implementation methods are provided. It has been tested and validated against a commercial Amarisoft 5G SA gNodeB in a Faraday Cage.},
keywords={Vehicular and wireless technologies;5G mobile communication;Software architecture;Computer architecture;Receivers;Stakeholders;Software reusability;Software Defined Radio;5G;Open-source},
doi={10.1109/VTC2021-Spring51267.2021.9448964},
ISSN={2577-2465},
month={April},}
@INPROCEEDINGS{1250178,
author={Holzman, L.E. and Fisher, T.A. and Galitsky, L.M. and Kontostathis, A. and Pottenger, W.M.},
booktitle={Proceedings. 15th IEEE International Conference on Tools with Artificial Intelligence},
title={A software infrastructure for research in textual data mining},
year={2003},
volume={},
number={},
pages={112-121},
abstract={Few tools exist that address the challenges facing researchers in the textual data mining (TDM) field. Some are too specific to their application, or are prototypes not suitable for general use. More general tools often are not capable of processing large volumes of data. We have created a textual data mining infrastructure (TMI) that incorporates both existing and new capabilities in a reusable framework conductive to developing new tools and components. TMI adheres to strict guidelines that allow it to run in a wide range of processing environments - as a result, it accommodates the volume of computing and diversity of research occurring in TDM. A unique capability of TMI is support for optimization. This facilitates text mining research by automating the search for optimal parameters in text mining algorithms. In this article we describe a number of applications that use the TMI. We present several novel results that have not been published elsewhere. We also discuss how the TMI utilizes existing machine-learning libraries, thereby enabling researchers to continue and extend their endeavors with minimal effort. Towards that end, TMI is available on the web at hddi.cse.lehigh.edu.},
keywords={Data mining;Time division multiplexing;Text mining;Libraries;Machine learning algorithms;Computer science;Data engineering;Design engineering;Application software;Prototypes},
doi={10.1109/TAI.2003.1250178},
ISSN={1082-3409},
month={Nov},}
@INPROCEEDINGS{6172944,
author={Kolbasin, Viacheslav A. and Ivanov, Alexey I. and Pedash, Vyacheslav Y.},
booktitle={2011 2nd International Conference on Advancements in Nuclear Instrumentation, Measurement Methods and their Applications},
title={Software realization of real-time neutrons and γ-rays pulse shape discrimination using CUDA platform},
year={2011},
volume={},
number={},
pages={1-4},
abstract={The two pulse shape discrimination methods were implemented in real-time. The pulse gradient analysis method was implemented programmatically on PC. The method based on artificial neural network was programmatically implemented using CUDA platform. It is shown that both implementations can provide up to 106 pulses per second processing performance. The results for pulse shape discrimination using polycrystalline stilbene and LiF detectors were shown.},
keywords={Graphics processing unit;Artificial neural networks;Neurons;Detectors;Electronics packaging;Instruction sets;Shape},
doi={10.1109/ANIMMA.2011.6172944},
ISSN={},
month={June},}
@INPROCEEDINGS{48095,
author={Yang, S. and Lewis, T.G. and Hsieh, C.-C.},
booktitle={[1989] Proceedings of the Twenty-Second Annual Hawaii International Conference on System Sciences. Volume II: Software Track},
title={Integrating computer-aided software engineering and user interface management systems},
year={1989},
volume={2},
number={},
pages={850-859 vol.2},
abstract={Oregon Speedcode Universe (OSU) is a software development environment for design, implementation, and maintenance of large software systems. Designed to be highly visual, OSU combines traditional structured-analysis techniques found in most computer-aided software engineering tools with the advanced graphical user-interface management systems found on most contemporary workstations. The design and implementation of four minute features of OSU are described: (1) the combination of functional decomposition with object-oriented design; (2) alternate architectural views, e.g. call graph, uses graph, object graph, and graphical display of procedures; (3) program understanding tools for design and maintenance; and (4) merging the user-interface specification with design and coding specifications.<>},
keywords={Computer aided software engineering;User interfaces;Engineering management;Programming profession;Prototypes;Displays;Software libraries;Software reusability;Computer science;Software maintenance},
doi={10.1109/HICSS.1989.48095},
ISSN={},
month={Jan},}
@INPROCEEDINGS{1639578,
author={Gopalakrishnan, G. and Kirby, R.},
booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium},
title={Toward reliable and efficient message passing software through formal analysis},
year={2006},
volume={},
number={},
pages={7 pp.-},
abstract={The quest for high performance drives parallel scientific computing software design. Well over 60% of the high-performance computing (HPC) community writes programs using the MPI library; to gain performance, they are known to perform many manual optimizations. Even tools that accept high level descriptions often generate MPI code, due to its eminent portability. However, since the overall performance of a program does not usually port (due to variations in the target architecture, cluster size, etc.), manual changes to the code are inevitable in today's approaches to MPI programming and optimization. This, together with the vastness and evolving nature of the MPI standard, and the innate complexity of concurrent programming introduces costly bugs. Our research addresses these challenges through specific efforts in the following broad areas: (i) high level expression of the parallel algorithm and compilation thereof into optimized MPI programs, (ii) optimizations of user-written detailed MPI programs through localized transformations such as barrier removal, (iii) formal modeling of complex communication standards, such as the MPI-2 standard and a facility for answering putative queries (this need arises when standard documents are impossibly difficult to manually study in order to answer questions that are not explicitly addressed in the standard), (iv) formal modeling of new (and hence relatively less well understood) features of communication libraries, such as the one-sided communication facility of MPI-2, and (v) formal modeling of intricate control algorithms in these libraries such as the progress engine for TCP and/or shared memory in MPICH2 (a formal model can explicate commonalities, help formally verify, as well as help create better future implementations). Our research gains focus through numerous collaborations},
keywords={Message passing;Communication standards;Scientific computing;Software design;High performance computing;Software libraries;Performance gain;Computer bugs;Parallel algorithms;Communication system control},
doi={10.1109/IPDPS.2006.1639578},
ISSN={1530-2075},
month={April},}
@INPROCEEDINGS{6968975,
author={Anastasi, Gaetano F. and Carlini, Emanuele and Coppola, Massimo and Dazzi, Patrizio and Distefano, Marco},
booktitle={2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)},
title={An OVF toolkit supporting Inter-Cloud application splitting},
year={2014},
volume={},
number={},
pages={96-101},
abstract={The Open Virtualization Format (OVF) is a software packaging standard designed to support the portability and deployment of applications in different virtualization platforms. Ease interoperability and portability among cloud providers is of paramount importance to mitigate vendor lock-in and fostering cooperation among different cloud technologies. To this end, the researcher community is spending a lot of effort in investigating cloud broker and cloud federation solutions. However, we feel that the community still misses an open-source reference tool for the management of these operations when it comes to the OVF standard. With the aim to fill this gap, we propose the OVF Toolkit, an open tool to parse, render, and split OVF files. This paper describes the principal design decisions, the implementation, and the capabilities of the toolkit, as well as its experimental evaluation.},
keywords={Home appliances;Standards;Software;Data structures;Virtualization;XML;Conferences;Cloud Computing;Utility programs;Software libraries;Open Virtualization Format},
doi={10.1109/CloudNet.2014.6968975},
ISSN={},
month={Oct},}
@INPROCEEDINGS{882175,
author={Champeau, J. and Dhaussy, P. and Latreille, L.},
booktitle={OCEANS 2000 MTS/IEEE Conference and Exhibition. Conference Proceedings (Cat. No.00CH37158)},
title={Mission control with the UML and SDL formalisms},
year={2000},
volume={3},
number={},
pages={1639-1645 vol.3},
abstract={The mission control system for an AUV is a sub-system which is integrated in the overall software development but in many cases the formalism used is completely different from the software design formalism. A generic behavior is associated with a set of functionalities which is the core language for the mission programming. This effort of generalisation is important to provide an abstraction level of the mission control environment. Following these guidelines, our approach is based on a behavior model coupled to an object software design. The object design is accepted like an efficient concept for the management of different levels of abstraction with a high level of reusability. The mission control system will not become a particular language but a specialized object framework without a particular target language. The mission control framework is integrated in the software design methodology of the overall AUV development like a special package. The static structure system is described by class diagrams. The cooperation between the different objects in the system is represented by sequence and collaboration diagrams. We specify the behavior of the active objects through SDL processes which have very precise semantics. The sequence diagram, enables us to add a graphical representation of the dynamic behavior of the system to the SDL descriptions. One of the major benefits with a design notation like SDL that has well-defined and complete semantics, is the possibility to test the application already in the design activity. The formal description of the SDL processes behavior then allows the test by simulation and its validation inside a software environment, like Telelogic-TAU. First, we describe the global object model. The software is then created for the mission code generation and finally the framework is implemented on the embedded targets.},
keywords={Unified modeling language;Software design;Control systems;Functional programming;Guidelines;Software packages;Packaging;Collaboration;Testing;Application software},
doi={10.1109/OCEANS.2000.882175},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9078290,
author={Kaddour, Abdelmadjid and Benmebrouk, Lazhar and Bekkouche, Simohamed Amine and Benyoucef, Boumédiène and Bezari, Salah and Khenniche, Rachid},
booktitle={2019 7th International Renewable and Sustainable Energy Conference (IRSEC)},
title={Improvement of the Stand-Alone PV System Performance by PVSYST Software},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Simulation of Standalone photovoltaic systems is essential to predict the performances of an eventual installation of such facility. Simulation tool enables determination of minimums and peak electricity production. This paper presents the evaluation of standalone photovoltaic system using the software package PVsyst. The objective of the simulation work was to design a reliable SAPV system and predicts its yearly energy production efficiency. SAPV configuration simulation was presented using PVsyst software. The total electrical energy that may be supplied by the system as well as power losses were also determined. The accurate determination of the optimum tilt angle for the location of interest is essential for maximum energy production by the system, by the optimization tool in our software Pvsyst, for determining this optimal tilt. This article described a practical implementation of solar photovoltaic system to supply power to a semi-arid location of Ghardaïa. Of the obtained results were the configuration and the optimal size of the generator. Also given were total power fluxes and methods of the optimization were sufficiently detailed and discussed.},
keywords={Optimization;Standalone PV system;Performance;Degradation},
doi={10.1109/IRSEC48032.2019.9078290},
ISSN={2380-7393},
month={Nov},}
@INPROCEEDINGS{10817,
author={Reingeard, C. and Maloeuvre, M.},
booktitle={1988. IMTC-88. 5th IEEE Instrumentation and Measurement Technology Conference},
title={CALIBRAT software to facilitate control, setting and calibration of measurement instruments},
year={1988},
volume={},
number={},
pages={48-51},
abstract={The features of CALIBRAT, a software package designed to facilitate quality assurance plan implementation, are described. It provides a set of powerful tools that use specific IEEE-488 bus command-oriented keywords and an instrument-manager to provide independence between the language and the instruments. CALIBRAT can be run on a personal computer with a GPIB-PCI or PC2 National Instruments Board.<>},
keywords={Calibration;Software measurement;Instruments;High level languages;Military computing;System testing;Writing;Hardware;Control systems;Storage area networks},
doi={10.1109/IMTC.1988.10817},
ISSN={},
month={April},}
@INPROCEEDINGS{5708024,
author={Cobos, Jordi and Arranz, Javier and Belotti, Alessandra and Marcote, Manuel},
booktitle={2010 5th ESA Workshop on Satellite Navigation Technologies and European Workshop on GNSS Signals and Signal Processing (NAVITEC)},
title={ODATIS: A generic multi-constellation operational precise orbit determination package},
year={2010},
volume={},
number={},
pages={1-4},
abstract={The Orbit Determination and Time Synchronization (ODATIS) tool is a generic operational Precise Orbit Determination package developed by DEIMOS Space S.L.U. ODATIS was conceived and designed from the very beginning as the starting point for the implementation of any Flight Dynamics System, with emphasis on covering all phases of any type of Earth orbiter, in terms of mission operations.},
keywords={Orbits;Accuracy;Global Positioning System;Clocks;Satellites;Earth;Data models;Flight Dynamics;Navigation;Precise Orbit Determination;operational software},
doi={10.1109/NAVITEC.2010.5708024},
ISSN={2325-5455},
month={Dec},}
@INPROCEEDINGS{667203,
author={Fatoohi, R.},
booktitle={Proceedings of the Thirtieth Hawaii International Conference on System Sciences},
title={Performance evaluation of communication software systems for distributed computing},
year={1997},
volume={1},
number={},
pages={100-109 vol.1},
abstract={In recent years, there has been an increasing interest in object-oriented distributed computing since it is better equipped to deal with complex systems while providing extensibility, maintainability and reusability. At the same time, several new high-speed network technologies have emerged for local- and wide-area networks. However, the performance of networking software is not improving as fast as that of the networking hardware and the workstation microprocessors. This paper gives an overview and evaluates the performance of the Common Object Request Broker Architecture (CORBA) standard in a distributed computing environment at NASA Ames Research Center. The environment consists of two testbeds of SGI workstations connected by four networks: Ethernet, FDDI, HiPPI and ATM. The performance results for three communication software systems are presented, analyzed and compared. These systems are: BSD socket programming interface, IONA's Orbix, an implementation of the CORBA specification, and the PVM message-passing library. The results show that high-level communication interfaces, such as CORBA and PVM, can achieve reasonable performance under certain conditions.},
keywords={Software systems;Distributed computing;Workstations;High-speed networks;Software performance;Hardware;Microprocessors;Computer architecture;NASA;Testing},
doi={10.1109/HICSS.1997.667203},
ISSN={1060-3425},
month={Jan},}
@INPROCEEDINGS{870394,
author={Morisio, M. and Seaman, C.B. and Parra, A.T. and Basili, V.R. and Kraft, S.E. and Condon, S.E.},
booktitle={Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium},
title={Investigating and improving a COTS-based software development process},
year={2000},
volume={},
number={},
pages={32-41},
abstract={The work described in the paper is an investigation of COTS based software development within a particular NASA environment, with an emphasis on the processes used. Fifteen projects using a COTS based approach were studied and their actual process was documented. This process is evaluated to identify essential differences in comparison to traditional software development. The main differences, and the activities for which projects require more guidance, are requirements definition and COTS selection, high level design, integration and testing. Starting from these empirical observations, a new process and guidelines for COTS based development are developed and briefly presented. The new process is currently under experimentation.},
keywords={Programming;Software packages;Packaging;Software engineering;Permission;Standards development;Software tools;Software maintenance;Educational institutions;NASA},
doi={10.1145/337180.337186},
ISSN={0270-5257},
month={June},}
@INPROCEEDINGS{1349623,
author={Far, B.H.},
booktitle={Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513)},
title={A collective view and methodologies for software agents' interaction},
year={2004},
volume={3},
number={},
pages={1249-1252 Vol.3},
abstract={Software agents' interactions are of special importance when a group of agents interact with each other to solve a problem that is beyond the capability and knowledge of each individual. Efficiency, performance and the overall quality of multi-agent applications depend mainly on how the agents interact with each other. We present an agent model by which we can distinguish different agent's interaction scenarios. The model has five attributes: goal; control; interface; identity; knowledge base. Using the model, we analyze and describe possible scenarios. Then, for each scenario, appropriate reasoning and decision-making techniques are devised. The model can readily be used in the design and implementation of multi-agent systems.},
keywords={Software agents;Decision making;Object oriented modeling;Uncertainty;Multiagent systems;Application software;Libraries;Design engineering;Drives;Fault tolerant systems},
doi={10.1109/CCECE.2004.1349623},
ISSN={0840-7789},
month={May},}
@INPROCEEDINGS{8261643,
author={Gutiérrez, Sebastián and Sánchez, Claudia N. and Alvarez, Jerónimo and Domínguez-Soberanes, Julieta},
booktitle={2017 IEEE International Autumn Meeting on Power, Electronics and Computing (ROPEC)},
title={A comparative analysis of finite element programs for their implementation in a graphic tool of insulated power cables},
year={2017},
volume={},
number={},
pages={1-6},
abstract={In this article a summary is presented of the main commercial and non-commercial finite element analysis programs required for the electrical, thermal and magnetic study of isolated electric power cables, according to the programming needs and their implementation in the design and development of a graphical simulation tool of this type. The type of selected program allowed to develop the three types of analysis required, to be programmed through an API (Application Programming Interface) and integrated directly into the graphical simulation tool.},
keywords={Finite element analysis;Mathematical model;Adaptation models;Tools;Computational modeling;Two dimensional displays;Solid modeling;finite element method;power cables;simulation tool;software},
doi={10.1109/ROPEC.2017.8261643},
ISSN={2573-0770},
month={Nov},}
@INPROCEEDINGS{1420130,
author={Raghavan, R. and Irwin, M.J. and McInnes, L.C. and Norris, B.},
booktitle={19th IEEE International Parallel and Distributed Processing Symposium},
title={Adaptive software for scientific computing: co-managing quality-performance-power tradeoffs},
year={2005},
volume={},
number={},
pages={7 pp.-},
abstract={Current trends in microprocessor design indicate that chips are approaching their packaging thermal limits, and the power-related costs of high-performance clusters and multiprocessors continue to grow as a quadratic function of peak execution rates and clock frequencies. Although a faster scientific simulation, such as one obtained by exploiting quality-performance tradeoffs, is also often one that consumes less power by using fewer compute cycles, a major challenge is developing explicitly power-aware scientific computing tools that can exploit special energy-saving features of the circuit fabric. Such tools are perhaps most natural when scientific computing involved sparse or irregular computations, for example, simulations based on partial differential equations in two or three spatial dimensions solved using implicit or semi-implicit schemes. Sparse kernels typically cannot execute near peak rates of the CPU's, and there is potential for tuning them to co-manage both power and performance characteristics. Furthermore, each sparse kernel often has a variety of implementations offering a wide range of tradeoffs in solution quality (e.g., accuracy, reliability, and scalability) and performance (e.g., execution time/rate and parallel efficiency/speedup). Consequently, proper method selection to meet changing application quality-of-service requirements and changing technologies can potentially provide dramatic performance improvements and savings in energy by using circuit fabric features such as dynamic voltage scaling. Our goal is to design adaptive tools for sparse computations that deliver reduced-energy realizations without adversely impacting application performance. In this paper, we provide an overview of our project and discuss some initial results.},
keywords={Software quality;Scientific computing;Computational modeling;Circuit simulation;Fabrics;Kernel;Microprocessors;Packaging;Cost function;Clocks},
doi={10.1109/IPDPS.2005.83},
ISSN={1530-2075},
month={April},}
@INPROCEEDINGS{10015341,
author={Meyer, Tom and Andelfinger, Philipp and Ruscheinski, Andreas and Uhrmacher, Adelinde M.},
booktitle={2022 Winter Simulation Conference (WSC)},
title={Seamless Simulation-Based Verification and Validation of Event-Driven Software Systems},
year={2022},
volume={},
number={},
pages={2130-2141},
abstract={Verification and validation (V&V) are essential concerns in the development of safety-critical distributed software systems. V&V efforts targeting full system implementations rely on testing, which requires real-world deployments and cumbersome analysis to track down issues across distributed software components. Here, we propose a simulation-based development and testing framework for distributed systems following the event-driven architecture (EDA) paradigm. During development, unmodified software components can be executed in their interaction with a simulated environment, allowing for early testing under envisioned deployments. After introducing the interplay of EDA and discrete-event simulation, we present our framework's architecture and the API offered to software components, which closely follows accepted EDA principles. We demonstrate the use of our framework on a medical software system used in the diagnosis of rare genetic diseases. By observing the system's interaction with simulated laboratories, the feedback loop between diagnoses by laboratories and classifications from the software system is evaluated.},
keywords={Target tracking;Laboratories;Computer architecture;Quality of service;Production;Software systems;Middleware},
doi={10.1109/WSC57314.2022.10015341},
ISSN={1558-4305},
month={Dec},}
@INPROCEEDINGS{6881520,
author={Moctar, Yehdhih Ould Mohammed and Brisk, Philip},
booktitle={2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC)},
title={Parallel FPGA routing based on the operator formulation},
year={2014},
volume={},
number={},
pages={1-6},
abstract={We have implemented an FPGA routing algorithm on a shared memory multi-processor using the Galois API, which offers speculative parallelism in software. The router is a parallel implementation of PathFinder, which is the basis for most commercial FPGA routers. We parallelize the maze expansion step for each net, while routing nets sequentially to limit the amount of rollback that would likely occur due to misspeculation. Our implementation relies on non-blocking priority queues, which use software transactional memory (SMT), to identify the best route for each net. Our experimental results demonstrate scalability for large benchmarks and that the amount of available parallelism depends primarily on the circuit size, not the inter-dependence of signals. We achieve an average speedup of approximately 3x compared to the most recently published work on parallel multi-threaded FPGA routing, and up to 6x in comparison to the single-threaded router implemented in the publicly available Versatile Place and Route (VPR) framework.},
keywords={Routing;Field programmable gate arrays;Benchmark testing;Runtime;Data structures;Instruction sets;Parallel processing;Field Programmable Gate Array (FPGA);Routing;Routing Resource Graph (RRG);Maze Expansion;Irregular Algorithm;Software Transactional Memory (STM)},
doi={10.1145/2593069.2593177},
ISSN={0738-100X},
month={June},}
@INPROCEEDINGS{1559603,
author={Jasiunas, M. and Kearney, D. and Bowyer, R.},
booktitle={2005 IEEE Aerospace Conference},
title={Connectivity, Resource Integration, and High Performance Reconfigurable Computing for Autonomous UAVs},
year={2005},
volume={},
number={},
pages={1-8},
abstract={In an investigation into the capabilities of small autonomous formations of unmanned aerial vehicles (UAVs), we identified connectivity, processing power, and lack of resource integration as three major limiting factors of current technology. In an endeavor to address these issues, we propose a new novel hardware and software environment consisting of a traditional Von Neumann processor coupled with a field programmable gate array (FPGA) for high performance processing, along with support libraries to better manage the resources of a formation. The supporting software libraries have the primary functions of allowing any networked resource (such as processors and UAV sensors) to be accessed from any location in the UAV formation, and also provide support that allows algorithms implemented simultaneously on the reconfigurable and traditional processors to migrate between UAVs for better connectivity to resources or to balance processing loads. In this paper we present the issues we faced in the design of these systems, along with our preliminary results indicating the advantages and shortcomings of the system. We also describe in detail the construction of the prototype systems used to determine the correct software settings for the mobile algorithms},
keywords={High performance computing;Unmanned aerial vehicles;Field programmable gate arrays;Software libraries;Software algorithms;Hardware;Software performance;Environmental management;Resource management;Software prototyping},
doi={10.1109/AERO.2005.1559603},
ISSN={1095-323X},
month={March},}
@ARTICLE{9316662,
author={Chen, Long and Xia, Chunhe and Lei, Shengwei and Wang, Tianbo},
journal={IEEE Access},
title={Detection, Traceability, and Propagation of Mobile Malware Threats},
year={2021},
volume={9},
number={},
pages={14576-14598},
abstract={In recent years, the application of smartphones, Android operating systems and mobile applications have become more prevalent worldwide. To study the traceability, propagation, and detection of the threats, we perform research on all aspects of the end-to-end environment. With machine learning based on the mobile malware detection algorithms that integrate the dynamic and static research of the identification algorithm, application software samples are collected to study sentences. Through knowledge labeling and knowledge construction, the association relationship of knowledge is extracted to realize the research of knowledge map construction. Flooding is closely correlated with the complexity of the Android mobile version of the kernel and malicious programs. A static dynamic analysis of the mobile malicious program is carried out, and the social network social diagram is constructed to model the propagation of the mobile malicious program. We extended the approach of deriving common malware behavior through graph clustering. On this basis, Android behavior analysis is performed through our virtual machine execution engine. We extend the family characteristics to the concept of DNA race genes. By studying SMS/MMS, Bluetooth, 5G base station networks, metropolitan area networks, social networks, homogeneous communities, telecommunication networks, and application market ecosystem propagation scenarios, we discovered the law of propagation. In addition, we studied the construction of the mobile Internet big data knowledge graph. Quantitative data for the main family chronology of mobile malware are obtained. We conducted detailed research and comprehensive analysis of Android application package (APK) details and behavior, relationship, resource-centric, and syntactic aspects. Furthermore, we summarized the architecture of mobile malware security analysis. We also discuss encryption of malware traffic discrimination. These precise modeling and quantified research results constitute the architecture of mobile malware analysis.},
keywords={Smart phones;Malware;Security;Internet;Mobile applications;Data privacy;Computer architecture;Android mobile malware;threat traceability;family chronology;propagation models;detection analysis;infected system environment;knowledge map construction;architecture of mobile malware security analysis},
doi={10.1109/ACCESS.2021.3049819},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{5695334,
author={Liu, Ling and Morozov, Oleksii},
booktitle={2010 International Conference on Reconfigurable Computing and FPGAs},
title={A Process-Oriented Streaming System Design Paradigm for FPGAs},
year={2010},
volume={},
number={},
pages={370-375},
abstract={This paper presents a streaming system design paradigm that allows developers to model streaming applications and their FPGA-based many-core hardware architectures as processes and channels. We have developed a programming language called System-Oberon, together with a run-time library, a hardware library implemented on an FPGA, and a compiler to automate the system design flow. In general, the proposed paradigm represents a software-driven approach to the streaming system designs on FPGAs. Compared to the existing solutions, our system design paradigm and its tool chain allow the automatic construction of a completely autonomous system on an FPGA, support the task-level parallelism from both software and hardware levels, and avoid the need for hardware programming work for application developers. These features make the proposed approach advantageous in achieving better results regarding the system's performance, power consumption, design reuse and time-to-market. To prove the applicability of our approach, a monitor for real-time ECG signal analysis was built and analyzed for its performance, size, power consumption and development time.},
keywords={Program processors;Electrocardiography;Field programmable gate arrays;Hardware;Libraries;System analysis and design;Transmission line measurements;automatic streaming system design;FPGA;many-core architecture},
doi={10.1109/ReConFig.2010.39},
ISSN={2325-6532},
month={Dec},}
@INPROCEEDINGS{5952232,
author={Sărăcin, Cristina Gabriela and Sărăcin, Marin},
booktitle={2011 7TH INTERNATIONAL SYMPOSIUM ON ADVANCED TOPICS IN ELECTRICAL ENGINEERING (ATEE)},
title={Software applications designed to optimize the voltage drops of the low voltage electric power supply installations},
year={2011},
volume={},
number={},
pages={1-6},
abstract={The developed software applications are dedicated to optimize the voltage drops of the low voltage electric power installations. Thru optimizing, it is understood the loading capacity estimation of the electrical potential of the transformer posts and the voltage droppings calculation for the formed elements of the electric power supply installations. The obtained values are later compared with the prescribed admitted values within the I7-2009 standardization. In idea to obtain these applications, they were created data bases with the electric installations components (commutation equipments, protection equipments and conductive elements). The applications are made on the principle of databases interrogations. The applications implementation is performed based on the Microsoft software package specific applications, Excel and Visual Basic. The second programming option has the advantage of object-oriented programming elements combining with event-oriented programming features. We have chosen these programming environments due to the fact that, these applications could be started on any computer which has installed the Microsoft Office software package.},
keywords={Reactive power;Power supplies;Power transformers;Receivers;Conductors;Graphical user interfaces},
doi={},
ISSN={2068-7966},
month={May},}
@INPROCEEDINGS{10033299,
author={du Plessis, Michael and Bam, Wouter},
booktitle={2022 IEEE 28th International Conference on Engineering, Technology and Innovation (ICE/ITMC) & 31st International Association For Management of Technology (IAMOT) Joint Conference},
title={iops: a Python package for the Input-Output Product Space methodology},
year={2022},
volume={},
number={},
pages={1-8},
abstract={Industrial diversification towards increasingly com-plex products is understood to be key to economic development. The Product Space (PS) is a tool that supports the analysis of countries' productive structures and the identification of promising routes for future development. The PS and associ-ated complexity indices highlight the relationship between the capabilities of countries and the successful export of complex products. The Input-Output Product Space (IO-PS) applies the PS and its associated metrics to a value chain. The results from the tool can inform industry-specific analyses by identifying avenues of development and quantifying their potential impact. Despite the utility of these approaches, the open-source packages that support PS- related analyses and their accessibility have left much to be desired. This has likely hampered the even greater uptake of these approaches. This article provides an overview of the most comprehensive implementations of the PS and IO-PS in Python, MATLAB and R to date. It identifies a number of incongruities between these packages and gaps in their application. Based on the shortcomings identified, a novel open-source Python package for the IO-PS that consolidates the disparate implementations is presented. It applies the IO-PS analysis approach to a chosen value chain and includes extended functionality compared to the original IO-PS in MATLAB and PS in Python and R. It incorporates trade data summation, analysis without a value chain and normalization toggling. The article makes a contribution by providing the first open-source Python IO-PS package and consolidating the existing implementations by explaining - and addressing - their differences.},
keywords={Measurement;Economics;Complexity theory;Standards;Matlab;input-output product space;product space;economic complexity;python;open-source;software},
doi={10.1109/ICE/ITMC-IAMOT55089.2022.10033299},
ISSN={},
month={June},}
@ARTICLE{1707631,
author={Bishop, J. and Horspool, N.},
journal={Computer},
title={Cross-Platform Development: Software that Lasts},
year={2006},
volume={39},
number={10},
pages={26-35},
abstract={The design of software that is easy to port or deliberately targeted for multiple platforms is a neglected area of software engineering. A promising solution is to link components and toolkits through XML and reflection. One of the more compelling definitions of software engineering is, the multiperson construction of multiversion software. The popular view of software engineering focuses on the first part of this definition - managing teams to produce a large product. But just as important is the view inherent in the second part of the definition - identifying specific parts of a product so that experts can design them and organizations can mass-produce them free of language and environment dependencies. Component-based software engineering has made tremendous strides toward satisfying both parts of the definition. Through the use of middleware constructed using reflection and controlled through XML specifications, it is possible to give the components in a large software system a high degree of platform and even language independence. The result is long lived software that can migrate gracefully as platforms improve and change},
keywords={Operating systems;Software libraries;Software performance;Hardware;Java;Application software;Graphical user interfaces;Costs;Middleware;Reflection;software engineering;cross-platform development},
doi={10.1109/MC.2006.337},
ISSN={1558-0814},
month={Oct},}
@INPROCEEDINGS{4338333,
author={Gao, Juntao and Zhang, Li and Jiang, Wei},
booktitle={International Conference on Semantic Computing (ICSC 2007)},
title={Procuring Requirements for ERP Software Based on Semantic Similarity},
year={2007},
volume={},
number={},
pages={61-70},
abstract={Enterprise resource planning (ERP) system is one of the most widely accepted choices to gain competitive edge for manufacturing related enterprises. However, the rate of successful implementation is lower than expected. One of the main reasons is that there is a gap between application domain and software discipline. In this paper, a methodology is proposed to procure the requirements for ERP software, by which both sides do their jobs in their familiar domain. The methodology consists three phases: business modeling, gap analysis, requirement analysis for software. This paper focuses on the second phase, which aims at identifying the business processes beyond the capability of ERP software. Based on ontology an algorithm to measure the similarity of business process models is designed and Hungarian algorithm is used to reduce its time complexity. Finally, an experiment is given to evaluate the method.},
keywords={Enterprise resource planning;Computer aided manufacturing;Computer science;Application software;Best practices;Software packages;Ontologies;Extraterrestrial measurements;Time measurement;Process design},
doi={10.1109/ICSC.2007.45},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{1264732,
author={Blankenheim, K.R. and Tate, R.},
booktitle={33rd Annual Frontiers in Education, 2003. FIE 2003.},
title={Integrating Linux into a Windows-based campus network: modifying open source/free software in support of the computer science curriculum},
year={2003},
volume={2},
number={},
pages={F3C-9},
abstract={Open source/free software can be extremely powerful and valuable at little or no cost. Student familiarity with open source/free software is essential for success in the computer science environment. It does, however include some risks: heterogeneous network security concerns, a steep learning curve, and frequent bureaucratic restrictions to overcome. This project overcame these concerns while providing a powerful suite of open source tools to interested students at no cost. More specifically, the software package adheres to security constraints of the institution's existing Windows-based network. Accompanying the package is an easy to follow, Web-based instruction manual allowing novice users to install a dual-boot Linux/Windows operating system configuration. Specialized programs validate user authorization and align Linux with existing network security settings. This product answered a genuine need to provide students the opportunity to learn about Linux and its benefits as a fully featured, application-rich, alternative operating system. The paper includes the results from the initial implementation and fielding of the distribution in the dormitories as well as the specific development, design, and implementation details. The paper provides a guide to engineers and educators who wish to broaden their computing abilities and opportunities by integrating new computer technologies into an existing network environment. It describes the analysis, process, and problems associated with selecting and implementing software for a heterogeneous network with administrative concerns. The presentation includes a demonstration of the software package and the Web based training program.},
keywords={Linux;Open source software;Computer science;Costs;Software packages;Operating systems;Computer networks;Power system security;Packaging;Manuals},
doi={10.1109/FIE.2003.1264732},
ISSN={0190-5848},
month={Nov},}
@INPROCEEDINGS{8903382,
author={Wang, Yiqing and Liu, Xin and Wu, Xiangyu and Yuan, Xuye and Meng, Jia and Tang, Yujiao},
booktitle={BIBE 2019; The Third International Conference on Biological Information and Biomedical Engineering},
title={AMPrimer: An R package for anchored multiplex PCR primer design},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Next-generation sequencing (NGS) has revolutionized life science for its ability to massively parallel sequencing. The quality of sequencing highly depends on the quality of the library constructed using PCR. A novel PCR has been developed to tackle some problems in the analysis of NGS termed anchored multiplex PCR (AMP), such as PCR bias. AMP has been shown as a robust and powerful method to enrich targets. Primer design plays an important role in library construction. We implemented an R package, AMPrimer, a panel for designing primers used in AMP. AMPrimer functions as an interface communicating R and Primer3, an opensource primer design software. The input file of AMPrimer contains the location of targets needed to be amplified. Target sequences are classified into two categories according to their length. Longer sequences are split into shorter fragments due to the sequencer's ability. Boulder-IO file fed into Primer3 is also generated by R. Primer3 would be used twice. The first run of Primer3 is to generate outer primers while the second run of Primer3 is to generate inner primers. Primer pairs are evaluated in terms of directionality, nested primer location, and secondary structure.},
keywords={},
doi={},
ISSN={},
month={June},}
@INPROCEEDINGS{938049,
author={Kolodnytsky, M.M. and Koivalchuk, A.M. and Kuryata, S.V. and Levitsky, V.G.},
booktitle={Proceedings of the 23rd International Conference on Information Technology Interfaces, 2001. ITI 2001.},
title={Interactive visual software system for problem solving and teaching in finite group theory},
year={2001},
volume={},
number={},
pages={409-416 vol.1},
abstract={The article shows how to solve some computational problems in finite group theory using the software system "DSR Open Lab 1.0" designed and developed by authors. We consider such computational problems as follows: the construction of the group using given elements or a genetic code (generators and relations), the operations with the group elements as well as the calculations of subgroups and their powers, normal subgroup, factor-group, etc. We also give a comparison of the user interface implementation of our software with Maple V Release 5. The presented examples show that the process of problem solving and teaching in finite group theory has become easier and more interactive now, due to the visual user interface of the presented software.},
keywords={Software systems;Problem-solving;Education;Content addressable storage;Genetics;Power generation;User interfaces;Software tools;Algebra;Packaging},
doi={10.1109/ITI.2001.938049},
ISSN={1330-1012},
month={June},}
@INPROCEEDINGS{8812865,
author={Alam, Omar},
booktitle={2019 IEEE/ACM International Conference on Software and System Processes (ICSSP)},
title={Towards an Agile Concern-Driven Development Process},
year={2019},
volume={},
number={},
pages={155-159},
abstract={This paper proposes an Agile Concern-Driven Development (Agile CDD) process, a software development process that uses concerns as its primary artifact and applies agile practices. Whereas classical Model-Driven Engineering (MDE) methodologies focus on models that are built from scratch with little support for reuse, Agile CDD is a reuse-focused development process in which an application is built incrementally by repeatedly reusing other existing concerns. In Agile CDD, a modeler would use a modelling language that is appropriate for the current development phase and for the problem domain. Model transformations would then be applied to produce the initial set of models for the next phase. The process will continue until an execute model is produced. In each phase, the modeller should consult a repository of reusable concerns to identify and reuse concerns. Changing requirements are welcome and incomplete implementations are moved to the next iteration by delaying design decisions.},
keywords={Unified modeling language;Software;Adaptation models;Authentication;Libraries;Analytical models;Tools;Agile;Software Process;Software Reuse;Model Driven Development},
doi={10.1109/ICSSP.2019.00028},
ISSN={},
month={May},}
@INPROCEEDINGS{5783175,
author={Stepalina, Ekaterina},
booktitle={2010 6th Central and Eastern European Software Engineering Conference (CEE-SECR)},
title={SaaS support in software documentation systems},
year={2010},
volume={},
number={},
pages={192-197},
abstract={In recent days more and more software developments tools become distributed by the SaaS (Software-As-A Service) model alongside with ready-to-install products. The developers of task and bug tracking systems now offer their solutions by a monthly fee. For instance, JIRA Studio produced by Atlassian can be connected to a corporative domain by subscription. This scheme allows software companies to reduce costs at the project's start and get scalable resources in future. Software documentation systems can also be purchased by a subscription now. The effectiveness of their usage for various documentation development is interesting. There are four major types of documentation supporting the development process and resulted products: project, technical, code and user documentation. Each of this type claims specific requirements for the documentation tool. The requirement analysis shows that rented documentation systems are the most appropriate for user and technical documentation. There are two major classes of software documentation systems: 1) Wiki, 2) DITA-orientedXML CMS. The following wiki systems have a hosted version: commercial Confluence, Central Desktop, EditMe, Incentive, Netcipia, PBWiki, Wikia, Wikispaces; open source BusinessWiki, Metadot Wiki, MindTouch, Wagn, Wikidot. The richest by the functionality andplugin collection is Confluence produced by Atlassian. The following XML CMS are offered by a SaaS model (all are commercial): Astoria On Demand, DITA Exchange. DocZone. SaaS is optionally supported in Bluestream XDocs, Siberlogic SiberSafe, Trisoft Infoshare, Vasont, X-Hive Docato. As wiki system is a ready integrated environment for creating and publishing documentation, DITA-system consists not only of XML CMS. To deploy a DITA-system, you should have an XML editor, publisher and CMS. The listed CMS can be integrated with top DITA XML editors and provide an API to integrate with other editors. These CMS also have build-in tools to export documents in multiple formats. However, the universal component architecture of DITA-systems makes the deployment and configuration more difficult than wiki implementation. Hosted documentation systems are offered by different prices. The offerings of top documentation systems are considered in this paper. Wiki subscription fees range from 4,95$ (EditMe) to 20$ (Confluence) per one user/month. XML CMS subscription price starts from 500$ per month and can reach 12000$ per month. These subscriptions have no fixed price; in each individual case the CMS vendor performs a specific project of a DITA-system implementation. Wiki rental costs approximate to CMS subscriptions' costs for large number of users, 500 and more. The advantages of renting a powerful documentation system for small and large project are the following: 1) Maximal functionality at a low affordable cost, 2) Platform independency and high system accessibility, 3) Document quality improvement at the expense of quality controlling tools application, 4) Higher effectiveness of documentation (content re-use, single source usage, automated tools for localization), 5) Organization of robust and scalable documentation process. As the SaaS business model becomes more popular, small companies get access to powerful software documentation systems, which are too expensive to purchase a standalone license at the startup. However, the system's access security, reliability and information confidentiality issues remain opened and controversial.},
keywords={XML;Electronic publishing;Internet;Information services;Documentation;Subscriptions;Google;Software documentation;SaaS;wiki;XML CMS},
doi={10.1109/CEE-SECR.2010.5783175},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9432545,
author={Sajkowski, Maciej and Frania, Krystian and Stenzel, Tomasz and Góral, Mateusz},
booktitle={2021 IEEE 19th International Power Electronics and Motion Control Conference (PEMC)},
title={Image Processing Based Control System for Wheeled Mobile Robots},
year={2021},
volume={},
number={},
pages={731-736},
abstract={The paper presents the design and tests of a wheeled mobile robot. The construction of the machine is based on a differential drive. A three-layer structure of the robot control system has been developed. The lowest layer is based on an 8-bit microcontroller and its purpose is to control motors and sensors of the robot. The medium layer is based on a 32-bit ARM Cortex M4 microcontroller. There has been implemented an x86 architecture computational unit as the main part of the highest layer of the control system. A control software developed for this computer is responsible for the acquisition and processing of an image stream from the camera mounted on the robot board. The software has been implemented using Aforge.NET library. Selected image processing filters have been tested in order to enable object tracking and gesture recognition in the mobile robot control system. Finally, a power consumption of the computational unit operating in several developed control modes has been measured.},
keywords={Microcontrollers;Robot vision systems;Robot control;Process control;Gesture recognition;Computer architecture;Software;differential drive;image processing;Aforge.NET},
doi={10.1109/PEMC48073.2021.9432545},
ISSN={2473-0165},
month={April},}
@INPROCEEDINGS{677027,
author={Fernandez, J.A. and Gonzalez, J.},
booktitle={Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146)},
title={NEXUS: a flexible, efficient and robust framework for integrating software components of a robotic system},
year={1998},
volume={1},
number={},
pages={524-529 vol.1},
abstract={We present NEXUS, a framework for integrating the software elements (routines, modules, etc.) of a robotic system in a modular, robust and efficient way. It is based on the use of some modular and object-oriented programming techniques. It achieves a desirable decoupling between the programs designed for a given task and the software facilities required in most of the robotic systems, making the software less sensitive to changes than monolithic applications. Another important features of NEXUS are its distributed nature, its hierarchical error recovery system, and the real-time capabilities. NEXUS has been developed for mobile robots but its design has been done generic enough for implementing other robotic systems, such as manipulators, teleoperation systems, etc. We describe the components and features of NEXUS and a real software application implemented for our mobile robot RAM-2.},
keywords={Robustness;Mobile robots;Hardware;Robotics and automation;Robot sensing systems;Application software;Real time systems;Costs;Vehicles;Intelligent robots},
doi={10.1109/ROBOT.1998.677027},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{7389025,
author={Mainetti, L. and Manco, L. and Patrono, L. and Sergi, I. and Vergallo, R.},
booktitle={2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)},
title={Web of Topics: An IoT-aware model-driven designing approach},
year={2015},
volume={},
number={},
pages={46-51},
abstract={In the Internet of Things, the extreme heterogeneity of sensors, actuators and user devices calls for new tools and design models able to translate the user's needs in machine-understandable scenarios. The scientific community has proposed different solution for such issue, e.g., the MQTT (MQ Telemetry Transport) protocol introduced the topic concept as “the key that identifies the information channel to which payload data is published”. This study extends the topic approach by proposing the Web of Topics (WoX), a conceptual model for the IoT. A WoX Topic is identified by two coordinates: (i) a discrete semantic feature of interest (e.g. temperature, humidity), and (ii) a URI-based location. An IoT entity defines its role within a Topic by specifying its technological and collaborative dimensions. By this approach, it is easier to define an IoT entity as a set of couples Topic-Role. In order to prove the effectiveness of the WoX approach, we developed the WoX APIs on top of an EPCglobal implementation. Then, 10 developers were asked to build a WoX-based application supporting a physics lab scenario at school. They also filled out an ex-ante and an ex-post questionnaire. A set of qualitative and quantitative metrics allowed measuring the model's outcome.},
keywords={Computer architecture;Sensors;Actuators;Protocols;Unified modeling language;Semantics;Computational modeling;Internet of Things;Information Architecture;Software metrics;Data Models},
doi={10.1109/WF-IoT.2015.7389025},
ISSN={},
month={Dec},}
@INPROCEEDINGS{506486,
author={Llorens, J. and Amescua, A. and Velasco, M.},
booktitle={Proceedings of the Fourth International Symposium on Assessment of Software Tools},
title={Software Thesaurus: a tool for reusing software objects},
year={1996},
volume={},
number={},
pages={99-103},
abstract={So far software reusability has not yet had practical application in the professional world. The reusability concept represents a direct link between productivity and software quality. In this paper a software tool is described, "Software Thesaurus" (ST), whose main purpose is to develop software, reusing objects produced previously in other software projects. This tool is defined by a new repository metamodel which supports the classification and retrieval of essential software objects defined by current object oriented methodologies, 4th generation languages, and GUI. This article presents both free text information and a software indexing system in order to classify all the objects necessary to develop a software application. The ST presents an original method to carry out typical software tasks i.e. analysis, design, and implementation through the combination of computer aid and reusability.},
keywords={Software tools;Thesauri;Data models;Software systems;Object oriented modeling;Software reusability;Application software;Indexing;Project management;Software engineering},
doi={10.1109/AST.1996.506486},
ISSN={},
month={May},}
@INPROCEEDINGS{5174761,
author={Milke, Edmund and Christen, Stefan and Prassler, Erwin and Nowak, Walter},
booktitle={2009 International Conference on Advanced Robotics},
title={Towards harmonization and refactoring of mobile manipulation algorithms},
year={2009},
volume={},
number={},
pages={1-8},
abstract={In this paper we present work towards the benchmarking of mobile manipulation algorithms. We review the current state-of-the art in mobile manipulation and analyze the most prominent algorithms concerning common structures and sub-components. We propose and implement harmonized interfaces for those components, building upon existing software frameworks and libraries. The foundation on the same subcomponents makes it possible to evaluate mobile manipulation planning algorithms in a systematic way. In particular it enables us to investigate on the influence of different combinations of sub-components for the overall planning task, for which we present experiments in simulation.},
keywords={Mobile robots;Path planning;Motion planning;Manipulators;Software libraries;Mobile computing;Art;Algorithm design and analysis;Robot sensing systems;Computer science;robotics;mobile manipulation;motion planning;best practice algorithms;benchmarking},
doi={},
ISSN={},
month={June},}
@INPROCEEDINGS{1616550,
author={Kootsey, J. Mailen and McAuley, Grant and Bernal, Julie},
booktitle={2005 IEEE Engineering in Medicine and Biology 27th Annual Conference},
title={Building Interactive Simulations in Web Pages without Programming},
year={2005},
volume={},
number={},
pages={855-858},
abstract={A software system is described for building interactive simulations and other numerical calculations in Web pages. The system is based on a new Java-based software architecture named NumberLinX (NLX) that isolates each function required to build the simulation so that a library of reusable objects could be assembled. The NLX objects are integrated into a commercial Web design program for coding-free page construction. The model description is entered through a wizard-like utility program that also functions as a model editor. The complete system permits very rapid construction of interactive simulations without coding. A wide range of applications are possible with the system beyond interactive calculations, including remote data collection and processing and collaboration over a network},
keywords={Web pages;Buildings;Software systems;Numerical simulation;Java;Software architecture;Software libraries;Assembly systems;Web design;Utility programs},
doi={10.1109/IEMBS.2005.1616550},
ISSN={1558-4615},
month={Jan},}
@INPROCEEDINGS{653684,
author={Klein, J.},
booktitle={Innovation in Technology Management. The Key to Global Leadership. PICMET '97},
title={Advantages of office automation application in concurrent engineering environment},
year={1997},
volume={},
number={},
pages={877-},
abstract={Summary form only given. The transformation of the "Sellers Market" of the 1980s to "Buyers Market" of the 1990s, created an extremely competitive marketing environment, in which the definition of time to market became crucial. In other words, the first to introduce a new and attractive product, will enjoy the major share of the potential profits. In order to survive in such an environment, the world's industrial establishments have modified their internal strategies and organizational structures, to shorten the interdisciplinary lead times. The new challenges, encountered with a great success by many industries and especially by hi-tech giants, emphasise the advantages of various team-work oriented methods, such as JIT and concurrent engineering. The PC revolution accelerated the creation of groupware orientation, to overcome the historical barriers between various organizational disciplines. Within the frame of this revolution, even the traditional office organization, based on a "boss", his secretary and a typist, has been forced to contribute to the main effort. Real time transfer of documents between the computer network users, filing as well as recovery of technical documentation, became a public domain. The groupware software packages, such as word processing, computerized graphics, E-mail, task control, electronic files etc., became a user-friendly tool, easily accessible by everybody in the organization. This paper presents the advantages of office computerization in a hi-tech company, acting in a concurrent engineering environment.},
keywords={Office automation;Concurrent engineering;Collaborative software;Collaborative work;Time to market;Acceleration;Computer networks;Documentation;Software packages;Text processing},
doi={10.1109/PICMET.1997.653684},
ISSN={},
month={July},}
@ARTICLE{10057961,
author={Hall, Tessa and Delport, Johannes A. and Fourie, Coenrad J.},
journal={IEEE Transactions on Applied Superconductivity},
title={Determination of the Bit Error Rate due to Thermal Noise using JoSIM Superconducting Circuit Simulator and the Monte Carlo Method},
year={2023},
volume={},
number={},
pages={1-5},
abstract={Thermal noise requires careful consideration during the design process of RSFQ circuits since it reduces circuit operating margins and can cause switching errors. Bit error rate (BER) provides a useful means of analysing the effect of this noise on a circuit. With tools developed under the IARPA SuperTools project, we present an implementation of the Monte-Carlo technique for determining BER via simulation. The Monte-Carlo method has been considered previously but not widely implemented due to slow simulation times preventing the determination of small BER values. We use JoSIM – an efficient simulator with SPICE syntax that allows for the simulation of superconducting components and noise sources with improved speed over older superconductor simulators. This speed improvement makes the Monte-Carlo method viable. The simulated BER is plotted against bias current with values in the low-BER region interpolated from the simulated values using MATLAB. We show how the results need to be used as a further qualifier of circuit performance for the characterization of a logic cell library.},
keywords={Junctions;Bit error rate;Thermal noise;Resistors;Monte Carlo methods;Integrated circuit modeling;Libraries;Electronic Design Automation;Simulation Software;Circuit Design;Superconductivity;RSFQ;Bit Error Rate},
doi={10.1109/TASC.2023.3251940},
ISSN={1558-2515},
month={},}
@INPROCEEDINGS{8098760,
author={Krak, Iurii and Kondratiuk, Sergii},
booktitle={2017 12th International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT)},
title={Cross-platform software for the development of sign communication system: Dactyl language modelling},
year={2017},
volume={1},
number={},
pages={167-170},
abstract={The technology, which is implemented using cross-platform tools, is proposed for modeling of gesture units of sign language, dynamic mapping between states of gesture units with a combination of gestures structures (words, sentences). The technology implemented simulated playback of gesture items and constructions using virtual model of spatial hand. With the cross-platform means technology achieves the ability to run on multiple platforms without implementation for each platform.},
keywords={Assistive technology;Gesture recognition;Hidden Markov models;Libraries;Hardware;Mobile communication;Cross-platform;sign language;sing modeling;communication system},
doi={10.1109/STC-CSIT.2017.8098760},
ISSN={},
month={Sep.},}
@ARTICLE{9490206,
author={Zheng, Wei and Wu, Chuang and Yang, Shuang and Xu, Yan and Li, Chunmei and Zhang, Zhiguo},
journal={IEEE Transactions on Magnetics},
title={Electronic, Magnetic, and Elastic Properties for Cr2FeZ (Z = Sb, As) Heusler Alloys: A First Principle Study},
year={2021},
volume={57},
number={9},
pages={1-5},
abstract={In this study, the electronic structures and magnetic and elastic properties of Cr2FeZ (Z = Sb, As) Heusler alloys were investigated through density functional theory calculations, which uses the generalized gradient approximation for the exchange-correlation functional included in the CASTEP software package. The results revealed that the Cr2FeSb and Cr2FeAs alloys successfully formed stable Hg2CuTi-type structures at finite temperatures. The ground-state properties of the stable structures were calculated, including lattice parameters, magnetic moments, and bulk moduli. The Cr2FeSb and Cr2FeAs alloys exhibited nearly half-metallic properties and high spin-polarization levels and thus can be used as half-metal/ferromagnetic metal (HM-FM) materials.},
keywords={Metals;Magnetic properties;Density functional theory;Tools;Temperature;Strain;Stationary state;Elastic properties;first principles;Heusler alloy;magnetic properties},
doi={10.1109/TMAG.2021.3098102},
ISSN={1941-0069},
month={Sep.},}
@INPROCEEDINGS{6552644,
author={Oueslati, Mohamed Mehdi and Ben Salah, Mohieddine and Dahmouni, Anouar Wajdi and Ben Nasrallah, Sassi},
booktitle={2013 5th International Conference on Modeling, Simulation and Applied Optimization (ICMSAO)},
title={Numerical investigation to study airfoil efficiency in plunging motion},
year={2013},
volume={},
number={},
pages={1-5},
abstract={The original incentive for developing the software package was the identification of the unsteady wake structure generation, and the prediction of aerodynamic performances of an airfoil. In fact, the Laplace's Equation is useful to solve such problem because it allows the conversion of the flow field from a 3D problem to a 2D problem in order to find the potential on the surface. In this work, we are interested to thrust generation from an airfoil in pure plunging motion. Therefore, two dimensional inviscid flow codes is developed based on the Unsteady Panel Method to predict the oscillatory flow field and the aerodynamic propriety of the oscillating airfoil. Moreover, a comparison between the performances of two different airfoils the NACA0015 and NACA4412 has been made.},
keywords={Automotive components;Mathematical model;Aerodynamics;Wind turbines;Laboratories;Drag;Equations;Unsteady Panel Method;invisvid flow;plunging motion;wake pattern},
doi={10.1109/ICMSAO.2013.6552644},
ISSN={},
month={April},}